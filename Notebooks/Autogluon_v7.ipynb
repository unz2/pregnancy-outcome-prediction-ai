{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       7.03 GB / 16.00 GB (44.0%)\n",
      "Disk Space Avail:   185.19 GB / 460.43 GB (40.2%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=10, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "DyStack: Disabling memory safe fit mode in DyStack because GPUs were detected and num_gpus='auto' (GPUs cannot be used in memory safe fit mode). If you want to use memory safe fit mode, manually set `num_gpus=0`.\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_improved/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    227867\n",
      "Train Data Columns: 70\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7263.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 106.49 MB (1.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 19 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['불임 원인 - 여성 요인']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['불임 원인 - 정자 면역학적 요인', '불임 원인 - 정자 운동성']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 2 | ['불임 원인 - 정자 면역학적 요인', '불임 원인 - 정자 운동성']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 10 | ['시술 당시 나이', '시술 유형', '특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', ...]\n",
      "\t\t('float', [])    : 30 | ['단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', ...]\n",
      "\t\t('int', [])      : 27 | ['배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  9 | ['시술 당시 나이', '특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', '난자 출처', ...]\n",
      "\t\t('float', [])     : 29 | ['단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', ...]\n",
      "\t\t('int', [])       : 12 | ['총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', ...]\n",
      "\t\t('int', ['bool']) : 17 | ['시술 유형', '배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t67 features in original data used to generate 67 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 76.93 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.52s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.68s of the 1799.48s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.54%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t8.12s\t = Training   runtime\n",
      "\t3.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 586.47s of the 1786.27s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.11%)\n",
      "\t0.7383\t = Validation score   (roc_auc)\n",
      "\t6.56s\t = Training   runtime\n",
      "\t2.19s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 577.81s of the 1777.61s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/8.8 GB\n",
      "\t0.7248\t = Validation score   (roc_auc)\n",
      "\t9.8s\t = Training   runtime\n",
      "\t6.15s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 561.45s of the 1761.25s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/8.4 GB\n",
      "\t0.7255\t = Validation score   (roc_auc)\n",
      "\t10.26s\t = Training   runtime\n",
      "\t6.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 544.59s of the 1744.39s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.76% memory usage per fold, 47.04%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=11.76%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t436.43s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 106.71s of the 1306.51s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/10.3 GB\n",
      "\t0.7281\t = Validation score   (roc_auc)\n",
      "\t7.78s\t = Training   runtime\n",
      "\t5.97s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 92.56s of the 1292.36s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/9.8 GB\n",
      "\t0.7284\t = Validation score   (roc_auc)\n",
      "\t8.07s\t = Training   runtime\n",
      "\t6.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 78.07s of the 1277.87s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.91% memory usage per fold, 71.31%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.91%)\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t57.78s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 17.88s of the 1217.68s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.32%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t12.63s\t = Training   runtime\n",
      "\t1.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2.80s of the 1202.59s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.17%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1194.06s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/6.3 GB\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.333, 'NeuralNetFastAI_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.167, 'LightGBMXT_BAG_L1': 0.083}\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t6.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 527.87s of the 1187.95s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.57%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t7.3s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 518.42s of the 1178.50s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.38%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t6.0s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 510.80s of the 1170.89s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/9.6 GB\n",
      "\t0.7479\t = Validation score   (roc_auc)\n",
      "\t24.22s\t = Training   runtime\n",
      "\t8.26s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 477.87s of the 1137.96s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/8.6 GB\n",
      "\t0.748\t = Validation score   (roc_auc)\n",
      "\t24.65s\t = Training   runtime\n",
      "\t6.75s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 446.03s of the 1106.11s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.51% memory usage per fold, 46.02%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=11.51%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t1093.68s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 10.19s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/8.5 GB\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L2': 0.524, 'RandomForestGini_BAG_L2': 0.476}\n",
      "\t0.7499\t = Validation score   (roc_auc)\n",
      "\t3.28s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
      "No base models to train on, skipping auxiliary stack level 4...\n",
      "No base models to train on, skipping stack level 4...\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.00s of the 6.78s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/10.7 GB\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L2': 0.524, 'RandomForestGini_BAG_L2': 0.476}\n",
      "\t0.7499\t = Validation score   (roc_auc)\n",
      "\t10.52s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1803.79s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1932.5 rows/s (22787 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_improved/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2       0.742413   0.739349     roc_auc        3.578420       7.881370   527.526221                 0.002296                0.026964           6.008877            2       True         10\n",
      "1           CatBoost_BAG_L1       0.742387   0.738717     roc_auc        0.169198       0.398556   436.427939                 0.169198                0.398556         436.427939            1       True          5\n",
      "2         LightGBMXT_BAG_L1       0.742156   0.738377     roc_auc        0.733875       3.253986     8.117057                 0.733875                3.253986           8.117057            1       True          1\n",
      "3           CatBoost_BAG_L2       0.742135   0.738865     roc_auc        5.175929      32.659910  1651.103707                 0.055016                0.473105        1093.677334            2       True         15\n",
      "4         LightGBMXT_BAG_L2       0.742035   0.738966     roc_auc        5.420290      33.753944   564.730711                 0.299377                1.567139           7.304338            2       True         11\n",
      "5    NeuralNetFastAI_BAG_L1       0.741981   0.737131     roc_auc        1.522332       1.012509    57.783099                 1.522332                1.012509          57.783099            1       True          8\n",
      "6           LightGBM_BAG_L2       0.741707   0.738984     roc_auc        5.344358      33.278821   563.422986                 0.223445                1.092016           5.996613            2       True         12\n",
      "7            XGBoost_BAG_L1       0.741008   0.738145     roc_auc        0.753482       1.002934    12.629133                 0.753482                1.002934          12.629133            1       True          9\n",
      "8           LightGBM_BAG_L1       0.740871   0.738317     roc_auc        0.397237       2.186421     6.560116                 0.397237                2.186421           6.560116            1       True          2\n",
      "9       WeightedEnsemble_L5       0.735000   0.749857     roc_auc     1005.835742      47.221602   616.812092                 0.000653                0.025682          10.515883            5       True         17\n",
      "10      WeightedEnsemble_L3       0.735000   0.749857     roc_auc     1005.836128      47.222926   609.573159                 0.001039                0.027006           3.276950            3       True         16\n",
      "11  RandomForestEntr_BAG_L2       0.734643   0.748001     roc_auc     1005.438957      38.932785   582.076233              1000.318044                6.745979          24.649860            2       True         14\n",
      "12  RandomForestGini_BAG_L2       0.734205   0.747935     roc_auc        5.517045      40.449941   581.646349                 0.396132                8.263135          24.219976            2       True         13\n",
      "13    ExtraTreesEntr_BAG_L1       0.734043   0.728382     roc_auc        0.379951       6.021941     8.069361                 0.379951                6.021941           8.069361            1       True          7\n",
      "14    ExtraTreesGini_BAG_L1       0.733485   0.728054     roc_auc        0.371011       5.967141     7.781509                 0.371011                5.967141           7.781509            1       True          6\n",
      "15  RandomForestEntr_BAG_L1       0.730170   0.725540     roc_auc        0.402269       6.193777    10.257609                 0.402269                6.193777          10.257609            1       True          4\n",
      "16  RandomForestGini_BAG_L1       0.729148   0.724821     roc_auc        0.391559       6.149540     9.800549                 0.391559                6.149540           9.800549            1       True          3\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t2811s\t = DyStack   runtime |\t4389s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 4389s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_improved\"\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 70\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9491.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 119.80 MB (1.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 19 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['불임 원인 - 여성 요인']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['불임 원인 - 정자 면역학적 요인']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 1 | ['불임 원인 - 정자 면역학적 요인']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 10 | ['시술 당시 나이', '시술 유형', '특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', ...]\n",
      "\t\t('float', [])    : 30 | ['단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', ...]\n",
      "\t\t('int', [])      : 28 | ['배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  9 | ['시술 당시 나이', '특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', '난자 출처', ...]\n",
      "\t\t('float', [])     : 29 | ['단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', ...]\n",
      "\t\t('int', [])       : 12 | ['총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', ...]\n",
      "\t\t('int', ['bool']) : 18 | ['시술 유형', '배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t68 features in original data used to generate 68 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 86.79 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4388.52s of the 4388.52s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.47%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t1899.85s\t = Training   runtime\n",
      "\t3.6s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2485.87s of the 2485.87s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.50%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t8.86s\t = Training   runtime\n",
      "\t2.41s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2475.00s of the 2475.00s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/8.8 GB\n",
      "\t0.7268\t = Validation score   (roc_auc)\n",
      "\t675.07s\t = Training   runtime\n",
      "\t6.79s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1792.73s of the 1792.72s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.8 GB\n",
      "\t0.7278\t = Validation score   (roc_auc)\n",
      "\t11.99s\t = Training   runtime\n",
      "\t6.73s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1773.62s of the 1773.62s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.70% memory usage per fold, 50.79%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=12.70%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t1636.15s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 135.97s of the 135.97s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/9.6 GB\n",
      "\t0.7298\t = Validation score   (roc_auc)\n",
      "\t9.85s\t = Training   runtime\n",
      "\t6.59s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 119.10s of the 119.09s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/8.3 GB\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 14.36s compared to 11.9s of available time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 438.85s of the -944.99s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/8.1 GB\n",
      "Warning: Ensemble Selection ran out of time, early stopping at iteration 25. This may mean that the time_limit specified is very small for this problem.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.48, 'LightGBM_BAG_L1': 0.32, 'LightGBMXT_BAG_L1': 0.16, 'RandomForestEntr_BAG_L1': 0.04}\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t708.78s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6042.98s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3669.7 rows/s (25636 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_improved\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import warnings\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 0. 시드 고정 (재현성 확보)\n",
    "# ==========================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "# 경로가 맞는지 확인해주세요.\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. 데이터 전처리 (누수 방지: 행 단위 처리만 수행)\n",
    "# ==========================================\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. 횟수 관련 컬럼 매핑 (문자열 -> 수치형)\n",
    "    count_cols = [\n",
    "        '총 시술 횟수', '클리닉 내 총 시술 횟수', \n",
    "        '총 임신 횟수', '총 출산 횟수',\n",
    "        'IVF 시술 횟수', 'DI 시술 횟수',\n",
    "        'IVF 임신 횟수', 'DI 임신 횟수',\n",
    "        'IVF 출산 횟수', 'DI 출산 횟수'\n",
    "    ]\n",
    "    \n",
    "    def map_count_str(x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        x = str(x)\n",
    "        if '6회 이상' in x: return 6\n",
    "        try:\n",
    "            return int(x.replace('회', ''))\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    for col in count_cols:\n",
    "        df[col] = df[col].apply(map_count_str)\n",
    "        \n",
    "    # 2. 나이 전처리: 범주형 그대로 두되, 순서형 정보(Ordinal)로 변환\n",
    "    # AutoGluon은 문자열도 잘 처리하지만, 나이는 순서가 중요하므로 매핑합니다.\n",
    "    age_map = {\n",
    "        '만18-34세': 0, '만35-37세': 1, '만38-39세': 2, \n",
    "        '만40-42세': 3, '만43-44세': 4, '만45-50세': 5, \n",
    "        '알 수 없음': -1 # 결측/알수없음은 별도 수치로\n",
    "    }\n",
    "    # 매핑되지 않는 값은 -1로 처리 (안전장치)\n",
    "    df['나이_코드'] = df['시술 당시 나이'].map(age_map).fillna(-1)\n",
    "    \n",
    "    # 3. 배아 생성 주요 이유 단순화\n",
    "    def clean_reason(x):\n",
    "        if pd.isna(x): return 'Unknown'\n",
    "        x = str(x)\n",
    "        if '시술용' in x: return 'Treatment'\n",
    "        if '기증' in x: return 'Donation'\n",
    "        if '저장' in x: return 'Storage'\n",
    "        return 'Other'\n",
    "    \n",
    "    df['배아_생성_이유_단순'] = df['배아 생성 주요 이유'].apply(clean_reason)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 3. 파생변수 생성 (Feature Engineering)\n",
    "# ==========================================\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- A. 결측치 처리 (AutoGluon은 결측치를 잘 다루므로 0이나 임의값 채우기 최소화) ---\n",
    "    # 수치형 변수들의 NaN은 0으로 채우는 게 논리적으로 타당한 경우만 채웁니다 (예: 시술 횟수)\n",
    "    fill_zero_cols = [\n",
    "        '총 생성 배아 수', '이식된 배아 수', '미세주입된 난자 수', \n",
    "        '수집된 신선 난자 수', '해동 난자 수'\n",
    "    ]\n",
    "    # 존재하는 컬럼만 처리\n",
    "    cols_to_fill = [c for c in fill_zero_cols if c in df.columns]\n",
    "    df[cols_to_fill] = df[cols_to_fill].fillna(0)\n",
    "\n",
    "    # --- B. 효율성 및 비율 지표 (Zero Division 방지) ---\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    # 난자 관련 합계\n",
    "    oocyte_cols = ['수집된 신선 난자 수', '혼합된 난자 수', '해동 난자 수']\n",
    "    valid_oocyte_cols = [c for c in oocyte_cols if c in df.columns]\n",
    "    df['총_난자_수'] = df[valid_oocyte_cols].sum(axis=1)\n",
    "    \n",
    "    # 1. 배아 생성 효율 (난자 대비 배아)\n",
    "    df['배아_생성_효율'] = df['총 생성 배아 수'] / (df['총_난자_수'] + epsilon)\n",
    "    \n",
    "    # 2. 이식 효율 (생성된 배아 중 얼마나 이식했나)\n",
    "    df['배아_이식_비율'] = df['이식된 배아 수'] / (df['총 생성 배아 수'] + epsilon)\n",
    "    \n",
    "    # 3. 미세주입 성공률\n",
    "    if '미세주입된 난자 수' in df.columns and '미세주입에서 생성된 배아 수' in df.columns:\n",
    "        df['미세주입_성공률'] = df['미세주입에서 생성된 배아 수'] / (df['미세주입된 난자 수'] + epsilon)\n",
    "\n",
    "    # --- C. 과거 성공 이력 (중요) ---\n",
    "    df['시술_대비_임신_성공률'] = df['총 임신 횟수'] / (df['총 시술 횟수'] + epsilon)\n",
    "    df['시술_대비_출산_성공률'] = df['총 출산 횟수'] / (df['총 시술 횟수'] + epsilon)\n",
    "    \n",
    "    # --- D. 상호작용 (도메인 지식) ---\n",
    "    # 나이가 많을수록 이식 배아 수가 중요함\n",
    "    df['나이_x_이식배아'] = df['나이_코드'] * df['이식된 배아 수']\n",
    "    \n",
    "    # --- E. 불임 원인 합계 ---\n",
    "    infertility_cols = [col for col in df.columns if '불임 원인' in col]\n",
    "    df['불임_원인_총합'] = df[infertility_cols].sum(axis=1) # 1과 0으로 되어있다고 가정\n",
    "    \n",
    "    # --- F. 중요 컬럼 삭제 방지 및 정리 ---\n",
    "    drop_cols = ['ID', '시술 시기 코드', '난자 해동 경과일', '배아 해동 경과일',\n",
    "                 'PGS 시술 여부', 'PGD 시술 여부', '착상 전 유전 검사 사용 여부', '임신 시도 또는 마지막 임신 경과 연수'] \n",
    "    df = df.drop([c for c in drop_cols if c in df.columns], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 전처리 및 파생변수 적용\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 4. 범주형 변수 타입 명시 (pd.get_dummies 대체)\n",
    "# ==========================================\n",
    "# AutoGluon이 범주형 변수를 인식하도록 object 타입 컬럼을 category로 변환\n",
    "# Test set의 통계를 쓰지 않으므로 누수 아님\n",
    "cat_cols = train_df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    train_df[col] = train_df[col].astype('category')\n",
    "    test_df[col] = test_df[col].astype('category')\n",
    "\n",
    "# ==========================================\n",
    "# 5. 모델 학습 (AutoGluon)\n",
    "# ==========================================\n",
    "\n",
    "# GPU 사용 여부 체크 (없으면 CPU 전체 사용)\n",
    "ag_args_fit = {\n",
    "    'num_gpus': 1 if pd.api.types.is_list_like(os.environ.get('CUDA_VISIBLE_DEVICES')) else 0\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target,\n",
    "    eval_metric='roc_auc', \n",
    "    path='ag_models_improved', # 경로 변경\n",
    "    problem_type='binary'\n",
    ").fit(\n",
    "    train_data=train_df,\n",
    "    presets='best_quality', # 가장 성능이 좋은 설정\n",
    "    time_limit=7200,        # 2시간 (충분함)\n",
    "    num_stack_levels=3,     # 스태킹 레벨 상향 (성능 향상 핵심)\n",
    "    num_bag_folds=10,       # 앙상블 폴드 수 상향 (안정성 확보)\n",
    "    ag_args_fit=ag_args_fit,\n",
    "    # excluded_model_types=['KNN'] # 속도가 너무 느리면 KNN 제외 고려\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 6. 추론 및 저장\n",
    "# ==========================================\n",
    "\n",
    "# predict_proba로 확률 예측\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "# 1번 클래스(성공)의 확률만 추출\n",
    "final_probs = pred_probs.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c7c3f8-495c-4d28-9be8-c868762a4046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.923365</td>\n",
       "      <td>0.727789</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.505685</td>\n",
       "      <td>6.731623</td>\n",
       "      <td>11.985702</td>\n",
       "      <td>1.505685</td>\n",
       "      <td>6.731623</td>\n",
       "      <td>11.985702</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.922081</td>\n",
       "      <td>0.726805</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.511207</td>\n",
       "      <td>6.785319</td>\n",
       "      <td>675.066578</td>\n",
       "      <td>1.511207</td>\n",
       "      <td>6.785319</td>\n",
       "      <td>675.066578</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.902709</td>\n",
       "      <td>0.729825</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.436919</td>\n",
       "      <td>6.585830</td>\n",
       "      <td>9.850467</td>\n",
       "      <td>1.436919</td>\n",
       "      <td>6.585830</td>\n",
       "      <td>9.850467</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.760003</td>\n",
       "      <td>0.739601</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>10.245007</td>\n",
       "      <td>13.084049</td>\n",
       "      <td>4265.621937</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.044137</td>\n",
       "      <td>708.779908</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.749083</td>\n",
       "      <td>0.738982</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.205471</td>\n",
       "      <td>2.406518</td>\n",
       "      <td>8.858772</td>\n",
       "      <td>3.205471</td>\n",
       "      <td>2.406518</td>\n",
       "      <td>8.858772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0  RandomForestEntr_BAG_L1    0.923365   0.727789     roc_auc        1.505685   \n",
       "1  RandomForestGini_BAG_L1    0.922081   0.726805     roc_auc        1.511207   \n",
       "2    ExtraTreesGini_BAG_L1    0.902709   0.729825     roc_auc        1.436919   \n",
       "3      WeightedEnsemble_L2    0.760003   0.739601     roc_auc       10.245007   \n",
       "4          LightGBM_BAG_L1    0.749083   0.738982     roc_auc        3.205471   \n",
       "\n",
       "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0       6.731623    11.985702                 1.505685   \n",
       "1       6.785319   675.066578                 1.511207   \n",
       "2       6.585830     9.850467                 1.436919   \n",
       "3      13.084049  4265.621937                 0.006016   \n",
       "4       2.406518     8.858772                 3.205471   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                6.731623          11.985702            1       True   \n",
       "1                6.785319         675.066578            1       True   \n",
       "2                6.585830           9.850467            1       True   \n",
       "3                0.044137         708.779908            2       True   \n",
       "4                2.406518           8.858772            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          4  \n",
       "1          3  \n",
       "2          6  \n",
       "3          7  \n",
       "4          2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. 리더보드 (오름차순 정렬) ---\n",
    "# 학습 데이터 내에서의 Validation Score 확인\n",
    "lb = predictor.leaderboard(train_df, silent=True)\n",
    "display(lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 피처 중요도 ---\n",
    "fi = predictor.feature_importance(data=train_df.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "display(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 3. 제출 파일 생성 ---\n",
    "# import datetime\n",
    "# submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "# submission['probability'] = final_probs.values\n",
    "\n",
    "# # 현재 시간 가져오기 (예: 0206_1031)\n",
    "# now = datetime.now().strftime('%m%d_%H%M')\n",
    "# file_name = f\"{now}_submission.csv\"\n",
    "# submission.to_csv(file_name, index=False)\n",
    "\n",
    "# print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a70df-fec8-4d5b-9ee5-f66126ed5d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
