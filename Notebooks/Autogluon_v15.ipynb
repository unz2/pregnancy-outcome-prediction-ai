{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       8.14 GB / 16.00 GB (50.9%)\n",
      "Disk Space Avail:   163.26 GB / 460.43 GB (35.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=2\n",
      "Beginning AutoGluon training ... Time limit = 10800s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v15\"\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 61\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8376.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 36.92 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['시술_대분류']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('category', []) : 1 | ['시술_대분류']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 14 | ['특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', '난자 출처', '정자 출처', ...]\n",
      "\t\t('float', [])    : 30 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])      : 16 | ['시술 당시 나이', '배란 자극 여부', '불명확 불임 원인', '총 시술 횟수', 'IVF 시술 횟수', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 14 | ['특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', '난자 출처', '정자 출처', ...]\n",
      "\t\t('float', [])     : 28 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       : 10 | ['시술 당시 나이', '총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['배란 자극 여부', '불명확 불임 원인', 'PGD 시술 여부', '난자 채취 경과일', 'BLASTOCYST_포함', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t60 features in original data used to generate 60 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 35.21 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.44s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Included models: ['GBM', 'CAT', 'XGB'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 46 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 7197.91s of the 10799.56s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.07%)\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t18.49s\t = Training   runtime\n",
      "\t6.95s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 7174.28s of the 10775.93s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.13%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t14.7s\t = Training   runtime\n",
      "\t4.55s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 7157.12s of the 10758.77s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 7.94% memory usage per fold, 63.56%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.94%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t1318.29s\t = Training   runtime\n",
      "\t2.92s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 5837.20s of the 9438.85s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 5.44% memory usage per fold, 43.55%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.44%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t29.23s\t = Training   runtime\n",
      "\t3.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 5805.10s of the 9406.75s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.10%)\n",
      "\t0.7376\t = Validation score   (roc_auc)\n",
      "\t20.18s\t = Training   runtime\n",
      "\t8.88s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 5782.34s of the 9383.99s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.02% memory usage per fold, 64.17%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.02%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t227.72s\t = Training   runtime\n",
      "\t1.32s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 5552.72s of the 9154.37s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.32%)\n",
      "\t0.7383\t = Validation score   (roc_auc)\n",
      "\t43.59s\t = Training   runtime\n",
      "\t24.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 5505.58s of the 9107.23s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.56% memory usage per fold, 68.48%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.56%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t382.85s\t = Training   runtime\n",
      "\t4.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 5120.73s of the 8722.38s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.84%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t119.06s\t = Training   runtime\n",
      "\t40.99s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 4996.41s of the 8598.06s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 5.57% memory usage per fold, 44.52%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.57%)\n",
      "\t0.7366\t = Validation score   (roc_auc)\n",
      "\t80.93s\t = Training   runtime\n",
      "\t11.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 4912.78s of the 8514.43s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 7.47% memory usage per fold, 59.78%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.47%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t1333.41s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 3577.41s of the 7179.06s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 7.76% memory usage per fold, 62.09%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.76%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t719.66s\t = Training   runtime\n",
      "\t2.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 2855.73s of the 6457.38s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.62%)\n",
      "\t0.7378\t = Validation score   (roc_auc)\n",
      "\t21.6s\t = Training   runtime\n",
      "\t10.51s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 2831.43s of the 6433.08s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.54%)\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t36.37s\t = Training   runtime\n",
      "\t3.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 2792.99s of the 6394.64s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.19%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t16.31s\t = Training   runtime\n",
      "\t5.8s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 2774.39s of the 6376.04s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 6.84% memory usage per fold, 54.74%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.84%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t308.91s\t = Training   runtime\n",
      "\t2.74s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 2463.59s of the 6065.24s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.01%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t17.91s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 2443.51s of the 6045.16s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 7.05% memory usage per fold, 56.38%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.05%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t1682.13s\t = Training   runtime\n",
      "\t3.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 759.46s of the 4361.11s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 5.27% memory usage per fold, 42.18%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.27%)\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t65.38s\t = Training   runtime\n",
      "\t45.69s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 689.29s of the 4290.94s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 7.69% memory usage per fold, 61.53%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.69%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t314.87s\t = Training   runtime\n",
      "\t3.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 372.41s of the 3974.06s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.15%)\n",
      "\t0.738\t = Validation score   (roc_auc)\n",
      "\t181.32s\t = Training   runtime\n",
      "\t242.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 180.80s of the 3782.45s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.23% memory usage per fold, 65.83%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.23%)\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t145.52s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 33.19s of the 3634.84s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.07%)\n",
      "\t0.7365\t = Validation score   (roc_auc)\n",
      "\t28.98s\t = Training   runtime\n",
      "\t2.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 2.02s of the 3603.68s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.14%)\n",
      "\t0.7214\t = Validation score   (roc_auc)\n",
      "\t4.42s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 719.79s of the 3597.13s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/7.0 GB\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.208, 'LightGBM_r96_BAG_L1': 0.208, 'XGBoost_r89_BAG_L1': 0.167, 'CatBoost_r69_BAG_L1': 0.167, 'CatBoost_r50_BAG_L1': 0.125, 'LightGBM_r161_BAG_L1': 0.083, 'LightGBM_r130_BAG_L1': 0.042}\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t18.96s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Included models: ['GBM', 'CAT', 'XGB'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 46 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3578.12s of the 3578.06s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.51%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t16.57s\t = Training   runtime\n",
      "\t3.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3559.66s of the 3559.61s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 5.16% memory usage per fold, 41.32%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.16%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t16.91s\t = Training   runtime\n",
      "\t2.71s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 3540.30s of the 3540.25s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.38% memory usage per fold, 75.07%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.38%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t783.24s\t = Training   runtime\n",
      "\t2.42s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 2755.27s of the 2755.21s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 6.27% memory usage per fold, 50.18%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.27%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t29.05s\t = Training   runtime\n",
      "\t3.23s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 2723.33s of the 2723.28s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 5.49% memory usage per fold, 43.94%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.49%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t24.79s\t = Training   runtime\n",
      "\t6.42s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 2695.72s of the 2695.67s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.29% memory usage per fold, 74.29%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.29%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t189.65s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 2503.95s of the 2503.89s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.83%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t46.15s\t = Training   runtime\n",
      "\t16.64s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 2454.57s of the 2454.52s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.63% memory usage per fold, 42.53%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.63%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t266.65s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 2186.00s of the 2185.95s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.81%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t53.03s\t = Training   runtime\n",
      "\t8.62s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 2130.21s of the 2130.16s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.11% memory usage per fold, 64.85%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.11%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t133.34s\t = Training   runtime\n",
      "\t9.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 1994.03s of the 1993.97s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.24% memory usage per fold, 65.94%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.24%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t407.23s\t = Training   runtime\n",
      "\t2.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 1584.64s of the 1584.59s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.13% memory usage per fold, 44.53%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.13%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t587.48s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 995.08s of the 995.03s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 5.79% memory usage per fold, 46.35%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.79%)\n",
      "\t0.738\t = Validation score   (roc_auc)\n",
      "\t24.51s\t = Training   runtime\n",
      "\t8.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 967.88s of the 967.83s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 6.84% memory usage per fold, 54.74%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.84%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t29.7s\t = Training   runtime\n",
      "\t3.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 935.86s of the 935.81s of remaining time.\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.87%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t20.14s\t = Training   runtime\n",
      "\t4.9s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L2 ... Training model for up to 913.05s of the 913.00s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.22% memory usage per fold, 65.75%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.22%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t128.18s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L2 ... Training model for up to 782.66s of the 782.61s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 6.09% memory usage per fold, 48.69%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.09%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t20.84s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L2 ... Training model for up to 759.61s of the 759.56s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.61% memory usage per fold, 68.91%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.61%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t485.54s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L2 ... Training model for up to 271.90s of the 271.85s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 7.46% memory usage per fold, 59.68%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.46%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t90.54s\t = Training   runtime\n",
      "\t43.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L2 ... Training model for up to 176.47s of the 176.42s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.25% memory usage per fold, 74.01%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.25%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t142.8s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L2 ... Training model for up to 31.47s of the 31.42s of remaining time.\n",
      "\tMemory not enough to fit 16 folds in parallel. Will train 8 folds in parallel instead (Estimated 6.40% memory usage per fold, 51.21%/80.00% total).\n",
      "\tFitting 16 child models (S1F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.40%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t28.78s\t = Training   runtime\n",
      "\t10.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -0.83s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/7.7 GB\n",
      "\tEnsemble Weights: {'LightGBM_r161_BAG_L2': 0.636, 'CatBoost_r177_BAG_L1': 0.182, 'LightGBM_r96_BAG_L1': 0.091, 'XGBoost_r89_BAG_L1': 0.091}\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t25.9s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10826.81s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 67.1 rows/s (32044 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/8.7 GB\n",
      "\t2.89s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/8.5 GB\n",
      "\t2.26s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t72.58s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.75s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/7.7 GB\n",
      "\t6.82s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t14.4s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/7.7 GB\n",
      "\t10.68s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t27.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/7.7 GB\n",
      "\t15.24s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t4.51s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t78.83s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t51.21s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/7.0 GB\n",
      "\t6.65s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.92s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/6.9 GB\n",
      "\t3.76s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t18.72s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.37s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t90.04s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r161_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/7.2 GB\n",
      "\t52.96s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r70_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t22.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r196_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/7.3 GB\n",
      "\t62.44s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r167_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t10.34s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r98_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t2.92s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r15_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/7.2 GB\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.208, 'LightGBM_r96_BAG_L1': 0.208, 'XGBoost_r89_BAG_L1': 0.167, 'CatBoost_r69_BAG_L1': 0.167, 'CatBoost_r50_BAG_L1': 0.125, 'LightGBM_r161_BAG_L1': 0.083, 'LightGBM_r130_BAG_L1': 0.042}\n",
      "\t18.96s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/7.2 GB\n",
      "\t2.51s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/7.1 GB\n",
      "\t2.65s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t29.81s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t2.21s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.8 GB\n",
      "\t9.19s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t9.37s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.7 GB\n",
      "\t12.26s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t18.2s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.6 GB\n",
      "\t5.93s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t6.3s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t18.41s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t43.38s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.6 GB\n",
      "\t6.88s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r89_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t2.31s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r130_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.5 GB\n",
      "\t5.17s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r50_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t6.47s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r194_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.48s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r69_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t23.56s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r161_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/7.0 GB\n",
      "\t42.34s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r70_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t11.71s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r196_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.9 GB\n",
      "\t8.79s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_r161_BAG_L2': 0.636, 'CatBoost_r177_BAG_L1': 0.182, 'LightGBM_r96_BAG_L1': 0.091, 'XGBoost_r89_BAG_L1': 0.091}\n",
      "\t25.9s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 843.14s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v15\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. feature_engineering\n",
    "# ==========================================\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 1. 수치형 변환 및 기초 클리닝 (derive_features 로직)\n",
    "    # ---------------------------------------------------------\n",
    "    count_cols = [\n",
    "        '총 시술 횟수', '클리닉 내 총 시술 횟수', '총 임신 횟수', '총 출산 횟수',\n",
    "        'IVF 시술 횟수', 'DI 시술 횟수', 'IVF 임신 횟수', 'DI 임신 횟수',\n",
    "        'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '이식된 배아 수', \n",
    "        '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '저장된 배아 수'\n",
    "    ]\n",
    "    \n",
    "    for col in count_cols:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            # '회', ' 이상' 등을 제거하고 공백 정리 후 숫자형으로 변환\n",
    "            df[col] = df[col].astype(str).str.replace(r'회| 이상', '', regex=True).str.strip()\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # DI 시술 유형에 대한 결측치 처리 (특정 조건에 따른 0 채움)\n",
    "    target_cols = [\n",
    "            '총 생성 배아 수', '기증자 정자와 혼합된 난자 수', '파트너 정자와 혼합된 난자 수',\n",
    "            '미세주입된 난자 수', '혼합된 난자 수', '저장된 신선 난자 수', '해동 난자 수',\n",
    "            '해동된 배아 수', '미세주입 후 저장된 배아 수', '저장된 배아 수',\n",
    "            '미세주입 배아 이식 수', '이식된 배아 수', '미세주입에서 생성된 배아 수',\n",
    "            '수집된 신선 난자 수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '대리모 여부',\n",
    "            '기증 배아 사용 여부', '신선 배아 사용 여부', '동결 배아 사용 여부'\n",
    "        ]\n",
    "    \n",
    "    # 해당 컬럼들이 존재하는 경우에만 처리\n",
    "    existing_target_cols = [c for c in target_cols if c in df.columns]\n",
    "    if '특정 시술 유형' in df.columns:\n",
    "        mask_di = df['특정 시술 유형'] == 'DI'\n",
    "        df.loc[mask_di, existing_target_cols] = df.loc[mask_di, existing_target_cols].fillna(0)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. 문자열 기반 파생 변수 생성 (수치 변환 전 수행) (preprocess 로직)\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    # 2.1 시술_대분류 & BLASTOCYST\n",
    "    if '특정 시술 유형' in df.columns:\n",
    "        def major_procedure(x):\n",
    "            if pd.isna(x): return \"Unknown\"\n",
    "            if \"IUI\" in x: return \"IUI\"\n",
    "            if \"DI\" in x: return \"Other\"\n",
    "            if \"ICSI\" in x: return \"ICSI\"\n",
    "            if \"IVF\" in x: return \"IVF\"\n",
    "            return \"Other\"\n",
    "        \n",
    "        df[\"시술_대분류\"] = df[\"특정 시술 유형\"].apply(major_procedure)\n",
    "        df[\"BLASTOCYST_포함\"] = df[\"특정 시술 유형\"].str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "\n",
    "    # 2.2 총시술_bin3 (위에서 수치형으로 변환된 '총 시술 횟수' 활용)\n",
    "    def collapse_trials(x):\n",
    "        # 이미 수치형으로 변환되었으므로 숫자 기준으로 처리하거나 문자열 매핑 유지\n",
    "        # 원본 로직이 문자열('0회')을 처리했으나, 앞서 수치형 변환을 했으므로 숫자로 처리\n",
    "        if x == 0: return '0회'\n",
    "        elif 1 <= x <= 2: return '1–2회'\n",
    "        else: return '3회 이상'\n",
    "        \n",
    "    df[\"총시술_bin3\"] = df[\"총 시술 횟수\"].apply(collapse_trials)\n",
    "\n",
    "    # 2.3 나이_3구간 (원본 문자열 '만xx-xx세' 활용)\n",
    "    def age_group_simple(age):\n",
    "        if age == '알 수 없음': return 'Unknown'\n",
    "        elif age == '만18-34세': return '34세 이하'\n",
    "        elif age in ['만35-37세', '만38-39세']: return '35-39세'\n",
    "        else: return '40세 이상'\n",
    "\n",
    "    df['나이_3구간'] = df['시술 당시 나이'].apply(age_group_simple)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. 불임 원인 및 복잡도 계산 (Column Drop 전 수행)\n",
    "    # ---------------------------------------------------------\n",
    "    female_cols = [\n",
    "        '불임 원인 - 여성 요인', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', \n",
    "        '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '여성 주 불임 원인', \n",
    "        '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인'\n",
    "    ]\n",
    "    male_cols = [\n",
    "        '불임 원인 - 남성 요인', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', \n",
    "        '불임 원인 - 정자 형태', '불임 원인 - 정자 면역학적 요인', '남성 주 불임 원인', \n",
    "        '남성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인'\n",
    "    ]\n",
    "    infertility_cols = [\n",
    "        \"남성 주 불임 원인\", \"남성 부 불임 원인\", \"여성 주 불임 원인\", \"여성 부 불임 원인\",\n",
    "        \"부부 주 불임 원인\", \"부부 부 불임 원인\", \"불명확 불임 원인\",\n",
    "        \"불임 원인 - 난관 질환\", \"불임 원인 - 남성 요인\", \"불임 원인 - 배란 장애\",\n",
    "        \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\",\n",
    "        \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\",\n",
    "        \"불임 원인 - 정자 형태\"\n",
    "    ]\n",
    "\n",
    "    # 불임 원인 복잡도 (preprocess)\n",
    "    df[\"불임_원인_개수\"] = df[infertility_cols].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df['불임원인_복잡도'] = df['불임_원인_개수'].apply(infertility_complexity)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. 배아 및 난자 관련 효율/상태 변수 생성\n",
    "    # ---------------------------------------------------------\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    # 4.1 난자 총합 및 손실률 (derive_features)\n",
    "    oocyte_cols = ['수집된 신선 난자 수', '혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '해동 난자 수']\n",
    "    df['총 난자 수'] = df[oocyte_cols].fillna(0).sum(axis=1)\n",
    "    df['배아 손실률'] = (df['총 난자 수'] - df['총 생성 배아 수']) / (df['총 난자 수'] + epsilon)\n",
    "\n",
    "    # 4.2 배아 이식 상태 및 단계 (preprocess)\n",
    "    embryo_stage_cols = [\n",
    "        \"단일 배아 이식 여부\", \"착상 전 유전 진단 사용 여부\", \"배아 생성 주요 이유\",\n",
    "        \"총 생성 배아 수\", \"미세주입된 난자 수\", \"미세주입에서 생성된 배아 수\",\n",
    "        \"이식된 배아 수\", \"미세주입 배아 이식 수\", \"저장된 배아 수\",\n",
    "        \"미세주입 후 저장된 배아 수\", \"해동된 배아 수\", \"해동 난자 수\",\n",
    "        \"수집된 신선 난자 수\", \"저장된 신선 난자 수\", \"혼합된 난자 수\",\n",
    "        \"파트너 정자와 혼합된 난자 수\", \"기증자 정자와 혼합된 난자 수\",\n",
    "        \"동결 배아 사용 여부\", \"신선 배아 사용 여부\", \"기증 배아 사용 여부\", \"대리모 여부\",\n",
    "    ]\n",
    "    df[\"배아_이식_미도달\"] = df[embryo_stage_cols].isna().all(axis=1).astype(int)\n",
    "    df[\"배아_이식_여부\"] = 1 - df[\"배아_이식_미도달\"]\n",
    "\n",
    "    def embryo_stage(row):\n",
    "        if row['배아_이식_여부'] == 0: return '배아단계_미도달'\n",
    "        elif pd.isna(row['총 생성 배아 수']) or row['총 생성 배아 수'] == 0: return '배아생성_실패'\n",
    "        elif pd.isna(row['이식된 배아 수']) or row['이식된 배아 수'] == 0: return '이식_미실시'\n",
    "        else: return '이식_완료'\n",
    "\n",
    "    df['배아_진행_단계'] = df.apply(embryo_stage, axis=1)\n",
    "\n",
    "    # 4.3 이식 배아 구간 (preprocess)\n",
    "    def embryo_count_bin(count):\n",
    "        if pd.isna(count) or count == 0: return '0개'\n",
    "        elif count <= 2: return '1-2개'\n",
    "        else: return '3개 이상'\n",
    "    df['이식배아_구간'] = df['이식된 배아 수'].apply(embryo_count_bin)\n",
    "\n",
    "    # 4.4 기타 상태 플래그\n",
    "    df['Day5_이식_여부'] = (df['배아 이식 경과일'] == 5.0).astype(int)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5. 수치형 변환(Mapping) 및 비율 계산 (derive_features 메인 로직)\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    # 5.1 나이 Mapping (Ordinal Encoding)\n",
    "    # *주의: 이 단계 이후로 '시술 당시 나이'는 숫자가 됨\n",
    "    age_order = {\n",
    "        '만18-34세': 1, '만35-37세': 2, '만38-39세': 3, \n",
    "        '만40-42세': 4, '알 수 없음': 5, '만43-44세': 6, '만45-50세': 7,\n",
    "    }\n",
    "    df['시술 당시 나이'] = df['시술 당시 나이'].map(age_order).fillna(5)\n",
    "\n",
    "    # 5.2 비율 및 효율성 변수\n",
    "    df['나이 이식배아 비율'] = df['시술 당시 나이'] * df['이식된 배아 수']\n",
    "    df['연령별 배아 효율'] = df['이식된 배아 수'] / df['시술 당시 나이']\n",
    "    df['배아_생성_효율'] = df['총 생성 배아 수'] / (df['수집된 신선 난자 수'] + 1)\n",
    "    df['배아_이식_비율'] = df['이식된 배아 수'] / (df['총 생성 배아 수'] + 1)\n",
    "    df['배아_저장_비율'] = df['저장된 배아 수'] / (df['총 생성 배아 수'] + 1)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 6. 범주형 데이터 단순화 (Categorical Cleaning)\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    # 6.1 시술 유형 정제\n",
    "    def clean_treatment(val):\n",
    "        val = str(val).upper()\n",
    "        if 'ICSI' in val: return 'ICSI'\n",
    "        if 'IVF' in val: return 'IVF'\n",
    "        if 'IUI' in val: return 'IUI'\n",
    "        return 'Other'\n",
    "    df['특정 시술 유형'] = df['특정 시술 유형'].apply(clean_treatment)\n",
    "\n",
    "    # 6.2 배아 생성 이유 정제\n",
    "    def clean_reason(x):\n",
    "        if pd.isna(x): return 'Unknown'\n",
    "        x = str(x)\n",
    "        if '시술용' in x: return 'Treatment'\n",
    "        if '기증' in x: return 'Donation'\n",
    "        if '저장' in x: return 'Storage'\n",
    "        return 'Other'\n",
    "    df['배아 생성 주요 이유'] = df['배아 생성 주요 이유'].apply(clean_reason)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 7. 교호작용(Interaction) 변수 생성 (preprocess)\n",
    "    # ---------------------------------------------------------\n",
    "    # '시술 당시 나이'가 이미 숫자로 변환되었으므로 astype(str) 사용 시 \"1.0_0\" 형태로 생성됨.\n",
    "    # 이는 One-hot encoding 등에 유리하므로 그대로 진행\n",
    "    df['나이×Day5'] = df['시술 당시 나이'].astype(str) + '_' + df['Day5_이식_여부'].astype(str)\n",
    "    df['시술횟수×나이'] = df['총시술_bin3'] + '_' + df['나이_3구간']\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 8. 불필요 컬럼 삭제 (derive_features)\n",
    "    # ---------------------------------------------------------\n",
    "    drop_cols = [\n",
    "        'ID', \n",
    "        '시술 시기 코드',\n",
    "        '저장된 배아 수', \n",
    "        '착상 전 유전 검사 사용 여부', \n",
    "        'PGS 시술 여부', \n",
    "        'DI 출산 횟수', \n",
    "        '대리모 여부', \n",
    "        '시술 유형',\n",
    "        '저장된 신선 난자 수',\n",
    "        '총 난자 수',\n",
    "        '클리닉 내 총 시술 횟수'\n",
    "    ]\n",
    "    # 사용된 원본 컬럼들 모두 삭제\n",
    "    final_drop_list = drop_cols + female_cols + male_cols\n",
    "    df.drop(columns=final_drop_list, errors='ignore', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 데이터 타입 최적화\n",
    "# ==========================================\n",
    "\n",
    "def optimize_memory(df):\n",
    "    for col in df.columns:\n",
    "        # 숫자형 데이터 최적화\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            if df[col].dtype == 'int64':\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        \n",
    "        # 문자열(object) 데이터 -> 범주형(category) 변환\n",
    "        # AutoGluon은 category 타입을 매우 효율적으로 처리합니다.\n",
    "        elif df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "train_df = optimize_memory(train_df)\n",
    "test_df = optimize_memory(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 4. 모델 학습 설정\n",
    "# ==========================================\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target,\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='ag_models_out_v15',\n",
    ").fit(\n",
    "    train_data=train_df,\n",
    "    time_limit=10800,\n",
    "    presets='best_quality',\n",
    "    num_stack_levels=1,\n",
    "    num_bag_folds=8,\n",
    "    num_bag_sets=2,\n",
    "    included_model_types=['GBM', 'CAT', 'XGB'],\n",
    "    refit_full=True,\n",
    "    dynamic_stacking=False,\n",
    "    save_space=True,\n",
    "    set_best_to_refit_full=True\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\n",
    "# ==========================================\n",
    "\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "final_probs = pred_probs.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca412e5d-8496-45dd-9636-a0159ca867ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_r161_BAG_L1_FULL</td>\n",
       "      <td>0.783320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2.060187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.960176</td>\n",
       "      <td>2.060187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.960176</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_r161_BAG_L1</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>0.737108</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>34.745983</td>\n",
       "      <td>45.693217</td>\n",
       "      <td>65.377847</td>\n",
       "      <td>34.745983</td>\n",
       "      <td>45.693217</td>\n",
       "      <td>65.377847</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_r33_BAG_L1_FULL</td>\n",
       "      <td>0.779560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.194533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.513463</td>\n",
       "      <td>1.194533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.513463</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_r33_BAG_L1</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.736634</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>19.760887</td>\n",
       "      <td>11.014163</td>\n",
       "      <td>80.926188</td>\n",
       "      <td>19.760887</td>\n",
       "      <td>11.014163</td>\n",
       "      <td>80.926188</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.766988</td>\n",
       "      <td>0.737602</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>9.486379</td>\n",
       "      <td>8.882177</td>\n",
       "      <td>20.180420</td>\n",
       "      <td>9.486379</td>\n",
       "      <td>8.882177</td>\n",
       "      <td>20.180420</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  score_test  score_val eval_metric  \\\n",
       "0  LightGBM_r161_BAG_L1_FULL    0.783320        NaN     roc_auc   \n",
       "1       LightGBM_r161_BAG_L1    0.783307   0.737108     roc_auc   \n",
       "2    XGBoost_r33_BAG_L1_FULL    0.779560        NaN     roc_auc   \n",
       "3         XGBoost_r33_BAG_L1    0.778641   0.736634     roc_auc   \n",
       "4       LightGBMLarge_BAG_L1    0.766988   0.737602     roc_auc   \n",
       "\n",
       "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0        2.060187            NaN  52.960176                 2.060187   \n",
       "1       34.745983      45.693217  65.377847                34.745983   \n",
       "2        1.194533            NaN   4.513463                 1.194533   \n",
       "3       19.760887      11.014163  80.926188                19.760887   \n",
       "4        9.486379       8.882177  20.180420                 9.486379   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                     NaN          52.960176            1       True   \n",
       "1               45.693217          65.377847            1       True   \n",
       "2                     NaN           4.513463            1       True   \n",
       "3               11.014163          80.926188            1       True   \n",
       "4                8.882177          20.180420            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0         66  \n",
       "1         19  \n",
       "2         57  \n",
       "3         10  \n",
       "4          5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 리더보드 출력 ---\n",
    "lb = predictor.leaderboard(train_df, silent=True)\n",
    "display(lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 및 예측이 완료되었습니다. 결과가 0210_1500_submission.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# --- 제출 파일 생성 ---\n",
    "submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "submission['probability'] = final_probs.values\n",
    "\n",
    "# 현재 시간 가져오기 (예: 0206_1031)\n",
    "now = datetime.now().strftime('%m%d_%H%M')\n",
    "file_name = f\"{now}_submission.csv\"\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['시술_대분류']\n",
      "Computing feature importance via permutation shuffling for 60 features using 5000 rows with 5 shuffle sets...\n",
      "\t197.39s\t= Expected runtime (39.48s per shuffle set)\n",
      "\t127.99s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "# --- 피처 중요도 ---\n",
    "fi = predictor.feature_importance(data=train_df.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "fi.to_excel('fi15.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
