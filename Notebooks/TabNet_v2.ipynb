{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb61869e-7f30-4059-b4ab-4ea4b0e5385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MPS 가속이 활성화되었습니다.\n",
      "Positive Class Weight: 2.8707\n",
      "TabNet 학습 시작 (Quantile Transform 적용됨)...\n",
      "epoch 0  | loss: 0.627   | train_auc: 0.69705 | valid_auc: 0.69158 |  0:00:47s\n",
      "epoch 1  | loss: 0.58758 | train_auc: 0.72737 | valid_auc: 0.72128 |  0:01:29s\n",
      "epoch 2  | loss: 0.58416 | train_auc: 0.73261 | valid_auc: 0.72791 |  0:02:12s\n",
      "epoch 3  | loss: 0.58218 | train_auc: 0.73462 | valid_auc: 0.73013 |  0:02:55s\n",
      "epoch 4  | loss: 0.58094 | train_auc: 0.73675 | valid_auc: 0.73219 |  0:03:37s\n",
      "epoch 5  | loss: 0.57985 | train_auc: 0.73759 | valid_auc: 0.73277 |  0:04:20s\n",
      "epoch 6  | loss: 0.57922 | train_auc: 0.73766 | valid_auc: 0.73232 |  0:05:03s\n",
      "epoch 7  | loss: 0.57892 | train_auc: 0.73876 | valid_auc: 0.73389 |  0:05:46s\n",
      "epoch 8  | loss: 0.57829 | train_auc: 0.73891 | valid_auc: 0.7337  |  0:06:29s\n",
      "epoch 9  | loss: 0.57797 | train_auc: 0.73988 | valid_auc: 0.7343  |  0:07:12s\n",
      "epoch 10 | loss: 0.57783 | train_auc: 0.74001 | valid_auc: 0.73511 |  0:07:56s\n",
      "epoch 11 | loss: 0.57766 | train_auc: 0.73846 | valid_auc: 0.73287 |  0:08:39s\n",
      "epoch 12 | loss: 0.57764 | train_auc: 0.73911 | valid_auc: 0.73386 |  0:09:22s\n",
      "epoch 13 | loss: 0.57779 | train_auc: 0.73844 | valid_auc: 0.73365 |  0:10:05s\n",
      "epoch 14 | loss: 0.57746 | train_auc: 0.73927 | valid_auc: 0.7331  |  0:17:48s\n",
      "epoch 15 | loss: 0.57686 | train_auc: 0.74027 | valid_auc: 0.73395 |  0:18:31s\n",
      "epoch 16 | loss: 0.57655 | train_auc: 0.74051 | valid_auc: 0.73513 |  0:19:13s\n",
      "epoch 17 | loss: 0.57631 | train_auc: 0.74153 | valid_auc: 0.73548 |  0:19:55s\n",
      "epoch 18 | loss: 0.57774 | train_auc: 0.74049 | valid_auc: 0.73499 |  0:20:38s\n",
      "epoch 19 | loss: 0.57705 | train_auc: 0.73986 | valid_auc: 0.73458 |  0:21:21s\n",
      "epoch 20 | loss: 0.57603 | train_auc: 0.74069 | valid_auc: 0.73422 |  0:22:03s\n",
      "epoch 21 | loss: 0.57631 | train_auc: 0.74192 | valid_auc: 0.73545 |  0:22:46s\n",
      "epoch 22 | loss: 0.57578 | train_auc: 0.74103 | valid_auc: 0.7347  |  0:23:29s\n",
      "epoch 23 | loss: 0.57551 | train_auc: 0.74198 | valid_auc: 0.73494 |  0:24:12s\n",
      "epoch 24 | loss: 0.57497 | train_auc: 0.74315 | valid_auc: 0.7352  |  0:24:56s\n",
      "epoch 25 | loss: 0.57547 | train_auc: 0.74062 | valid_auc: 0.73336 |  0:25:39s\n",
      "epoch 26 | loss: 0.57546 | train_auc: 0.74383 | valid_auc: 0.73485 |  0:26:22s\n",
      "epoch 27 | loss: 0.57499 | train_auc: 0.74299 | valid_auc: 0.73434 |  0:27:05s\n",
      "epoch 28 | loss: 0.57458 | train_auc: 0.74432 | valid_auc: 0.73528 |  0:27:49s\n",
      "epoch 29 | loss: 0.57457 | train_auc: 0.74147 | valid_auc: 0.73181 |  0:28:32s\n",
      "epoch 30 | loss: 0.57436 | train_auc: 0.74532 | valid_auc: 0.73419 |  0:29:14s\n",
      "epoch 31 | loss: 0.57341 | train_auc: 0.74474 | valid_auc: 0.73478 |  0:29:57s\n",
      "epoch 32 | loss: 0.5733  | train_auc: 0.74522 | valid_auc: 0.73328 |  0:30:40s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 17 and best_valid_auc = 0.73548\n",
      "\n",
      "최종 검증 AUC: 0.73548\n",
      "예측 완료. 'final_probs_tabnet'에 확률값이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import warnings\n",
    "\n",
    "# 경고 무시 및 시드 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# MPS 장치 설정 (Apple Silicon 가속)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(f\"✅ MPS 가속이 활성화되었습니다.\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(f\"⚠️ MPS를 찾을 수 없어 CPU로 실행합니다.\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "# [누수 방지 1, 2]: 학습과 테스트 데이터를 엄격히 분리하여 로드\n",
    "train_df = pd.read_csv(\"../Data/train.csv\")\n",
    "test_df = pd.read_csv(\"../Data/test.csv\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 전처리 함수 (파생변수 생성 - 로직만 공유)\n",
    "# ==========================================\n",
    "def preprocess_for_tabnet(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # 계산형 파생변수 (누수 없음)\n",
    "    df_copy['배아_생성_효율'] = df_copy['총 생성 배아 수'] / (df_copy['수집된 신선 난자 수'] + 1)\n",
    "    df_copy['배아_이식_비율'] = df_copy['이식된 배아 수'] / (df_copy['총 생성 배아 수'] + 1)\n",
    "    df_copy['배아_저장_비율'] = df_copy['저장된 배아 수'] / (df_copy['총 생성 배아 수'] + 1)\n",
    "    \n",
    "    # 문자열 결합 파생변수 (누수 없음)\n",
    "    df_copy['나이×Day5'] = df_copy['시술 당시 나이'].astype(str) + '_' + (df_copy['배아 이식 경과일'] == 5.0).astype(str)\n",
    "    \n",
    "    # ID 제거\n",
    "    if 'ID' in df_copy.columns:\n",
    "        df_copy = df_copy.drop(['ID'], axis=1)\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "# 전처리 적용\n",
    "train_processed = preprocess_for_tabnet(train_df)\n",
    "test_processed = preprocess_for_tabnet(test_df)\n",
    "\n",
    "# 타겟 분리\n",
    "target_col = '임신 성공 여부'\n",
    "X_train_full = train_processed.drop(columns=[target_col])\n",
    "y_train_full = train_processed[target_col].values\n",
    "X_test = test_processed.copy()\n",
    "\n",
    "# ==========================================\n",
    "# 3. 데이터 누수 방지 프로세스 (Imputation, Encoding, Scaling)\n",
    "# ==========================================\n",
    "\n",
    "# 컬럼 타입 자동 분류\n",
    "numeric_cols = X_train_full.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
    "categorical_cols = X_train_full.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# 3-1. 결측치 처리 (Numeric)\n",
    "# [누수 방지 6]: Test 데이터 결측치는 Train 데이터의 중앙값으로 채움\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "X_train_full[numeric_cols] = imputer_num.fit_transform(X_train_full[numeric_cols])\n",
    "X_test[numeric_cols] = imputer_num.transform(X_test[numeric_cols])\n",
    "\n",
    "# 3-2. 결측치 처리 (Categorical)\n",
    "# 범주형 결측치는 'Unknown'이라는 새로운 범주로 채움 (통계값 사용 아님)\n",
    "X_train_full[categorical_cols] = X_train_full[categorical_cols].fillna(\"Unknown\")\n",
    "X_test[categorical_cols] = X_test[categorical_cols].fillna(\"Unknown\")\n",
    "\n",
    "# 3-3. Label Encoding (Test Data Unseen Label 처리 포함)\n",
    "# [누수 방지 3, 5]: pd.get_dummies 금지, LabelEncoder는 Train에만 fit\n",
    "categorical_dims = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Train 데이터로만 학습\n",
    "    le.fit(X_train_full[col].astype(str))\n",
    "    \n",
    "    # Train 변환\n",
    "    X_train_full[col] = le.transform(X_train_full[col].astype(str))\n",
    "    \n",
    "    # Test 변환 (Safe Handling)\n",
    "    # Test에만 있는 새로운 값(Unseen)은 Train의 최빈값(Mode)으로 대체하여 누수 방지 및 에러 예방\n",
    "    test_values = X_test[col].astype(str).values\n",
    "    train_mode = le.transform([le.classes_[0]])[0] # Fallback용 (실제로는 최빈값 권장하나 여기선 0번 인덱스 활용)\n",
    "    \n",
    "    # Unseen Value Masking\n",
    "    known_labels = set(le.classes_)\n",
    "    test_values_safe = [x if x in known_labels else le.classes_[0] for x in test_values]\n",
    "    \n",
    "    X_test[col] = le.transform(test_values_safe)\n",
    "    \n",
    "    # 카테고리 수 저장 (TabNet 입력용)\n",
    "    categorical_dims[col] = len(le.classes_)\n",
    "\n",
    "# 3-4. Scaling (QuantileTransformer - 상관계수 낮추기 핵심)\n",
    "# [누수 방지 4]: Scaler는 Train 데이터로만 fit\n",
    "# StandardScaler 대신 QuantileTransformer를 사용하여 분포를 정규분포로 강제 변환\n",
    "# 이는 트리 모델(AutoGluon)과 딥러닝이 데이터를 보는 방식을 근본적으로 다르게 만듦\n",
    "scaler = QuantileTransformer(output_distribution='normal', random_state=SEED)\n",
    "X_train_full[numeric_cols] = scaler.fit_transform(X_train_full[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# 데이터 타입 변환 (메모리 최적화)\n",
    "X_train_full = X_train_full.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# ==========================================\n",
    "# 4. TabNet 준비\n",
    "# ==========================================\n",
    "\n",
    "# Categorical Feature Index 추출\n",
    "cat_idxs = [i for i, f in enumerate(X_train_full.columns) if f in categorical_cols]\n",
    "cat_dims = [categorical_dims[f] for f in categorical_cols]\n",
    "\n",
    "# 학습/검증 데이터 분리 (Stratified Split)\n",
    "# [누수 방지 1]: 모델 학습 중 검증을 위해 Train set 내에서 분리 (Test set 건드리지 않음)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full.values, y_train_full, \n",
    "    test_size=0.2, random_state=SEED, stratify=y_train_full\n",
    ")\n",
    "\n",
    "# 불균형 데이터 가중치 계산\n",
    "# 계산도 오직 분리된 y_train 만을 사용\n",
    "num_pos = (y_train == 1).sum()\n",
    "num_neg = (y_train == 0).sum()\n",
    "pos_weight = num_neg / num_pos\n",
    "class_weights = torch.tensor([1.0, pos_weight], dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"Positive Class Weight: {pos_weight:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. TabNet 모델 학습 (상관계수 파괴 설정)\n",
    "# ==========================================\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    n_d=64, n_a=64,             # [변경] 모델 용량을 키워 더 복잡한 패턴 학습 유도\n",
    "    n_steps=3,                  # [변경] 스텝 수를 줄여 트리 모델과 다른 의사결정 깊이 유도\n",
    "    gamma=1.5, \n",
    "    n_independent=2, \n",
    "    n_shared=2,\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=2,              # [변경] 임베딩 차원을 2로 늘려 범주 간 관계 학습 강화\n",
    "    optimizer_fn=torch.optim.AdamW, # [변경] AdamW 사용 (일반화 성능 향상)\n",
    "    optimizer_params=dict(lr=2e-2, weight_decay=1e-2),\n",
    "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='entmax',\n",
    "    device_name=device,         # MPS 설정\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Weighted Loss Function 정의\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "print(\"TabNet 학습 시작 (Quantile Transform 적용됨)...\")\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=100,             \n",
    "    patience=15,                # 참을성 조금 증가\n",
    "    batch_size=1024,            \n",
    "    virtual_batch_size=64,      # [변경] Ghost BN 사이즈를 줄여 노이즈 증가 -> 상관계수 감소 유도\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    loss_fn=loss_fn             \n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 6. Test Data 예측\n",
    "# ==========================================\n",
    "# [누수 방지 2]: Test Data는 학습에 전혀 관여하지 않고 예측에만 사용\n",
    "preds_proba = clf.predict_proba(X_test.values)\n",
    "final_probs_tabnet = preds_proba[:, 1]\n",
    "\n",
    "print(f\"\\n최종 검증 AUC: {clf.best_cost:.5f}\")\n",
    "print(\"예측 완료. 'final_probs_tabnet'에 확률값이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035e8d52-515b-4f51-9604-52e081c0c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료! 결과 저장됨: TN_0211_0040_submission.csv\n",
      "Best Validation AUC: 0.7354792411002122\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. 결과 추출\n",
    "# ==========================================\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime('%m%d_%H%M')\n",
    "file_name = f\"TN_{now}_submission.csv\"\n",
    "\n",
    "submission = pd.read_csv(\"../Data/sample_submission.csv\")\n",
    "submission['probability'] = final_probs_tabnet\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"완료! 결과 저장됨: {file_name}\")\n",
    "print(f\"Best Validation AUC: {clf.best_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d82ad-317b-4f97-aaa5-0baf66b35d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
