{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_models_out\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       4.15 GB / 16.00 GB (26.0%)\n",
      "Disk Space Avail:   190.67 GB / 460.43 GB (41.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "DyStack: Disabling memory safe fit mode in DyStack because GPUs were detected and num_gpus='auto' (GPUs cannot be used in memory safe fit mode). If you want to use memory safe fit mode, manually set `num_gpus=0`.\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    227867\n",
      "Train Data Columns: 67\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4646.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 415.95 MB (9.0% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 9.0% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 18 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['불임 원인 - 여성 요인']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])     :  1 | ['is_blastocyst']\n",
      "\t\t('category', []) :  1 | ['이식배아_구간']\n",
      "\t\t('float', [])    : 30 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])      : 16 | ['배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', ...]\n",
      "\t\t('object', [])   : 17 | ['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 18 | ['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', ...]\n",
      "\t\t('float', [])     : 27 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       :  2 | ['나이_순서', '나이_제곱']\n",
      "\t\t('int', ['bool']) : 18 | ['배란 자극 여부', '착상 전 유전 검사 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', ...]\n",
      "\t1.5s = Fit runtime\n",
      "\t65 features in original data used to generate 65 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 58.25 MB (1.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.7s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 299.36s of the 898.30s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=9.89%)\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=83286, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83286, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=83286, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83286, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 294.15s of the 893.09s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=10.67%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=83281, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83281, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=83281, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83281, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 292.16s of the 891.10s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 246 due to low memory. Expected memory usage reduced from 18.25% -> 15.0% of available memory...\n",
      "\t0.7275\t = Validation score   (roc_auc)\n",
      "\t7.9s\t = Training   runtime\n",
      "\t5.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 278.80s of the 877.73s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.5 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 232 due to low memory. Expected memory usage reduced from 19.36% -> 15.0% of available memory...\n",
      "\t0.7279\t = Validation score   (roc_auc)\n",
      "\t7.73s\t = Training   runtime\n",
      "\t4.81s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 265.89s of the 864.83s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.46% memory usage per fold, 48.91%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=24.46%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=83282, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=83282, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 263.88s of the 862.81s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.5 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 233 due to low memory. Expected memory usage reduced from 19.29% -> 15.0% of available memory...\n",
      "\t0.7299\t = Validation score   (roc_auc)\n",
      "\t6.13s\t = Training   runtime\n",
      "\t4.61s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 252.75s of the 851.69s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.4 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 227 due to low memory. Expected memory usage reduced from 19.79% -> 15.0% of available memory...\n",
      "\t0.7305\t = Validation score   (roc_auc)\n",
      "\t6.26s\t = Training   runtime\n",
      "\t4.56s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 241.58s of the 840.51s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.17% memory usage per fold, 76.67%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=19.17%)\n",
      "\t0.7375\t = Validation score   (roc_auc)\n",
      "\t165.89s\t = Training   runtime\n",
      "\t3.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 73.54s of the 672.48s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=14.57%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t64.76s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 6.94s of the 605.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=8.41%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2.09s of the 601.03s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=13.21%)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=83934, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83934, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=83934, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83934, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 0.04s of the 598.98s of remaining time.\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = -0.0s)\n",
      "\tTime limit exceeded... Skipping CatBoost_r177_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 598.79s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.2 GB\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L1': 0.409, 'RandomForestEntr_BAG_L1': 0.045, 'ExtraTreesEntr_BAG_L1': 0.045}\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t4.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 264.25s of the 594.69s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.07%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=83951, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83951, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=83951, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83951, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 262.10s of the 592.54s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=10.94%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=83975, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83975, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=83975, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=83975, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 259.95s of the 590.39s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/4.0 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 264 due to low memory. Expected memory usage reduced from 17.01% -> 15.0% of available memory...\n",
      "\t0.746\t = Validation score   (roc_auc)\n",
      "\t15.14s\t = Training   runtime\n",
      "\t5.62s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 238.73s of the 569.17s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 243 due to low memory. Expected memory usage reduced from 18.45% -> 15.0% of available memory...\n",
      "\t0.7458\t = Validation score   (roc_auc)\n",
      "\t16.73s\t = Training   runtime\n",
      "\t5.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 216.19s of the 546.63s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.63% memory usage per fold, 49.26%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=24.63%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=83982, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=83982, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 214.04s of the 544.48s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 240 due to low memory. Expected memory usage reduced from 18.68% -> 15.0% of available memory...\n",
      "\t0.747\t = Validation score   (roc_auc)\n",
      "\t6.54s\t = Training   runtime\n",
      "\t4.92s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 202.16s of the 532.59s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.4 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 229 due to low memory. Expected memory usage reduced from 19.58% -> 15.0% of available memory...\n",
      "\t0.7467\t = Validation score   (roc_auc)\n",
      "\t6.61s\t = Training   runtime\n",
      "\t4.73s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 190.38s of the 520.81s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 20.25% memory usage per fold, 40.50%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=20.25%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t118.36s\t = Training   runtime\n",
      "\t2.98s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 69.44s of the 399.87s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.62% memory usage per fold, 70.49%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=17.62%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t61.23s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 5.99s of the 336.42s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=9.56%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 327.69s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.5 GB\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.292, 'RandomForestGini_BAG_L2': 0.25, 'ExtraTreesEntr_BAG_L2': 0.25, 'RandomForestEntr_BAG_L2': 0.208}\n",
      "\t0.7496\t = Validation score   (roc_auc)\n",
      "\t3.99s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 215.72s of the 323.62s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.18%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=84702, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=84702, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=84702, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=84702, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 213.28s of the 321.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.27%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=84701, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=84701, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=84701, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=84701, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 211.19s of the 319.09s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.9 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 259 due to low memory. Expected memory usage reduced from 17.31% -> 15.0% of available memory...\n",
      "\t0.7435\t = Validation score   (roc_auc)\n",
      "\t14.46s\t = Training   runtime\n",
      "\t5.47s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 190.71s of the 298.62s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.5 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 233 due to low memory. Expected memory usage reduced from 19.26% -> 15.0% of available memory...\n",
      "\t0.7439\t = Validation score   (roc_auc)\n",
      "\t15.72s\t = Training   runtime\n",
      "\t5.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 169.35s of the 277.25s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 25.48% memory usage per fold, 50.97%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=25.48%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=84709, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=84709, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 167.04s of the 274.94s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 237 due to low memory. Expected memory usage reduced from 18.97% -> 15.0% of available memory...\n",
      "\t0.7434\t = Validation score   (roc_auc)\n",
      "\t6.54s\t = Training   runtime\n",
      "\t4.85s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 155.22s of the 263.12s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.4 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 230 due to low memory. Expected memory usage reduced from 19.51% -> 15.0% of available memory...\n",
      "\t0.7435\t = Validation score   (roc_auc)\n",
      "\t6.56s\t = Training   runtime\n",
      "\t4.8s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 143.41s of the 251.31s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 20.36% memory usage per fold, 40.73%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=20.36%)\n",
      "\t0.7503\t = Validation score   (roc_auc)\n",
      "\t99.33s\t = Training   runtime\n",
      "\t3.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 41.51s of the 149.41s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.32% memory usage per fold, 69.26%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=17.32%)\n",
      "\t0.7503\t = Validation score   (roc_auc)\n",
      "\t38.67s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 0.65s of the 108.56s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=9.73%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L3.\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 106.78s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.8 GB\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L3': 0.5, 'XGBoost_BAG_L3': 0.5}\n",
      "\t0.7508\t = Validation score   (roc_auc)\n",
      "\t4.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L4 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 102.71s of the 102.68s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.45%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=85311, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=85311, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=85311, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=85311, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 100.54s of the 100.50s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.17%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=85331, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=85331, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=85331, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=85331, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: RandomForestGini_BAG_L4 ... Training model for up to 98.41s of the 98.38s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.9 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 260 due to low memory. Expected memory usage reduced from 17.26% -> 15.0% of available memory...\n",
      "\t0.7447\t = Validation score   (roc_auc)\n",
      "\t14.73s\t = Training   runtime\n",
      "\t5.56s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L4 ... Training model for up to 77.63s of the 77.59s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.5 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 231 due to low memory. Expected memory usage reduced from 19.43% -> 15.0% of available memory...\n",
      "\t0.7454\t = Validation score   (roc_auc)\n",
      "\t16.2s\t = Training   runtime\n",
      "\t5.46s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 55.45s of the 55.41s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.46% memory usage per fold, 48.91%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=24.46%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=85339, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=85339, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L4 ... Training model for up to 51.66s of the 51.62s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.5 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 231 due to low memory. Expected memory usage reduced from 19.43% -> 15.0% of available memory...\n",
      "\t0.7453\t = Validation score   (roc_auc)\n",
      "\t6.6s\t = Training   runtime\n",
      "\t5.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L4 ... Training model for up to 39.61s of the 39.58s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.5 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 231 due to low memory. Expected memory usage reduced from 19.44% -> 15.0% of available memory...\n",
      "\t0.7452\t = Validation score   (roc_auc)\n",
      "\t6.83s\t = Training   runtime\n",
      "\t5.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 27.30s of the 27.26s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.99% memory usage per fold, 79.97%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=19.99%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L4.\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 18.54s of the 18.50s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.92% memory usage per fold, 71.68%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=17.92%)\n",
      "\t0.7503\t = Validation score   (roc_auc)\n",
      "\t20.28s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.00s of the -3.79s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/3.5 GB\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L3': 0.36, 'XGBoost_BAG_L3': 0.32, 'XGBoost_BAG_L4': 0.16, 'RandomForestEntr_BAG_L4': 0.08, 'RandomForestEntr_BAG_L2': 0.04, 'ExtraTreesEntr_BAG_L2': 0.04}\n",
      "\t0.7509\t = Validation score   (roc_auc)\n",
      "\t15.89s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 919.76s ... Best model: WeightedEnsemble_L5 | Estimated inference throughput: 1802.1 rows/s (45574 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.9s\t = Training   runtime\n",
      "\t5.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.73s\t = Training   runtime\n",
      "\t4.81s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t6.13s\t = Training   runtime\n",
      "\t4.61s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t6.26s\t = Training   runtime\n",
      "\t4.56s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.6/3.2 GB\n",
      "\tStopping at the best epoch learned earlier - 2.\n",
      "\t21.77s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/xgboost/sklearn.py:1118: UserWarning: [13:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/context.cc:207: Device is changed from GPU to CPU as we couldn't find any available GPU on the system.\n",
      "  self.get_booster().save_model(fname)\n",
      "\t1.74s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L1': 0.409, 'RandomForestEntr_BAG_L1': 0.045, 'ExtraTreesEntr_BAG_L1': 0.045}\n",
      "\t4.03s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t15.14s\t = Training   runtime\n",
      "\t5.62s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t16.73s\t = Training   runtime\n",
      "\t5.38s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t6.54s\t = Training   runtime\n",
      "\t4.92s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t6.61s\t = Training   runtime\n",
      "\t4.73s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.6/3.3 GB\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t14.76s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1\n",
      "\t1.79s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.292, 'RandomForestGini_BAG_L2': 0.25, 'ExtraTreesEntr_BAG_L2': 0.25, 'RandomForestEntr_BAG_L2': 0.208}\n",
      "\t3.99s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t14.46s\t = Training   runtime\n",
      "\t5.47s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t15.72s\t = Training   runtime\n",
      "\t5.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t6.54s\t = Training   runtime\n",
      "\t4.85s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t6.56s\t = Training   runtime\n",
      "\t4.8s\t = Validation runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L3_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.6/3.3 GB\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t14.74s\t = Training   runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L3_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1\n",
      "\t1.71s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L4_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L3': 0.5, 'XGBoost_BAG_L3': 0.5}\n",
      "\t4.03s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L4_FULL | Skipping fit via cloning parent ...\n",
      "\t14.73s\t = Training   runtime\n",
      "\t5.56s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L4_FULL | Skipping fit via cloning parent ...\n",
      "\t16.2s\t = Training   runtime\n",
      "\t5.46s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L4_FULL | Skipping fit via cloning parent ...\n",
      "\t6.6s\t = Training   runtime\n",
      "\t5.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L4_FULL | Skipping fit via cloning parent ...\n",
      "\t6.83s\t = Training   runtime\n",
      "\t5.06s\t = Validation runtime\n",
      "Fitting 1 L4 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L4_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1\n",
      "\t1.58s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L5_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L3': 0.36, 'XGBoost_BAG_L3': 0.32, 'XGBoost_BAG_L4': 0.16, 'RandomForestEntr_BAG_L4': 0.08, 'RandomForestEntr_BAG_L2': 0.04, 'ExtraTreesEntr_BAG_L2': 0.04}\n",
      "\t15.89s\t = Training   runtime\n",
      "Refit complete, total runtime = 66.65s ... Best model: \"WeightedEnsemble_L5\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2_FULL       0.742936        NaN     roc_auc        0.965429            NaN   41.523581                 0.002749                     NaN           4.031799            2       True         34\n",
      "1            WeightedEnsemble_L2       0.742839   0.739289     roc_auc        2.505626      13.409728  248.663135                 0.003204                0.026789           4.031799            2       True          7\n",
      "2         NeuralNetFastAI_BAG_L2       0.742823   0.738636     roc_auc        4.462109      25.991254  377.030443                 1.202016                2.977685         118.363938            2       True         12\n",
      "3    NeuralNetFastAI_BAG_L2_FULL       0.742679        NaN     roc_auc        1.884811            NaN   66.284201                 0.162339                     NaN          14.757250            2       True         39\n",
      "4                 XGBoost_BAG_L2       0.742635   0.738621     roc_auc        3.763276      23.846110  319.892578                 0.503183                0.832542          61.226073            2       True         13\n",
      "5            XGBoost_BAG_L2_FULL       0.742392        NaN     roc_auc        1.807478            NaN   53.312846                 0.085006                     NaN           1.785895            2       True         40\n",
      "6            XGBoost_BAG_L1_FULL       0.742176        NaN     roc_auc        0.077887            NaN    1.736708                 0.077887                     NaN           1.736708            1       True         33\n",
      "7                 XGBoost_BAG_L1       0.742134   0.738230     roc_auc        0.544347       1.008451   64.760018                 0.544347                1.008451          64.760018            1       True          6\n",
      "8         NeuralNetFastAI_BAG_L1       0.741677   0.737498     roc_auc        1.201178       3.009315  165.885232                 1.201178                3.009315         165.885232            1       True          5\n",
      "9    NeuralNetFastAI_BAG_L1_FULL       0.741441        NaN     roc_auc        0.175605            NaN   21.768988                 0.175605                     NaN          21.768988            1       True         32\n",
      "10      WeightedEnsemble_L3_FULL       0.738207        NaN     roc_auc        3.244340            NaN  100.530861                 0.002596                     NaN           3.988458            3       True         41\n",
      "11           WeightedEnsemble_L3       0.738072   0.749640     roc_auc        5.000405      43.693998  307.670415                 0.002848                0.025980           3.988458            3       True         14\n",
      "12    ExtraTreesEntr_BAG_L2_FULL       0.737738        NaN     roc_auc        2.076232            NaN   58.132645                 0.353760                4.730380           6.605694            2       True         38\n",
      "13         ExtraTreesEntr_BAG_L2       0.737690   0.746661     roc_auc        3.630565      27.743948  265.272199                 0.370472                4.730380           6.605694            2       True         11\n",
      "14  RandomForestEntr_BAG_L2_FULL       0.736988        NaN     roc_auc        2.096361            NaN   68.253515                 0.373889                5.383960          16.726564            2       True         36\n",
      "15    ExtraTreesGini_BAG_L2_FULL       0.736924        NaN     roc_auc        2.088448            NaN   58.068515                 0.365976                4.921234           6.541564            2       True         37\n",
      "16       RandomForestEntr_BAG_L2       0.736876   0.745810     roc_auc        3.727454      28.397529  275.393069                 0.467361                5.383960          16.726564            2       True          9\n",
      "17         ExtraTreesGini_BAG_L2       0.736850   0.747012     roc_auc        3.655700      27.934802  265.208069                 0.395607                4.921234           6.541564            2       True         10\n",
      "18    ExtraTreesGini_BAG_L1_FULL       0.735743        NaN     roc_auc        0.338657       4.605569    6.132717                 0.338657                4.605569           6.132717            1       True         30\n",
      "19         ExtraTreesGini_BAG_L1       0.735743   0.729943     roc_auc        0.374013       4.605569    6.132717                 0.374013                4.605569           6.132717            1       True          3\n",
      "20  RandomForestGini_BAG_L2_FULL       0.735500        NaN     roc_auc        2.148118            NaN   66.668581                 0.425647                5.618875          15.141630            2       True         35\n",
      "21       RandomForestGini_BAG_L2       0.735181   0.746011     roc_auc        3.764117      28.632444  273.808135                 0.504024                5.618875          15.141630            2       True          8\n",
      "22         ExtraTreesEntr_BAG_L3       0.735159   0.743539     roc_auc        7.061702      52.274420  489.836610                 0.358946                4.796176           6.564642            3       True         18\n",
      "23    ExtraTreesEntr_BAG_L1_FULL       0.735017        NaN     roc_auc        0.345189       4.557297    6.259805                 0.345189                4.557297           6.259805            1       True         31\n",
      "24         ExtraTreesEntr_BAG_L1       0.735017   0.730546     roc_auc        0.376467       4.557297    6.259805                 0.376467                4.557297           6.259805            1       True          4\n",
      "25         ExtraTreesGini_BAG_L3       0.734983   0.743406     roc_auc        7.073598      52.330419  489.807157                 0.370842                4.852174           6.535189            3       True         17\n",
      "26    ExtraTreesEntr_BAG_L3_FULL       0.734914        NaN     roc_auc        3.825161            NaN  119.650191                 0.336072                4.796176           6.564642            3       True         45\n",
      "27           WeightedEnsemble_L5       0.734877   0.750910     roc_auc       10.793250      77.635306  716.925642                 0.001832                0.028555          15.887918            5       True         27\n",
      "28           WeightedEnsemble_L4       0.734646   0.750836     roc_auc        8.361046      51.269732  625.302738                 0.001418                0.026574           4.027993            4       True         21\n",
      "29    ExtraTreesGini_BAG_L3_FULL       0.734622        NaN     roc_auc        3.827033            NaN  119.620737                 0.337944                4.852174           6.535189            3       True         44\n",
      "30        NeuralNetFastAI_BAG_L3       0.734500   0.750321     roc_auc        7.878146      50.501626  582.600579                 1.175390                3.023381          99.328611            3       True         19\n",
      "31                XGBoost_BAG_L3       0.734481   0.750328     roc_auc        7.184238      48.219777  521.946134                 0.481482                0.741532          38.674166            3       True         20\n",
      "32      WeightedEnsemble_L5_FULL       0.734450        NaN     roc_auc        5.770030            NaN  206.485297                 0.004119                     NaN          15.887918            5       True         54\n",
      "33      WeightedEnsemble_L4_FULL       0.734118        NaN     roc_auc        3.847800            NaN  133.559892                 0.001380                     NaN           4.027993            4       True         48\n",
      "34           XGBoost_BAG_L3_FULL       0.733993        NaN     roc_auc        3.672974            NaN  114.795506                 0.183885                     NaN           1.709958            3       True         47\n",
      "35                XGBoost_BAG_L4       0.733807   0.750257     roc_auc       10.405149      72.144915  684.840802                 0.515664                0.609535          20.281961            4       True         26\n",
      "36   NeuralNetFastAI_BAG_L3_FULL       0.733732        NaN     roc_auc        3.662535            NaN  127.821941                 0.173446                     NaN          14.736392            3       True         46\n",
      "37         ExtraTreesEntr_BAG_L4       0.733392   0.745243     roc_auc       10.262569      76.592134  671.390249                 0.373084                5.056754           6.831408            4       True         25\n",
      "38    ExtraTreesEntr_BAG_L4_FULL       0.733073        NaN     roc_auc        5.685543            NaN  179.647403                 0.378829                5.056754           6.831408            4       True         52\n",
      "39         ExtraTreesGini_BAG_L4       0.733052   0.745281     roc_auc       10.239032      76.532906  671.154470                 0.349547                4.997526           6.595629            4       True         24\n",
      "40           XGBoost_BAG_L4_FULL       0.733000        NaN     roc_auc        5.379791            NaN  174.400458                 0.073076                     NaN           1.584463            4       True         53\n",
      "41    ExtraTreesGini_BAG_L4_FULL       0.732626        NaN     roc_auc        5.660080            NaN  179.411624                 0.353366                4.997526           6.595629            4       True         51\n",
      "42  RandomForestEntr_BAG_L1_FULL       0.732585        NaN     roc_auc        0.363999       4.807877    7.726281                 0.363999                4.807877           7.726281            1       True         29\n",
      "43       RandomForestEntr_BAG_L1       0.732585   0.727881     roc_auc        0.380430       4.807877    7.726281                 0.380430                4.807877           7.726281            1       True          2\n",
      "44       RandomForestGini_BAG_L1       0.732539   0.727488     roc_auc        0.383658       5.025060    7.902452                 0.383658                5.025060           7.902452            1       True          1\n",
      "45  RandomForestGini_BAG_L1_FULL       0.732539        NaN     roc_auc        0.421135       5.025060    7.902452                 0.421135                5.025060           7.902452            1       True         28\n",
      "46       RandomForestGini_BAG_L4       0.731244   0.744664     roc_auc       10.300309      77.098332  679.287920                 0.410824                5.562952          14.729079            4       True         22\n",
      "47       RandomForestEntr_BAG_L4       0.730782   0.745394     roc_auc       10.275754      76.997216  680.755763                 0.386269                5.461836          16.196922            4       True         23\n",
      "48  RandomForestEntr_BAG_L4_FULL       0.730695        NaN     roc_auc        5.692835            NaN  189.012917                 0.386121                5.461836          16.196922            4       True         50\n",
      "49       RandomForestEntr_BAG_L3       0.730532   0.743922     roc_auc        7.084912      52.654575  498.994703                 0.382156                5.176330          15.722735            3       True         16\n",
      "50       RandomForestGini_BAG_L3       0.730456   0.743473     roc_auc        7.120669      52.945788  497.733498                 0.417913                5.467543          14.461530            3       True         15\n",
      "51  RandomForestGini_BAG_L4_FULL       0.730184        NaN     roc_auc        5.718816            NaN  187.545074                 0.412101                5.562952          14.729079            4       True         49\n",
      "52  RandomForestEntr_BAG_L3_FULL       0.729880        NaN     roc_auc        3.865475            NaN  128.808283                 0.376386                5.176330          15.722735            3       True         43\n",
      "53  RandomForestGini_BAG_L3_FULL       0.729401        NaN     roc_auc        3.898982            NaN  127.547079                 0.409893                5.467543          14.461530            3       True         42\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t1006s\t = DyStack   runtime |\t2594s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 2594s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out\"\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 67\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4728.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 503.21 MB (10.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 10.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 18 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['불임 원인 - 여성 요인']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])     :  1 | ['is_blastocyst']\n",
      "\t\t('category', []) :  1 | ['이식배아_구간']\n",
      "\t\t('float', [])    : 30 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])      : 16 | ['배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', ...]\n",
      "\t\t('object', [])   : 17 | ['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 18 | ['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', ...]\n",
      "\t\t('float', [])     : 27 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       :  2 | ['나이_순서', '나이_제곱']\n",
      "\t\t('int', ['bool']) : 18 | ['배란 자극 여부', '착상 전 유전 검사 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', ...]\n",
      "\t1.8s = Fit runtime\n",
      "\t65 features in original data used to generate 65 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 65.53 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2591.51s of the 2591.51s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.55%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=85895, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=85895, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=85895, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=85895, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2588.39s of the 2588.39s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=12.17%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=85896, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=85896, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=85896, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=85896, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2586.30s of the 2586.30s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/3.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 242 due to low memory. Expected memory usage reduced from 18.58% -> 15.0% of available memory...\n",
      "\t0.7292\t = Validation score   (roc_auc)\n",
      "\t8.45s\t = Training   runtime\n",
      "\t5.37s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2572.11s of the 2572.11s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/3.4 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 230 due to low memory. Expected memory usage reduced from 19.52% -> 15.0% of available memory...\n",
      "\t0.7299\t = Validation score   (roc_auc)\n",
      "\t8.7s\t = Training   runtime\n",
      "\t5.24s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2557.81s of the 2557.80s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.11% memory usage per fold, 48.21%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=24.11%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=85901, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=85901, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2555.78s of the 2555.78s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/3.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 246 due to low memory. Expected memory usage reduced from 18.27% -> 15.0% of available memory...\n",
      "\t0.7314\t = Validation score   (roc_auc)\n",
      "\t7.28s\t = Training   runtime\n",
      "\t5.34s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2542.79s of the 2542.79s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/3.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 241 due to low memory. Expected memory usage reduced from 18.64% -> 15.0% of available memory...\n",
      "\t0.7318\t = Validation score   (roc_auc)\n",
      "\t7.43s\t = Training   runtime\n",
      "\t5.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2529.69s of the 2529.69s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.75% memory usage per fold, 79.01%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=19.75%)\n",
      "\t0.737\t = Validation score   (roc_auc)\n",
      "\t1000.52s\t = Training   runtime\n",
      "\t2.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1526.80s of the 1526.80s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 20.33% memory usage per fold, 40.67%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=20.33%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t115.69s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1408.65s of the 1408.64s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=10.54%)\n",
      "\t0.7373\t = Validation score   (roc_auc)\n",
      "\t1127.78s\t = Training   runtime\n",
      "\t4.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 277.98s of the 277.98s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.48% memory usage per fold, 69.90%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=17.48%)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=90547, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=90547, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=90547, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=90547, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 274.89s of the 274.88s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.14% memory usage per fold, 48.29%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=24.14%)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=90556, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=90556, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 273.05s of the 273.05s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.58%)\n",
      "\t0.7346\t = Validation score   (roc_auc)\n",
      "\t211.44s\t = Training   runtime\n",
      "\t4.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 59.41s of the 59.40s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.47% memory usage per fold, 65.87%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=16.47%)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=90991, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=90991, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=90991, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=90991, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 56.21s of the 56.21s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.89% memory usage per fold, 43.78%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=21.89%)\n",
      "\t0.7253\t = Validation score   (roc_auc)\n",
      "\t82.56s\t = Training   runtime\n",
      "\t4.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -28.54s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/2.9 GB\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.44, 'NeuralNetTorch_BAG_L1': 0.24, 'NeuralNetFastAI_BAG_L1': 0.2, 'RandomForestGini_BAG_L1': 0.04, 'RandomForestEntr_BAG_L1': 0.04, 'NeuralNetFastAI_r191_BAG_L1': 0.04}\n",
      "\t0.74\t = Validation score   (roc_auc)\n",
      "\t7.11s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2629.36s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3663.3 rows/s (51271 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t8.45s\t = Training   runtime\n",
      "\t5.37s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t8.7s\t = Training   runtime\n",
      "\t5.24s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.28s\t = Training   runtime\n",
      "\t5.34s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.43s\t = Training   runtime\n",
      "\t5.3s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.6/2.7 GB\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t97.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1\n",
      "\t2.57s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.3/3.0 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t142.2s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.3/3.5 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t57.75s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.6/3.6 GB\n",
      "\tStopping at the best epoch learned earlier - 0.\n",
      "\t15.17s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.44, 'NeuralNetTorch_BAG_L1': 0.24, 'NeuralNetFastAI_BAG_L1': 0.2, 'RandomForestGini_BAG_L1': 0.04, 'RandomForestEntr_BAG_L1': 0.04, 'NeuralNetFastAI_r191_BAG_L1': 0.04}\n",
      "\t7.11s\t = Training   runtime\n",
      "Refit complete, total runtime = 318.17s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. 파생변수 생성\n",
    "# ==========================================\n",
    "\n",
    "def derive_features(df):\n",
    "    \n",
    "    df['is_blastocyst'] = df['특정 시술 유형'].str.contains('BLASTOCYST', case=False, na=False)\n",
    "    \n",
    "    elderly_categories = ['만35-37세', '만38-39세', '만40-42세', '만43-44세', '만45-50세']\n",
    "    df['고령 여부'] = df['시술 당시 나이'].isin(elderly_categories).astype(int)\n",
    "\n",
    "    age_order = {'만18-34세': 1, '만35-37세': 2, '만38-39세': 3, '만40-42세': 4, '만43-44세': 5, '만45-50세': 6, '알 수 없음': 0}\n",
    "    df['나이_순서'] = df['시술 당시 나이'].map(age_order)\n",
    "    df['나이_제곱'] = df['나이_순서'] ** 2\n",
    "    df['나이x배아'] = df['나이_순서'] * df['이식된 배아 수']\n",
    "    # '나이가 적으면서 배아가 많은 그룹' vs '나이가 많으면서 배아가 적은 그룹' 강조\n",
    "    df['연령별 배아 효율'] = df['이식된 배아 수'] / (df['나이_순서'] + 1e-5)\n",
    "\n",
    "    df['배아 발달 기간'] = df['배아 이식 경과일'] - df['난자 혼합 경과일']\n",
    "    df['배아 생성 효율'] = df['저장된 배아 수'] / (df['저장된 신선 난자 수'] + 1e-6)\n",
    "    df['이식 비중'] = df['이식된 배아 수'] / (df['이식된 배아 수'] + df['저장된 배아 수'] + 1e-5)\n",
    "\n",
    "    df['이식배아_구간'] = pd.cut(\n",
    "    df['이식된 배아 수'].fillna(0),\n",
    "    bins=[-float('inf'), 0, 2, float('inf')],\n",
    "    labels=['0개', '1-2개', '3개 이상']\n",
    "    )\n",
    "\n",
    "    def clean_treatment(text): \n",
    "        text = str(text).upper()\n",
    "        if 'ICSI' in text:\n",
    "            return 'ICSI'\n",
    "        if 'IVF' in text:\n",
    "            return 'IVF'\n",
    "        if 'IUI' in text:\n",
    "            return 'IUI'\n",
    "        return 'Other'\n",
    "\n",
    "    df['시술유형_정제'] = df['특정 시술 유형'].apply(clean_treatment)\n",
    "    \n",
    "    drop_cols = ['특정 시술 유형', '시술 유형', 'DI 출산 횟수', '대리모 여부', \n",
    "                 '난자 기증자 나이', '저장된 신선 난자 수', 'PGD 시술 여부', '난자 혼합 경과일',\n",
    "                 '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '불임 원인 - 자궁경부 문제', '불임 원인 - 정자 농도']\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = derive_features(train_df)\n",
    "test_df = derive_features(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 모델 학습 설정\n",
    "# ==========================================\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target, \n",
    "    eval_metric='roc_auc',\n",
    "    path='ag_models_out',\n",
    ").fit(\n",
    "    train_data=train_df,\n",
    "    time_limit=3600,\n",
    "    presets='best_quality',\n",
    "    ag_args_fit={'num_gpus': 1},\n",
    "    num_bag_folds=5,\n",
    "    num_stack_levels=3,\n",
    "    refit_full=True\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\n",
    "# ==========================================\n",
    "\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "final_probs = pred_probs.iloc[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c7c3f8-495c-4d28-9be8-c868762a4046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.740018</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>22.505892</td>\n",
       "      <td>2350.820244</td>\n",
       "      <td>0.030680</td>\n",
       "      <td>7.112056</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.738821</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.607768</td>\n",
       "      <td>115.689540</td>\n",
       "      <td>1.607768</td>\n",
       "      <td>115.689540</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.737322</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.082671</td>\n",
       "      <td>1127.784631</td>\n",
       "      <td>4.082671</td>\n",
       "      <td>1127.784631</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.737040</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2.012486</td>\n",
       "      <td>1000.515935</td>\n",
       "      <td>2.012486</td>\n",
       "      <td>1000.515935</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
       "      <td>0.734639</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.171800</td>\n",
       "      <td>211.437797</td>\n",
       "      <td>4.171800</td>\n",
       "      <td>211.437797</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.731827</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.295477</td>\n",
       "      <td>7.425525</td>\n",
       "      <td>5.295477</td>\n",
       "      <td>7.425525</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.731438</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.337596</td>\n",
       "      <td>7.283738</td>\n",
       "      <td>5.337596</td>\n",
       "      <td>7.283738</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.729893</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.236917</td>\n",
       "      <td>8.703051</td>\n",
       "      <td>5.236917</td>\n",
       "      <td>8.703051</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.729204</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.370015</td>\n",
       "      <td>8.452349</td>\n",
       "      <td>5.370015</td>\n",
       "      <td>8.452349</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
       "      <td>0.725286</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.165354</td>\n",
       "      <td>82.562682</td>\n",
       "      <td>4.165354</td>\n",
       "      <td>82.562682</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.236917</td>\n",
       "      <td>8.703051</td>\n",
       "      <td>5.236917</td>\n",
       "      <td>8.703051</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.295477</td>\n",
       "      <td>7.425525</td>\n",
       "      <td>5.295477</td>\n",
       "      <td>7.425525</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesGini_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.337596</td>\n",
       "      <td>7.283738</td>\n",
       "      <td>5.337596</td>\n",
       "      <td>7.283738</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestGini_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.370015</td>\n",
       "      <td>8.452349</td>\n",
       "      <td>5.370015</td>\n",
       "      <td>8.452349</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.566758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.566758</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281.307246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.112056</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeuralNetTorch_r79_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.754873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.754873</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.204506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.204506</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.168928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.168928</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.099598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.099598</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model  score_val eval_metric  pred_time_val  \\\n",
       "0                WeightedEnsemble_L2   0.740018     roc_auc      22.505892   \n",
       "1                     XGBoost_BAG_L1   0.738821     roc_auc       1.607768   \n",
       "2              NeuralNetTorch_BAG_L1   0.737322     roc_auc       4.082671   \n",
       "3             NeuralNetFastAI_BAG_L1   0.737040     roc_auc       2.012486   \n",
       "4          NeuralNetTorch_r79_BAG_L1   0.734639     roc_auc       4.171800   \n",
       "5              ExtraTreesEntr_BAG_L1   0.731827     roc_auc       5.295477   \n",
       "6              ExtraTreesGini_BAG_L1   0.731438     roc_auc       5.337596   \n",
       "7            RandomForestEntr_BAG_L1   0.729893     roc_auc       5.236917   \n",
       "8            RandomForestGini_BAG_L1   0.729204     roc_auc       5.370015   \n",
       "9        NeuralNetFastAI_r191_BAG_L1   0.725286     roc_auc       4.165354   \n",
       "10      RandomForestEntr_BAG_L1_FULL        NaN     roc_auc       5.236917   \n",
       "11        ExtraTreesEntr_BAG_L1_FULL        NaN     roc_auc       5.295477   \n",
       "12        ExtraTreesGini_BAG_L1_FULL        NaN     roc_auc       5.337596   \n",
       "13      RandomForestGini_BAG_L1_FULL        NaN     roc_auc       5.370015   \n",
       "14               XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "15          WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN   \n",
       "16    NeuralNetTorch_r79_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "17        NeuralNetTorch_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "18  NeuralNetFastAI_r191_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "19       NeuralNetFastAI_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "\n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   2350.820244                0.030680           7.112056            2   \n",
       "1    115.689540                1.607768         115.689540            1   \n",
       "2   1127.784631                4.082671        1127.784631            1   \n",
       "3   1000.515935                2.012486        1000.515935            1   \n",
       "4    211.437797                4.171800         211.437797            1   \n",
       "5      7.425525                5.295477           7.425525            1   \n",
       "6      7.283738                5.337596           7.283738            1   \n",
       "7      8.703051                5.236917           8.703051            1   \n",
       "8      8.452349                5.370015           8.452349            1   \n",
       "9     82.562682                4.165354          82.562682            1   \n",
       "10     8.703051                5.236917           8.703051            1   \n",
       "11     7.425525                5.295477           7.425525            1   \n",
       "12     7.283738                5.337596           7.283738            1   \n",
       "13     8.452349                5.370015           8.452349            1   \n",
       "14     2.566758                     NaN           2.566758            1   \n",
       "15   281.307246                     NaN           7.112056            2   \n",
       "16    57.754873                     NaN          57.754873            1   \n",
       "17   142.204506                     NaN         142.204506            1   \n",
       "18    15.168928                     NaN          15.168928            1   \n",
       "19    97.099598                     NaN          97.099598            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         10  \n",
       "1        True          6  \n",
       "2        True          7  \n",
       "3        True          5  \n",
       "4        True          8  \n",
       "5        True          4  \n",
       "6        True          3  \n",
       "7        True          2  \n",
       "8        True          1  \n",
       "9        True          9  \n",
       "10       True         12  \n",
       "11       True         14  \n",
       "12       True         13  \n",
       "13       True         11  \n",
       "14       True         16  \n",
       "15       True         20  \n",
       "16       True         18  \n",
       "17       True         17  \n",
       "18       True         19  \n",
       "19       True         15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. 리더보드 (오름차순 정렬) ---\n",
    "lb = predictor.leaderboard(silent=True)\n",
    "display(lb.sort_values(by='score_val', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ID', '불임 원인 - 여성 요인']\n",
      "Computing feature importance via permutation shuffling for 65 features using 5000 rows with 5 shuffle sets...\n",
      "\t687.09s\t= Expected runtime (137.42s per shuffle set)\n",
      "\t353.78s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>혼합된 난자 수</th>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>3.177682e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.007922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>고령 여부</th>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1.200663e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.002345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파트너 정자와 혼합된 난자 수</th>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>1.811763e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.006279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>배아 생성 효율</th>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>3.663121e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총 시술 횟수</th>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>4.172608e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.004811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수집된 신선 난자 수</th>\n",
       "      <td>0.010548</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>6.727227e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>0.009490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불명확 불임 원인</th>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>8.884317e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>나이_제곱</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>1.385145e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입에서 생성된 배아 수</th>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>1.762981e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.005748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입 후 저장된 배아 수</th>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>1.891189e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술유형_정제</th>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1.910074e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.002457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IVF 시술 횟수</th>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1.996064e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>0.006633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>해동된 배아 수</th>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>2.082257e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.001262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술 당시 나이</th>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>2.233874e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>0.003541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>정자 기증자 나이</th>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>3.258965e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저장된 배아 수</th>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>3.279925e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>클리닉 내 총 시술 횟수</th>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>3.433683e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불임 원인 - 배란 장애</th>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>3.613170e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>배아 이식 경과일</th>\n",
       "      <td>0.012952</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>3.739622e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.010955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입 배아 이식 수</th>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.801052e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.002246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입된 난자 수</th>\n",
       "      <td>0.006140</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>4.458489e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이식 비중</th>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>7.012960e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.004154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_blastocyst</th>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>7.738542e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IVF 출산 횟수</th>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>7.762749e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>배아 발달 기간</th>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>8.890407e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.007328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총 생성 배아 수</th>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>9.362324e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019431</td>\n",
       "      <td>0.013114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술 시기 코드</th>\n",
       "      <td>0.009739</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>9.588293e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.007837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>나이x배아</th>\n",
       "      <td>0.034878</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>1.049898e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041845</td>\n",
       "      <td>0.027911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기증자 정자와 혼합된 난자 수</th>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1.101011e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불임 원인 - 자궁내막증</th>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>1.273793e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance    stddev       p_value  n  p99_high   p99_low\n",
       "혼합된 난자 수            0.008310  0.000189  3.177682e-08  5  0.008699  0.007922\n",
       "고령 여부               0.002509  0.000079  1.200663e-07  5  0.002672  0.002345\n",
       "파트너 정자와 혼합된 난자 수    0.006767  0.000237  1.811763e-07  5  0.007256  0.006279\n",
       "배아 생성 효율            0.003149  0.000132  3.663121e-07  5  0.003420  0.002878\n",
       "총 시술 횟수             0.005280  0.000228  4.172608e-07  5  0.005750  0.004811\n",
       "수집된 신선 난자 수         0.010548  0.000514  6.727227e-07  5  0.011606  0.009490\n",
       "불명확 불임 원인           0.002006  0.000105  8.884317e-07  5  0.002222  0.001790\n",
       "나이_제곱               0.003484  0.000203  1.385145e-06  5  0.003903  0.003066\n",
       "미세주입에서 생성된 배아 수     0.006589  0.000408  1.762981e-06  5  0.007430  0.005748\n",
       "미세주입 후 저장된 배아 수     0.002159  0.000136  1.891189e-06  5  0.002440  0.001879\n",
       "시술유형_정제             0.002825  0.000179  1.910074e-06  5  0.003193  0.002457\n",
       "IVF 시술 횟수           0.007639  0.000489  1.996064e-06  5  0.008645  0.006633\n",
       "해동된 배아 수            0.001455  0.000094  2.082257e-06  5  0.001649  0.001262\n",
       "시술 당시 나이            0.004096  0.000269  2.233874e-06  5  0.004650  0.003541\n",
       "정자 기증자 나이           0.001954  0.000141  3.258965e-06  5  0.002245  0.001663\n",
       "저장된 배아 수            0.003758  0.000272  3.279925e-06  5  0.004318  0.003197\n",
       "클리닉 내 총 시술 횟수       0.007773  0.000570  3.433683e-06  5  0.008945  0.006600\n",
       "불임 원인 - 배란 장애       0.001671  0.000124  3.613170e-06  5  0.001926  0.001415\n",
       "배아 이식 경과일           0.012952  0.000970  3.739622e-06  5  0.014948  0.010955\n",
       "미세주입 배아 이식 수        0.002657  0.000200  3.801052e-06  5  0.003068  0.002246\n",
       "미세주입된 난자 수          0.006140  0.000480  4.458489e-06  5  0.007129  0.005151\n",
       "이식 비중               0.005069  0.000444  7.012960e-06  5  0.005984  0.004154\n",
       "is_blastocyst       0.000250  0.000022  7.738542e-06  5  0.000296  0.000203\n",
       "IVF 출산 횟수           0.001558  0.000140  7.762749e-06  5  0.001847  0.001270\n",
       "배아 발달 기간            0.009065  0.000843  8.890407e-06  5  0.010802  0.007328\n",
       "총 생성 배아 수           0.016273  0.001534  9.362324e-06  5  0.019431  0.013114\n",
       "시술 시기 코드            0.009739  0.000924  9.588293e-06  5  0.011640  0.007837\n",
       "나이x배아               0.034878  0.003384  1.049898e-05  5  0.041845  0.027911\n",
       "기증자 정자와 혼합된 난자 수    0.001306  0.000128  1.101011e-05  5  0.001570  0.001042\n",
       "불임 원인 - 자궁내막증       0.001114  0.000113  1.273793e-05  5  0.001348  0.000880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 2. 피처 중요도 ---\n",
    "fi = predictor.feature_importance(data=train_df.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "display(fi.sort_values(by='p_value', ascending=True).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 제출 파일 생성 ---\n",
    "# submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "# submission['probability'] = final_probs.values\n",
    "\n",
    "# # 현재 시간 가져오기 (예: 0206_1031)\n",
    "# now = datetime.now().strftime('%m%d_%H%M')\n",
    "# file_name = f\"{now}_submission.csv\"\n",
    "# submission.to_csv(file_name, index=False)\n",
    "\n",
    "# print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835eaff4-be75-49e5-afb1-cd1e4c4982f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_excel('fi4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40daa829-9d39-4d77-9021-70dfe9eebe17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
