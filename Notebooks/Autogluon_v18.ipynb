{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       7.06 GB / 16.00 GB (44.2%)\n",
      "Disk Space Avail:   119.60 GB / 460.43 GB (26.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=10, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 14400s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v18\"\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 90\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7282.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 70.42 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 31 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['불임 원인 - 여성 요인']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['ID', '불임 원인 - 정자 면역학적 요인']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('category', []) : 1 | ['ID']\n",
      "\t\t('int', [])      : 1 | ['불임 원인 - 정자 면역학적 요인']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 14 | ['시술 시기 코드', '시술 당시 나이', '시술 유형', '특정 시술 유형', '배란 유도 유형', ...]\n",
      "\t\t('float', [])    : 42 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])      : 31 | ['배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 13 | ['시술 시기 코드', '시술 당시 나이', '특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', ...]\n",
      "\t\t('float', [])     : 32 | ['임신 시도 또는 마지막 임신 경과 연수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', ...]\n",
      "\t\t('int', [])       : 12 | ['총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', ...]\n",
      "\t\t('int', ['bool']) : 30 | ['시술 유형', '배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t87 features in original data used to generate 87 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 44.74 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.56s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 6398.15s of the 14399.43s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.53%)\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t11.64s\t = Training   runtime\n",
      "\t3.79s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 6380.98s of the 14382.26s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.69%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t8.49s\t = Training   runtime\n",
      "\t2.75s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 6370.23s of the 14371.51s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/8.1 GB\n",
      "\t0.7297\t = Validation score   (roc_auc)\n",
      "\t12.52s\t = Training   runtime\n",
      "\t7.65s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 6349.61s of the 14350.89s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/8.2 GB\n",
      "\t0.7303\t = Validation score   (roc_auc)\n",
      "\t12.92s\t = Training   runtime\n",
      "\t7.78s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 6328.46s of the 14329.74s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.40% memory usage per fold, 75.20%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.40%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t2311.77s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 4014.72s of the 12016.00s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.7 GB\n",
      "\t0.732\t = Validation score   (roc_auc)\n",
      "\t10.05s\t = Training   runtime\n",
      "\t7.46s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3996.78s of the 11998.06s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.0 GB\n",
      "\t0.7324\t = Validation score   (roc_auc)\n",
      "\t10.41s\t = Training   runtime\n",
      "\t7.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3978.44s of the 11979.72s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.04%)\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t112.72s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3863.07s of the 11864.35s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.79%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t18.62s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3841.84s of the 11843.12s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.84%)\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t142.62s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3696.81s of the 11698.09s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.81%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t15.67s\t = Training   runtime\n",
      "\t4.56s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 3678.75s of the 11680.03s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.34% memory usage per fold, 66.71%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.34%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t85.29s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 3591.54s of the 11592.82s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.08%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t170.79s\t = Training   runtime\n",
      "\t3.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 3418.41s of the 11419.69s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.10%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t294.71s\t = Training   runtime\n",
      "\t15.73s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 3119.58s of the 11120.86s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.99%)\n",
      "\t0.7352\t = Validation score   (roc_auc)\n",
      "\t1083.14s\t = Training   runtime\n",
      "\t2.77s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2034.29s of the 10035.57s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.58% memory usage per fold, 68.66%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.58%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t252.14s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1779.68s of the 9780.96s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.27%)\n",
      "\t0.7403\t = Validation score   (roc_auc)\n",
      "\t100.27s\t = Training   runtime\n",
      "\t22.24s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1673.96s of the 9675.24s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.89%)\n",
      "\t0.7374\t = Validation score   (roc_auc)\n",
      "\t306.48s\t = Training   runtime\n",
      "\t2.61s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1365.33s of the 9366.61s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.48%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t53.28s\t = Training   runtime\n",
      "\t5.35s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1308.92s of the 9310.20s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/9.2 GB\n",
      "\t0.7229\t = Validation score   (roc_auc)\n",
      "\t52.54s\t = Training   runtime\n",
      "\t8.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1247.87s of the 9249.15s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.42% memory usage per fold, 67.35%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.42%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t996.86s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 248.37s of the 8249.64s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.37%)\n",
      "\t0.7364\t = Validation score   (roc_auc)\n",
      "\t258.18s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 639.82s of the 7988.68s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/6.9 GB\n",
      "\tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.158, 'CatBoost_BAG_L1': 0.105, 'NeuralNetFastAI_BAG_L1': 0.105, 'CatBoost_r177_BAG_L1': 0.105, 'NeuralNetTorch_r79_BAG_L1': 0.105, 'NeuralNetTorch_r22_BAG_L1': 0.105, 'XGBoost_r33_BAG_L1': 0.105, 'LightGBMXT_BAG_L1': 0.053, 'LightGBM_BAG_L1': 0.053, 'NeuralNetTorch_BAG_L1': 0.053, 'NeuralNetFastAI_r102_BAG_L1': 0.053}\n",
      "\t0.741\t = Validation score   (roc_auc)\n",
      "\t16.73s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 5313.26s of the 7971.79s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.95%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t8.52s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 5301.79s of the 7960.32s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.43%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t8.85s\t = Training   runtime\n",
      "\t1.55s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 5290.70s of the 7949.23s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/9.5 GB\n",
      "\t0.7383\t = Validation score   (roc_auc)\n",
      "\t41.76s\t = Training   runtime\n",
      "\t9.34s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 5239.07s of the 7897.60s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.7 GB\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t66.62s\t = Training   runtime\n",
      "\t10.63s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 5161.29s of the 7819.83s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.77% memory usage per fold, 47.07%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.77%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t1368.18s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 3791.21s of the 6449.74s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.9 GB\n",
      "\t0.7424\t = Validation score   (roc_auc)\n",
      "\t12.61s\t = Training   runtime\n",
      "\t8.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 3769.95s of the 6428.48s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.7 GB\n",
      "\t0.7427\t = Validation score   (roc_auc)\n",
      "\t16.35s\t = Training   runtime\n",
      "\t8.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 3744.90s of the 6403.43s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.34% memory usage per fold, 74.73%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.34%)\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t180.93s\t = Training   runtime\n",
      "\t1.75s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 3561.29s of the 6219.82s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.29%)\n",
      "\t0.7404\t = Validation score   (roc_auc)\n",
      "\t27.14s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3529.28s of the 6187.81s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.57%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t154.77s\t = Training   runtime\n",
      "\t2.36s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 3370.38s of the 6028.91s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.76%)\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t23.37s\t = Training   runtime\n",
      "\t5.36s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 3342.81s of the 6001.34s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.87% memory usage per fold, 70.92%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.87%)\n",
      "\t0.7404\t = Validation score   (roc_auc)\n",
      "\t55.68s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 3283.98s of the 5942.52s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.90%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t282.69s\t = Training   runtime\n",
      "\t5.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 2997.56s of the 5656.09s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.78%)\n",
      "\t0.7407\t = Validation score   (roc_auc)\n",
      "\t59.65s\t = Training   runtime\n",
      "\t14.96s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 2933.76s of the 5592.29s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.11%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t843.03s\t = Training   runtime\n",
      "\t4.69s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 2087.37s of the 4745.90s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.16% memory usage per fold, 40.64%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.16%)\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t298.94s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 1786.01s of the 4444.54s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.28%)\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t77.87s\t = Training   runtime\n",
      "\t7.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 1703.88s of the 4362.42s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.89%)\n",
      "\t0.7355\t = Validation score   (roc_auc)\n",
      "\t397.58s\t = Training   runtime\n",
      "\t4.72s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 1304.08s of the 3962.61s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.82% memory usage per fold, 70.57%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.82%)\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t144.88s\t = Training   runtime\n",
      "\t7.34s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 1154.56s of the 3813.09s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/10.3 GB\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t161.24s\t = Training   runtime\n",
      "\t8.84s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 983.87s of the 3642.40s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.94% memory usage per fold, 79.51%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.94%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t645.16s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 334.23s of the 2992.76s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.23%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t976.32s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 531.33s of the 2013.30s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/8.7 GB\n",
      "\tEnsemble Weights: {'ExtraTreesEntr_BAG_L2': 0.417, 'ExtraTreesGini_BAG_L2': 0.333, 'ExtraTrees_r42_BAG_L2': 0.167, 'RandomForestEntr_BAG_L2': 0.083}\n",
      "\t0.744\t = Validation score   (roc_auc)\n",
      "\t15.93s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 1997.32s of the 1997.24s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.44%)\n",
      "\t0.743\t = Validation score   (roc_auc)\n",
      "\t8.33s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 1986.16s of the 1986.09s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.65%)\n",
      "\t0.7432\t = Validation score   (roc_auc)\n",
      "\t7.32s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 1976.74s of the 1976.67s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/9.8 GB\n",
      "\t0.7373\t = Validation score   (roc_auc)\n",
      "\t970.12s\t = Training   runtime\n",
      "\t8.35s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 997.79s of the 997.72s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.3 GB\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t47.23s\t = Training   runtime\n",
      "\t8.75s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 941.34s of the 941.27s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.36% memory usage per fold, 49.44%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.36%)\n",
      "\t0.7427\t = Validation score   (roc_auc)\n",
      "\t1221.94s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the -282.72s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/7.4 GB\n",
      "\tEnsemble Weights: {'ExtraTreesEntr_BAG_L2': 0.4, 'ExtraTreesGini_BAG_L2': 0.3, 'ExtraTrees_r42_BAG_L2': 0.15, 'NeuralNetFastAI_BAG_L1': 0.05, 'RandomForestEntr_BAG_L2': 0.05, 'LightGBM_BAG_L3': 0.05}\n",
      "\t0.744\t = Validation score   (roc_auc)\n",
      "\t36.4s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14719.2s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 180.1 rows/s (25636 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/7.5 GB\n",
      "\t3.09s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/7.4 GB\n",
      "\t2.77s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t12.52s\t = Training   runtime\n",
      "\t7.65s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t12.92s\t = Training   runtime\n",
      "\t7.78s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1337.32s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.05s\t = Training   runtime\n",
      "\t7.46s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.41s\t = Training   runtime\n",
      "\t7.51s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.3 GB\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t988.79s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.94s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/6.2 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t42.12s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.1 GB\n",
      "\t6.73s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t999.27s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/6.2 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t1009.25s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.3 GB\n",
      "\t598.66s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t1069.69s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t983.43s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.1 GB\n",
      "\t18.5s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/6.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t2570.3s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t5.23s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t52.54s\t = Training   runtime\n",
      "\t8.02s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t960.43s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t987.12s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.158, 'CatBoost_BAG_L1': 0.105, 'NeuralNetFastAI_BAG_L1': 0.105, 'CatBoost_r177_BAG_L1': 0.105, 'NeuralNetTorch_r79_BAG_L1': 0.105, 'NeuralNetTorch_r22_BAG_L1': 0.105, 'XGBoost_r33_BAG_L1': 0.105, 'LightGBMXT_BAG_L1': 0.053, 'LightGBM_BAG_L1': 0.053, 'NeuralNetTorch_BAG_L1': 0.053, 'NeuralNetFastAI_r102_BAG_L1': 0.053}\n",
      "\t16.73s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t2.24s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t2.28s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t41.76s\t = Training   runtime\n",
      "\t9.34s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t66.62s\t = Training   runtime\n",
      "\t10.63s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t420.3s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t12.61s\t = Training   runtime\n",
      "\t8.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t16.35s\t = Training   runtime\n",
      "\t8.22s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.6/6.0 GB\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t35.77s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t2.22s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.2 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t45.87s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.3 GB\n",
      "\t6.63s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t3.64s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.4 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t211.71s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.3 GB\n",
      "\t10.66s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.6/6.3 GB\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t2057.84s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t233.44s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.1 GB\n",
      "\t116.44s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t683.68s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t7.33s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t161.24s\t = Training   runtime\n",
      "\t8.84s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t25.05s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.6/6.0 GB\n",
      "\tStopping at the best epoch learned earlier - 5.\n",
      "\t12.8s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr_BAG_L2': 0.417, 'ExtraTreesGini_BAG_L2': 0.333, 'ExtraTrees_r42_BAG_L2': 0.167, 'RandomForestEntr_BAG_L2': 0.083}\n",
      "\t15.93s\t = Training   runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L3_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t2.59s\t = Training   runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L3_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.1 GB\n",
      "\t2.32s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t970.12s\t = Training   runtime\n",
      "\t8.35s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t47.23s\t = Training   runtime\n",
      "\t8.75s\t = Validation runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L3_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t11.29s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L4_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr_BAG_L2': 0.4, 'ExtraTreesGini_BAG_L2': 0.3, 'ExtraTrees_r42_BAG_L2': 0.15, 'NeuralNetFastAI_BAG_L1': 0.05, 'RandomForestEntr_BAG_L2': 0.05, 'LightGBM_BAG_L3': 0.05}\n",
      "\t36.4s\t = Training   runtime\n",
      "Refit complete, total runtime = 15492.98s ... Best model: \"WeightedEnsemble_L4\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v18\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. feature_engineering\n",
    "# ==========================================\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \n",
    "    # 수치형 변환 ('회', ' 이상' 등을 제거하고 공백 정리 후 숫자형으로 변환)\n",
    "    count_cols = [\n",
    "        '총 시술 횟수', '클리닉 내 총 시술 횟수', '총 임신 횟수', '총 출산 횟수',\n",
    "        'IVF 시술 횟수', 'DI 시술 횟수', 'IVF 임신 횟수', 'DI 임신 횟수',\n",
    "        'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '이식된 배아 수', \n",
    "        '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '저장된 배아 수'\n",
    "    ]\n",
    "    \n",
    "    for col in count_cols:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype(str).str.replace(r'회| 이상', '', regex=True).str.strip()\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    \n",
    "    # 시술 유형 DI에 대한 결측치 처리 (0으로 채우기)\n",
    "    target_cols = [\n",
    "            '총 생성 배아 수', '기증자 정자와 혼합된 난자 수', '파트너 정자와 혼합된 난자 수',\n",
    "            '미세주입된 난자 수', '혼합된 난자 수', '저장된 신선 난자 수', '해동 난자 수',\n",
    "            '해동된 배아 수', '미세주입 후 저장된 배아 수', '저장된 배아 수',\n",
    "            '미세주입 배아 이식 수', '이식된 배아 수', '미세주입에서 생성된 배아 수',\n",
    "            '수집된 신선 난자 수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '대리모 여부',\n",
    "            '기증 배아 사용 여부', '신선 배아 사용 여부', '동결 배아 사용 여부'\n",
    "        ]\n",
    "    existing_target_cols = [c for c in target_cols if c in df.columns]\n",
    "    mask_di = df['시술 유형'] == 'DI'\n",
    "    df.loc[mask_di, existing_target_cols] = df.loc[mask_di, existing_target_cols].fillna(0)\n",
    "\n",
    "    \n",
    "    # 배아 생성 이유 정제\n",
    "    def clean_reason(row):\n",
    "        if row['시술 유형'] == 'DI':\n",
    "            return '해당없음'\n",
    "    \n",
    "        x = row['배아 생성 주요 이유']\n",
    "        if pd.isna(x): return 'Unknown'\n",
    "    \n",
    "        x = str(x)\n",
    "        if '시술용' in x: return '시술용'\n",
    "        if '기증' in x: return '기증용'\n",
    "        if '저장' in x: return '저장용'\n",
    "        return 'Other'\n",
    "    \n",
    "    df['배아 생성 주요 이유'] = df.apply(clean_reason, axis=1)\n",
    "\n",
    "    \n",
    "    # 이진 분류 컬럼 결측 0으로 채우기\n",
    "    binary_cols = ['PGS 시술 여부', 'PGD 시술 여부', '착상 전 유전 검사 사용 여부']\n",
    "    df[binary_cols] = df[binary_cols].fillna(0)\n",
    "    \n",
    "    \n",
    "    if '특정 시술 유형' in df.columns:\n",
    "        df[\"BLASTOCYST_포함\"] = df[\"특정 시술 유형\"].str.contains(\"BLASTOCYST\", case=False, na=False).astype(int)\n",
    "        df[\"AH_포함\"] = df[\"특정 시술 유형\"].str.contains(\"AH\", case=False, na=False).astype(int)\n",
    "        \n",
    "        def major_procedure(x):\n",
    "            if pd.isna(x): return \"Unknown\"\n",
    "            x = str(x).upper()\n",
    "\n",
    "            # 1. ICSI (ICSI:IVF나 ICSI:ICSI 등을 모두 포함)\n",
    "            if \"ICSI\" in x: return \"ICSI\"\n",
    "            # 2. IVF (ICSI가 없으면서 IVF가 포함된 경우)\n",
    "            if \"IVF\" in x: return \"IVF\"\n",
    "            # 3. DI (기증자 인공수정)\n",
    "            if \"DI\" in x: return \"DI\"\n",
    "            # 4. IUI, ICI, IVI (모두 넓은 의미의 인공수정 계열)\n",
    "            if any(keyword in x for keyword in [\"IUI\", \"ICI\", \"IVI\"]): return \"IUI\"\n",
    "            # 5. 기타 (GIFT, FER 등 아주 적은 수의 데이터)\n",
    "            if \"UNKNOWN\" in x: return \"Unknown\"\n",
    "            return \"Other\"\n",
    "        \n",
    "        df[\"특정 시술 유형\"] = df[\"특정 시술 유형\"].apply(major_procedure)\n",
    "\n",
    "    \n",
    "    # 불임 원인 및 복잡도 계산\n",
    "    female_cols = [\n",
    "        '불임 원인 - 여성 요인', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', \n",
    "        '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증'\n",
    "    ]\n",
    "    male_cols = [\n",
    "        '불임 원인 - 남성 요인', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', \n",
    "        '불임 원인 - 정자 형태', '불임 원인 - 정자 면역학적 요인'\n",
    "    ]\n",
    "    infertility_cols = [\n",
    "        \"남성 주 불임 원인\", \"남성 부 불임 원인\", \"여성 주 불임 원인\", \"여성 부 불임 원인\",\n",
    "        \"부부 주 불임 원인\", \"부부 부 불임 원인\", \"불명확 불임 원인\",\n",
    "        \"불임 원인 - 난관 질환\", \"불임 원인 - 남성 요인\", \"불임 원인 - 배란 장애\",\n",
    "        \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\",\n",
    "        \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\",\n",
    "        \"불임 원인 - 정자 형태\"\n",
    "    ]\n",
    "\n",
    "    df['남성 결함 개수'] = df[male_cols].sum(axis=1)\n",
    "    df['여성 결함 개수'] = df[female_cols].sum(axis=1)\n",
    "    df['불임 원인 개수'] = df[infertility_cols].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df['불임 원인 개수'] = df['불임 원인 개수'].apply(infertility_complexity)\n",
    "\n",
    "    \n",
    "    # 총 시술 횟수 -> 3구간으로 구간화\n",
    "    def collapse_trials(x):\n",
    "        if pd.isna(x): return 'Unknown'\n",
    "        if x <= 0: return '0회' \n",
    "        elif 1 <= x <= 2: return '1–2회'\n",
    "        elif 3 <= x <= 5: return '3–5회'\n",
    "        else: return '6회 이상'\n",
    "\n",
    "    df[\"총 시술 bin3\"] = df[\"총 시술 횟수\"].apply(collapse_trials)\n",
    "\n",
    "\n",
    "    def div(num1, num2):\n",
    "        return np.where(num2 == 0, -1, num1 / num2)\n",
    "\n",
    "    if '시술 당시 나이' in df.columns:\n",
    "        temp_age = df['시술 당시 나이'].astype(str).str.extract(r'(\\d+)')[0].astype(float)\n",
    "    else:\n",
    "        temp_age = np.nan\n",
    "    \n",
    "    df['나이x이식배아'] = (temp_age + 1) * df['이식된 배아 수']\n",
    "    df['연령별 배아 효율'] = div(df['이식된 배아 수'], (temp_age + 1))\n",
    "    \n",
    "    df['배아 생성 효율'] = div(df['총 생성 배아 수'], df['수집된 신선 난자 수'])\n",
    "    df['배아 이식 비율'] = div(df['이식된 배아 수'], df['총 생성 배아 수'])\n",
    "    df['배아 저장 비율'] = div(df['저장된 배아 수'], df['총 생성 배아 수'])\n",
    "    \n",
    "    df['이상적 배양 기간'] = df['배아 이식 경과일'].isin([3, 5]).astype(int)\n",
    "\n",
    "    df['IVF 시술 대비 임신율'] = div(df['IVF 임신 횟수'], df['IVF 시술 횟수'])\n",
    "    df['IVF 시술 대비 출산율'] = div(df['IVF 출산 횟수'], df['IVF 시술 횟수'])\n",
    "    df['IVF 임신 유지력'] = div(df['IVF 출산 횟수'], df['IVF 임신 횟수'])\n",
    "\n",
    "    df['DI 시술 대비 임신율'] = div(df['DI 임신 횟수'], df['DI 시술 횟수'])\n",
    "    df['DI 시술 대비 출산율'] = div(df['DI 출산 횟수'], df['DI 시술 횟수'])\n",
    "    df['DI 임신 유지력'] = div(df['DI 출산 횟수'], df['DI 임신 횟수'])\n",
    "\n",
    "    \n",
    "    # 시술 중단 단계\n",
    "    def define_detailed_stage(row):\n",
    "        if row['이식된 배아 수'] > 0: # 1. 이식이 실제로 이루어진 경우 (가장 성공에 근접)\n",
    "            return '4_이식완료'\n",
    "        elif row['저장된 배아 수'] > 0: # 2. 이식은 안 했지만, 냉동 보관된 배아가 있는 경우 (이번엔 실패/연기지만 배아는 확보됨)\n",
    "            return '3_전체동결(이식보류)'\n",
    "        elif row['총 생성 배아 수'] > 0: # 3. 배아는 생성되었으나 이식도 못 하고 저장도 못한 경우 (배아 발달 중지 등)\n",
    "            return '2_배아생성후_소실'\n",
    "        elif row['수집된 신선 난자 수'] > 0 or row['혼합된 난자 수'] > 0: # 4. 난자는 채취했으나 수정(배아 생성)에 실패한 경우\n",
    "            return '1_수정실패'\n",
    "        else: # 5. 난자 채취조차 실패했거나 기록이 없는 경우\n",
    "            return '0_채취단계_실패_또는_정보없음'\n",
    "\n",
    "    df['상세_진행_단계'] = df.apply(define_detailed_stage, axis=1)\n",
    "    \n",
    "\n",
    "    # 이식 취소 원인\n",
    "    def explain_cancellation(row):\n",
    "        if row['이식된 배아 수'] > 0:\n",
    "            return 'Normal_Transfer' # 정상 이식\n",
    "        if row['총 생성 배아 수'] == 0:\n",
    "            return 'Fail_No_Embryos' # 배아가 없어서 못함\n",
    "        if row['저장된 배아 수'] > 0:\n",
    "            return 'Freeze_All' # 의도적인 전체 동결 (Freeze-all 전략 등)\n",
    "        if row['착상 전 유전 진단 사용 여부'] == 1:\n",
    "            return 'PGT_Fail' # 유전 검사 탈락 가능성\n",
    "        return 'Unknown_Fail'\n",
    "\n",
    "    df['이식_취소_사유'] = df.apply(explain_cancellation, axis=1)\n",
    "\n",
    "    # 배아 생존율 및 생산 효율\n",
    "    df['최종_배아_활용률'] = div(df['이식된 배아 수'] + df['저장된 배아 수'], df['수집된 신선 난자 수'])\n",
    "    df['미세주입_성공률'] = div(df['미세주입에서 생성된 배아 수'], df['미세주입된 난자 수'])\n",
    "    \n",
    "    df.drop('ID', errors='ignore', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 데이터 타입 최적화\n",
    "# ==========================================\n",
    "\n",
    "def optimize_memory(df):\n",
    "    for col in df.columns:\n",
    "        # 숫자형 데이터 최적화\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            if df[col].dtype == 'int64':\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        \n",
    "        # 문자열(object) 데이터 -> 범주형(category) 변환\n",
    "        elif df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "train_df = optimize_memory(train_df)\n",
    "test_df = optimize_memory(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 4. 모델 학습 설정\n",
    "# ==========================================\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target,\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='ag_models_out_v18',\n",
    ").fit(\n",
    "    train_data=train_df,\n",
    "    time_limit=14400,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=10,\n",
    "    num_bag_sets=1,\n",
    "    num_stack_levels=2,\n",
    "    refit_full=True,\n",
    "    dynamic_stacking=False,\n",
    "    save_space=True,\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\n",
    "# ==========================================\n",
    "\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "final_probs = pred_probs.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca412e5d-8496-45dd-9636-a0159ca867ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>0.743988</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>217.584635</td>\n",
       "      <td>12216.968628</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>36.397715</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.743985</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>145.113390</td>\n",
       "      <td>6593.854918</td>\n",
       "      <td>0.029245</td>\n",
       "      <td>15.932032</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L3</td>\n",
       "      <td>0.743154</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>217.553948</td>\n",
       "      <td>12180.570913</td>\n",
       "      <td>1.426397</td>\n",
       "      <td>7.318608</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT_BAG_L3</td>\n",
       "      <td>0.743042</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>217.838494</td>\n",
       "      <td>12181.584684</td>\n",
       "      <td>1.710942</td>\n",
       "      <td>8.332379</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L3</td>\n",
       "      <td>0.742741</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>216.353190</td>\n",
       "      <td>13395.192185</td>\n",
       "      <td>0.225639</td>\n",
       "      <td>1221.939880</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val eval_metric  pred_time_val      fit_time  \\\n",
       "0  WeightedEnsemble_L4   0.743988     roc_auc     217.584635  12216.968628   \n",
       "1  WeightedEnsemble_L3   0.743985     roc_auc     145.113390   6593.854918   \n",
       "2      LightGBM_BAG_L3   0.743154     roc_auc     217.553948  12180.570913   \n",
       "3    LightGBMXT_BAG_L3   0.743042     roc_auc     217.838494  12181.584684   \n",
       "4      CatBoost_BAG_L3   0.742741     roc_auc     216.353190  13395.192185   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.030687          36.397715            4       True   \n",
       "1                0.029245          15.932032            3       True   \n",
       "2                1.426397           7.318608            3       True   \n",
       "3                1.710942           8.332379            3       True   \n",
       "4                0.225639        1221.939880            3       True   \n",
       "\n",
       "   fit_order  \n",
       "0         52  \n",
       "1         46  \n",
       "2         48  \n",
       "3         47  \n",
       "4         51  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 리더보드 출력 ---\n",
    "lb = predictor.leaderboard()\n",
    "display(lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 및 예측이 완료되었습니다. 결과가 0212_0959_submission.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# --- 제출 파일 생성 ---\n",
    "submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "submission['probability'] = final_probs.values\n",
    "\n",
    "# 현재 시간 가져오기 (예: 0206_1031)\n",
    "now = datetime.now().strftime('%m%d_%H%M')\n",
    "file_name = f\"{now}_submission.csv\"\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 피처 중요도 ---\n",
    "# fi = predictor.feature_importance(data=train_df.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "# fi.to_excel('fi18.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pregnancy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
