{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb61869e-7f30-4059-b4ab-4ea4b0e5385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MPS 가속이 활성화되었습니다.\n",
      "Computed Positive Class Weight: 2.8707\n",
      "epoch 0  | loss: 0.65653 | train_auc: 0.71722 | valid_auc: 0.71646 |  0:00:44s\n",
      "epoch 1  | loss: 0.59411 | train_auc: 0.71849 | valid_auc: 0.71622 |  0:01:27s\n",
      "epoch 2  | loss: 0.58958 | train_auc: 0.72514 | valid_auc: 0.72232 |  0:02:10s\n",
      "epoch 3  | loss: 0.58876 | train_auc: 0.72266 | valid_auc: 0.71873 |  0:02:53s\n",
      "epoch 4  | loss: 0.58887 | train_auc: 0.72603 | valid_auc: 0.72377 |  0:03:34s\n",
      "epoch 5  | loss: 0.58581 | train_auc: 0.72945 | valid_auc: 0.72555 |  0:04:17s\n",
      "epoch 6  | loss: 0.58519 | train_auc: 0.72866 | valid_auc: 0.7253  |  0:05:01s\n",
      "epoch 7  | loss: 0.58355 | train_auc: 0.73194 | valid_auc: 0.72803 |  0:05:42s\n",
      "epoch 8  | loss: 0.58179 | train_auc: 0.73199 | valid_auc: 0.72828 |  0:06:25s\n",
      "epoch 9  | loss: 0.58157 | train_auc: 0.73366 | valid_auc: 0.7297  |  0:07:08s\n",
      "epoch 10 | loss: 0.58074 | train_auc: 0.73438 | valid_auc: 0.72963 |  0:07:51s\n",
      "epoch 11 | loss: 0.57995 | train_auc: 0.73472 | valid_auc: 0.72995 |  0:08:35s\n",
      "epoch 12 | loss: 0.57945 | train_auc: 0.73536 | valid_auc: 0.73013 |  0:09:19s\n",
      "epoch 13 | loss: 0.57911 | train_auc: 0.73394 | valid_auc: 0.72811 |  0:10:02s\n",
      "epoch 14 | loss: 0.58049 | train_auc: 0.73106 | valid_auc: 0.72644 |  0:10:45s\n",
      "epoch 15 | loss: 0.5806  | train_auc: 0.73478 | valid_auc: 0.73014 |  0:11:28s\n",
      "epoch 16 | loss: 0.57913 | train_auc: 0.73563 | valid_auc: 0.73003 |  0:12:12s\n",
      "epoch 17 | loss: 0.57919 | train_auc: 0.7364  | valid_auc: 0.72996 |  0:12:55s\n",
      "epoch 18 | loss: 0.57906 | train_auc: 0.73557 | valid_auc: 0.72919 |  0:13:39s\n",
      "epoch 19 | loss: 0.57969 | train_auc: 0.73651 | valid_auc: 0.73131 |  0:14:22s\n",
      "epoch 20 | loss: 0.57856 | train_auc: 0.73759 | valid_auc: 0.732   |  0:15:04s\n",
      "epoch 21 | loss: 0.57745 | train_auc: 0.73816 | valid_auc: 0.73314 |  0:15:48s\n",
      "epoch 22 | loss: 0.57679 | train_auc: 0.7386  | valid_auc: 0.73229 |  0:16:30s\n",
      "epoch 23 | loss: 0.57789 | train_auc: 0.73312 | valid_auc: 0.72804 |  0:17:14s\n",
      "epoch 24 | loss: 0.57772 | train_auc: 0.73792 | valid_auc: 0.73335 |  0:17:57s\n",
      "epoch 25 | loss: 0.57766 | train_auc: 0.73028 | valid_auc: 0.72611 |  0:18:40s\n",
      "epoch 26 | loss: 0.57893 | train_auc: 0.73071 | valid_auc: 0.72692 |  0:19:24s\n",
      "epoch 27 | loss: 0.57949 | train_auc: 0.73831 | valid_auc: 0.73265 |  0:20:07s\n",
      "epoch 28 | loss: 0.57827 | train_auc: 0.73889 | valid_auc: 0.73387 |  0:20:50s\n",
      "epoch 29 | loss: 0.57736 | train_auc: 0.73955 | valid_auc: 0.734   |  0:21:34s\n",
      "epoch 30 | loss: 0.57703 | train_auc: 0.74002 | valid_auc: 0.73477 |  0:22:18s\n",
      "epoch 31 | loss: 0.57653 | train_auc: 0.74076 | valid_auc: 0.73441 |  0:23:00s\n",
      "epoch 32 | loss: 0.57568 | train_auc: 0.74159 | valid_auc: 0.73518 |  0:23:45s\n",
      "epoch 33 | loss: 0.57522 | train_auc: 0.74206 | valid_auc: 0.73615 |  0:24:27s\n",
      "epoch 34 | loss: 0.57473 | train_auc: 0.74221 | valid_auc: 0.735   |  0:59:28s\n",
      "epoch 35 | loss: 0.57417 | train_auc: 0.74267 | valid_auc: 0.7351  |  1:04:00s\n",
      "epoch 36 | loss: 0.57442 | train_auc: 0.74207 | valid_auc: 0.73503 |  1:04:43s\n",
      "epoch 37 | loss: 0.5733  | train_auc: 0.74405 | valid_auc: 0.7363  |  1:05:27s\n",
      "epoch 38 | loss: 0.57334 | train_auc: 0.74436 | valid_auc: 0.73672 |  1:06:10s\n",
      "epoch 39 | loss: 0.57321 | train_auc: 0.74445 | valid_auc: 0.73571 |  1:06:53s\n",
      "epoch 40 | loss: 0.57245 | train_auc: 0.74538 | valid_auc: 0.73599 |  1:07:36s\n",
      "epoch 41 | loss: 0.57215 | train_auc: 0.74573 | valid_auc: 0.73664 |  1:08:19s\n",
      "epoch 42 | loss: 0.57245 | train_auc: 0.74579 | valid_auc: 0.73597 |  1:09:01s\n",
      "epoch 43 | loss: 0.57204 | train_auc: 0.74633 | valid_auc: 0.73636 |  1:09:45s\n",
      "epoch 44 | loss: 0.57163 | train_auc: 0.74646 | valid_auc: 0.73524 |  1:10:28s\n",
      "epoch 45 | loss: 0.57108 | train_auc: 0.74731 | valid_auc: 0.73565 |  1:11:12s\n",
      "epoch 46 | loss: 0.57087 | train_auc: 0.74866 | valid_auc: 0.73541 |  1:11:57s\n",
      "epoch 47 | loss: 0.57039 | train_auc: 0.74793 | valid_auc: 0.73466 |  1:12:40s\n",
      "epoch 48 | loss: 0.56977 | train_auc: 0.74869 | valid_auc: 0.73476 |  1:13:23s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_valid_auc = 0.73672\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import warnings\n",
    "\n",
    "# 경고 무시 및 시드 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# MPS 장치 설정 (Apple Silicon 가속)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(f\"✅ MPS 가속이 활성화되었습니다.\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(f\"⚠️ MPS를 찾을 수 없어 CPU로 실행합니다.\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "train_df = pd.read_csv(\"../Data/train.csv\")\n",
    "test_df = pd.read_csv(\"../Data/test.csv\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 전처리 함수 (User Provided Logic + Bug Fix)\n",
    "# ==========================================\n",
    "def preprocess_for_tabnet(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # 시술_대분류\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        if \"IUI\" in x: return \"IUI\"\n",
    "        if \"DI\" in x: return \"Other\"\n",
    "        if \"ICSI\" in x: return \"ICSI\"\n",
    "        if \"IVF\" in x: return \"IVF\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df_copy[\"시술_대분류\"] = df_copy[\"특정 시술 유형\"].apply(major_procedure)\n",
    "    \n",
    "    # BLASTOCYST 포함 여부\n",
    "    df_copy[\"BLASTOCYST_포함\"] = df_copy[\"특정 시술 유형\"].str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    \n",
    "    # 배아 이식 여부 관련\n",
    "    embryo_stage_cols = [\n",
    "        \"단일 배아 이식 여부\", \"착상 전 유전 진단 사용 여부\", \"배아 생성 주요 이유\",\n",
    "        \"총 생성 배아 수\", \"미세주입된 난자 수\", \"미세주입에서 생성된 배아 수\",\n",
    "        \"이식된 배아 수\", \"미세주입 배아 이식 수\", \"저장된 배아 수\",\n",
    "        \"미세주입 후 저장된 배아 수\", \"해동된 배아 수\", \"해동 난자 수\",\n",
    "        \"수집된 신선 난자 수\", \"저장된 신선 난자 수\", \"혼합된 난자 수\",\n",
    "        \"파트너 정자와 혼합된 난자 수\", \"기증자 정자와 혼합된 난자 수\",\n",
    "        \"동결 배아 사용 여부\", \"신선 배아 사용 여부\", \"기증 배아 사용 여부\", \"대리모 여부\",\n",
    "    ]\n",
    "    \n",
    "    df_copy[\"배아_이식_미도달\"] = df_copy[embryo_stage_cols].isna().all(axis=1).astype(int)\n",
    "    df_copy[\"배아_이식_여부\"] = 1 - df_copy[\"배아_이식_미도달\"]\n",
    "    \n",
    "    # 배아 진행 단계\n",
    "    def embryo_stage(row):\n",
    "        if row['배아_이식_여부'] == 0: return '배아단계_미도달'\n",
    "        elif pd.isna(row['총 생성 배아 수']) or row['총 생성 배아 수'] == 0: return '배아생성_실패'\n",
    "        elif pd.isna(row['이식된 배아 수']) or row['이식된 배아 수'] == 0: return '이식_미실시'\n",
    "        else: return '이식_완료'\n",
    "    \n",
    "    df_copy['배아_진행_단계'] = df_copy.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    # 총시술_bin3\n",
    "    def collapse_trials(x):\n",
    "        if x == '0회': return '0회'\n",
    "        elif x in ['1회', '2회']: return '1–2회'\n",
    "        else: return '3회 이상'\n",
    "    \n",
    "    df_copy[\"총시술_bin3\"] = df_copy[\"총 시술 횟수\"].apply(collapse_trials)\n",
    "    \n",
    "    # 나이_3구간\n",
    "    def age_group_simple(age):\n",
    "        if age == '알 수 없음': return 'Unknown'\n",
    "        elif age == '만18-34세': return '34세 이하'\n",
    "        elif age in ['만35-37세', '만38-39세']: return '35-39세'\n",
    "        else: return '40세 이상'\n",
    "    \n",
    "    df_copy['나이_3구간'] = df_copy['시술 당시 나이'].apply(age_group_simple)\n",
    "    \n",
    "    # 이식배아_구간\n",
    "    def embryo_count_bin(count):\n",
    "        if pd.isna(count) or count == 0: return '0개'\n",
    "        elif count <= 2: return '1-2개'\n",
    "        else: return '3개 이상'\n",
    "    \n",
    "    df_copy['이식배아_구간'] = df_copy['이식된 배아 수'].apply(embryo_count_bin)\n",
    "    \n",
    "    # Day5_이식_여부\n",
    "    df_copy['Day5_이식_여부'] = (df_copy['배아 이식 경과일'] == 5.0).astype(int)\n",
    "    \n",
    "    # 불임원인_복잡도\n",
    "    infertility_cols = [\n",
    "        \"남성 주 불임 원인\", \"남성 부 불임 원인\", \"여성 주 불임 원인\", \"여성 부 불임 원인\",\n",
    "        \"부부 주 불임 원인\", \"부부 부 불임 원인\", \"불명확 불임 원인\",\n",
    "        \"불임 원인 - 난관 질환\", \"불임 원인 - 남성 요인\", \"불임 원인 - 배란 장애\",\n",
    "        \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\",\n",
    "        \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\",\n",
    "        \"불임 원인 - 정자 형태\"\n",
    "    ]\n",
    "    df_copy[\"불임_원인_개수\"] = df_copy[infertility_cols].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df_copy['불임원인_복잡도'] = df_copy['불임_원인_개수'].apply(infertility_complexity)\n",
    "    \n",
    "    # 배아_해동_실시_여부\n",
    "    df_copy['배아_해동_실시_여부'] = df_copy['배아 해동 경과일'].notna().astype(int)\n",
    "    \n",
    "    # 배아 효율 비율 변수들\n",
    "    df_copy['배아_생성_효율'] = df_copy['총 생성 배아 수'] / (df_copy['수집된 신선 난자 수'] + 1)\n",
    "    df_copy['배아_이식_비율'] = df_copy['이식된 배아 수'] / (df_copy['총 생성 배아 수'] + 1)\n",
    "    df_copy['배아_저장_비율'] = df_copy['저장된 배아 수'] / (df_copy['총 생성 배아 수'] + 1)\n",
    "    \n",
    "    # 교호작용 변수들\n",
    "    df_copy['나이×Day5'] = df_copy['시술 당시 나이'].astype(str) + '_' + df_copy['Day5_이식_여부'].astype(str)\n",
    "    df_copy['시술횟수×나이'] = df_copy['총시술_bin3'] + '_' + df_copy['나이_3구간']\n",
    "\n",
    "    # ID 컬럼 제거 (제공된 코드의 버그 수정: df_copy에서 제거)\n",
    "    if 'ID' in df_copy.columns:\n",
    "        df_copy = df_copy.drop(['ID'], axis=1)\n",
    "    \n",
    "    # 배아_이식_미도달은 파생변수 생성용이므로 제거\n",
    "    if '배아_이식_미도달' in df_copy.columns:\n",
    "        df_copy = df_copy.drop(['배아_이식_미도달'], axis=1)\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "# 전처리 적용\n",
    "train_processed = preprocess_for_tabnet(train_df)\n",
    "test_processed = preprocess_for_tabnet(test_df)\n",
    "\n",
    "# 타겟 분리\n",
    "target_col = '임신 성공 여부'\n",
    "X = train_processed.drop(columns=[target_col])\n",
    "y = train_processed[target_col].values\n",
    "X_test = test_processed.copy()\n",
    "\n",
    "# ==========================================\n",
    "# 3. 데이터 누수 방지 (Imputation, Encoding, Scaling)\n",
    "# ==========================================\n",
    "\n",
    "# 컬럼 타입 자동 분류\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# 3-1. 결측치 처리 (Numeric) - Train의 Median 활용\n",
    "# [누수 방지 준수 6번]: Test 결측치는 Train 통계값으로 처리\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "X[numeric_cols] = imputer_num.fit_transform(X[numeric_cols])\n",
    "X_test[numeric_cols] = imputer_num.transform(X_test[numeric_cols])\n",
    "\n",
    "# 3-2. 결측치 처리 (Categorical) - 'Unknown'으로 채움\n",
    "X[categorical_cols] = X[categorical_cols].fillna(\"Unknown\")\n",
    "X_test[categorical_cols] = X_test[categorical_cols].fillna(\"Unknown\")\n",
    "\n",
    "# 3-3. Label Encoding (TabNet 필수)\n",
    "# [누수 방지 준수 3번, 5번]: Test 데이터는 fit에 사용하지 않음\n",
    "categorical_dims = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X[col].astype(str))\n",
    "    \n",
    "    # Train 변환\n",
    "    X[col] = le.transform(X[col].astype(str))\n",
    "    \n",
    "    # Test 변환 (Unknown Label Handling)\n",
    "    # Test에만 있는 새로운 카테고리는 Train의 최빈값(mode) 또는 0번 클래스로 매핑\n",
    "    test_values = X_test[col].astype(str).values\n",
    "    # 학습된 클래스에 없는 값 식별\n",
    "    unseen_mask = ~np.in1d(test_values, le.classes_)\n",
    "    \n",
    "    if unseen_mask.any():\n",
    "        # Train의 최빈값 찾기\n",
    "        mode_val = X[col].mode()[0] \n",
    "        # unseen 값을 임시로 classes_[0]로 대체 (transform 에러 방지용) 후 나중에 최빈값으로 덮어씀\n",
    "        # 여기서는 단순히 transform 가능한 값으로 매핑하고 인코딩 후 mode_val(integer)로 교체\n",
    "        \n",
    "        # 1. 안전하게 변환하기 위해 unseen을 known class 중 하나로 임시 변경\n",
    "        temp_safe_val = le.classes_[0]\n",
    "        test_values_safe = test_values.copy()\n",
    "        test_values_safe[unseen_mask] = temp_safe_val\n",
    "        \n",
    "        # 2. 변환 수행\n",
    "        X_test[col] = le.transform(test_values_safe)\n",
    "        \n",
    "        # 3. Unseen 위치에 Train Mode(이미 인코딩된 정수) 할당\n",
    "        X_test.loc[unseen_mask, col] = mode_val\n",
    "    else:\n",
    "        X_test[col] = le.transform(test_values)\n",
    "        \n",
    "    categorical_dims[col] = len(le.classes_)\n",
    "\n",
    "# 3-4. Scaling (Numeric)\n",
    "# [누수 방지 준수 4번]: Scaler는 Train에만 Fit\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# 메모리 효율을 위해 float32로 변환\n",
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# ==========================================\n",
    "# 4. TabNet 준비 (인덱스 및 파라미터)\n",
    "# ==========================================\n",
    "\n",
    "# Categorical Feature Index 추출 (TabNet 입력용)\n",
    "cat_idxs = [i for i, f in enumerate(X.columns) if f in categorical_cols]\n",
    "cat_dims = [categorical_dims[f] for f in categorical_cols]\n",
    "\n",
    "# 학습/검증 데이터 분리 (Stratified Split)\n",
    "# [누수 방지 준수 1번]: 모델 학습 시 검증용 데이터 분리\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X.values, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# 불균형 데이터 가중치 계산 (Positive 클래스 가중치)\n",
    "# 0: 190123, 1: 66228 => 비율 약 2.87배\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "class_weights = torch.tensor([1.0, pos_weight], dtype=torch.float).to(device)\n",
    "print(f\"Computed Positive Class Weight: {pos_weight:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. TabNet 모델 학습\n",
    "# ==========================================\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    n_d=32, n_a=32, n_steps=5,    # 모델 복잡도 조절\n",
    "    gamma=1.5, n_independent=2, n_shared=2,\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=1,                # 범주형 임베딩 차원\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='entmax',           # entmax or sparsemax\n",
    "    device_name=device,           # MPS 설정\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Weighted Loss Function 정의\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=100,                # 필요에 따라 조절 (예: 100)\n",
    "    patience=10,\n",
    "    batch_size=1024,              # 대용량 데이터 배치 사이즈\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    loss_fn=loss_fn               # 가중치 적용된 손실함수 전달\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 6. Test Data 예측\n",
    "# ==========================================\n",
    "\n",
    "preds_proba = clf.predict_proba(X_test.values)\n",
    "final_probs_tabnet = preds_proba[:, 1] # Positive 클래스(1)에 대한 확률만 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035e8d52-515b-4f51-9604-52e081c0c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료! 결과 저장됨: TN_0210_2321_submission.csv\n",
      "Best Validation AUC: 0.7367179542770432\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. 결과 추출\n",
    "# ==========================================\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime('%m%d_%H%M')\n",
    "file_name = f\"TN_{now}_submission.csv\"\n",
    "\n",
    "submission = pd.read_csv(\"../Data/sample_submission.csv\")\n",
    "submission['probability'] = final_probs_tabnet\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"완료! 결과 저장됨: {file_name}\")\n",
    "print(f\"Best Validation AUC: {clf.best_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d82ad-317b-4f97-aaa5-0baf66b35d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
