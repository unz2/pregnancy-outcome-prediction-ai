{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_models_out_v2\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       8.09 GB / 16.00 GB (50.5%)\n",
      "Disk Space Avail:   167.41 GB / 460.43 GB (36.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "DyStack: Disabling memory safe fit mode in DyStack because GPUs were detected and num_gpus='auto' (GPUs cannot be used in memory safe fit mode). If you want to use memory safe fit mode, manually set `num_gpus=0`.\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v2/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    182293\n",
      "Train Data Columns: 62\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8318.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 200.59 MB (2.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 38 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])    : 15 | ['시술 당시 나이', '배란 자극 여부', '불명확 불임 원인', '총 시술 횟수', '클리닉 내 총 시술 횟수', ...]\n",
      "\t\t('object', []) :  8 | ['시술 유형', '특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', '난자 출처', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  7 | ['특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', '난자 출처', '정자 출처', ...]\n",
      "\t\t('float', [])     : 34 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       : 13 | ['시술 당시 나이', '총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', ...]\n",
      "\t\t('int', ['bool']) :  7 | ['시술 유형', '배란 자극 여부', '착상 전 유전 검사 사용 여부', '불명확 불임 원인', 'PGD 시술 여부', ...]\n",
      "\t0.9s = Fit runtime\n",
      "\t61 features in original data used to generate 61 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 67.80 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.99s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Included models: ['GBM', 'CAT', 'XGB', 'NN_TORCH'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 67 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1199.04s of the 1799.00s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.91%)\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t3.6s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1191.04s of the 1791.00s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.49%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t3.14s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1186.08s of the 1786.05s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.10%)\n",
      "[2026-02-09 14:01:59,692 E 7122 566316] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t157.58s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1026.86s of the 1626.82s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.21%)\n",
      "\t0.7379\t = Validation score   (roc_auc)\n",
      "\t5.3s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1019.72s of the 1619.69s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.56%)\n",
      "\t0.7356\t = Validation score   (roc_auc)\n",
      "\t70.68s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 947.14s of the 1547.10s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.29%)\n",
      "\t0.737\t = Validation score   (roc_auc)\n",
      "\t7.39s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 937.23s of the 1537.19s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.89%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t18.31s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 917.22s of the 1517.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.37%)\n",
      "\t0.7355\t = Validation score   (roc_auc)\n",
      "\t131.73s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 783.56s of the 1383.52s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.39%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t13.46s\t = Training   runtime\n",
      "\t4.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 767.21s of the 1367.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.96%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t67.26s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 698.27s of the 1298.23s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.83%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t20.95s\t = Training   runtime\n",
      "\t5.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 674.46s of the 1274.43s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.23%)\n",
      "\t0.7346\t = Validation score   (roc_auc)\n",
      "\t181.97s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 490.63s of the 1090.59s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.75%)\n",
      "\t0.7354\t = Validation score   (roc_auc)\n",
      "\t17.73s\t = Training   runtime\n",
      "\t2.0s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 470.85s of the 1070.81s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.99%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t195.49s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 273.53s of the 873.49s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.73%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t54.22s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 217.66s of the 817.63s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.04%)\n",
      "\t0.7378\t = Validation score   (roc_auc)\n",
      "\t7.54s\t = Training   runtime\n",
      "\t1.88s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 208.11s of the 808.07s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.83%)\n",
      "\t0.7383\t = Validation score   (roc_auc)\n",
      "\t6.69s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 199.68s of the 799.65s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.34%)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. 파생변수 생성\n",
    "# ==========================================\n",
    "\n",
    "def derive_features(df):\n",
    "\n",
    "    # 1. 수치형 변환 및 클리닝 (정규표현식 활용)\n",
    "    count_cols = [\n",
    "        '총 시술 횟수', '클리닉 내 총 시술 횟수', '총 임신 횟수', '총 출산 횟수',\n",
    "        'IVF 시술 횟수', 'DI 시술 횟수', 'IVF 임신 횟수', 'DI 임신 횟수',\n",
    "        'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '이식된 배아 수', \n",
    "        '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '저장된 배아 수'\n",
    "    ]\n",
    "    \n",
    "    for col in count_cols:\n",
    "        if df[col].dtype == 'object':\n",
    "            # '회', ' 이상' 등을 제거하고 공백 정리 후 숫자형으로 변환\n",
    "            df[col] = df[col].astype(str).str.replace(r'회| 이상', '', regex=True).str.strip()\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    target_cols = [\n",
    "            '총 생성 배아 수', '기증자 정자와 혼합된 난자 수', '파트너 정자와 혼합된 난자 수',\n",
    "            '미세주입된 난자 수', '혼합된 난자 수', '저장된 신선 난자 수', '해동 난자 수',\n",
    "            '해동된 배아 수', '미세주입 후 저장된 배아 수', '저장된 배아 수',\n",
    "            '미세주입 배아 이식 수', '이식된 배아 수', '미세주입에서 생성된 배아 수',\n",
    "            '수집된 신선 난자 수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '대리모 여부',\n",
    "            '기증 배아 사용 여부', '신선 배아 사용 여부', '동결 배아 사용 여부'\n",
    "        ]\n",
    "\n",
    "    # 시술 유형이 DI인 행에 대해서만 지정된 컬럼들의 NaN을 0으로 채움\n",
    "    df.loc[df['특정 시술 유형'] == 'DI', target_cols] = df.loc[df['특정 시술 유형'] == 'DI', target_cols].fillna(0)\n",
    "\n",
    "\n",
    "    # 2. 연령 관련 변수 생성\n",
    "    age_order = {\n",
    "        '만18-34세': 1, '만35-37세': 2, '만38-39세': 3, \n",
    "        '만40-42세': 4, '만43-44세': 5, '만45-50세': 6, '알 수 없음': 7\n",
    "    }\n",
    "    df['시술 당시 나이'] = df['시술 당시 나이'].map(age_order).fillna(7)\n",
    "    \n",
    "    # 파생 변수 계산 (Zero Division 방지를 위해 1e-6 활용)\n",
    "    epsilon = 1e-6\n",
    "    df['나이x배아'] = df['시술 당시 나이'] * df['이식된 배아 수']\n",
    "    df['연령별 배아 효율'] = df['이식된 배아 수'] / (df['시술 당시 나이'] + epsilon)\n",
    "    df['배아 발달 기간'] = df['배아 이식 경과일'] - df['난자 혼합 경과일']\n",
    "    df['이식 비중'] = df['이식된 배아 수'] / (df['이식된 배아 수'] + df['저장된 배아 수'] + epsilon)\n",
    "\n",
    "    # 3. 난자 및 배아 효율성 변수\n",
    "    oocyte_cols = ['수집된 신선 난자 수', '혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '해동 난자 수']\n",
    "    df['총 난자 수'] = df[oocyte_cols].fillna(0).sum(axis=1)\n",
    "    \n",
    "    # 0으로 나누기 방지를 위해 총 난자 수가 0인 경우 0으로 처리하거나 epsilon 추가\n",
    "    df['배아 손실률'] = (df['총 난자 수'] - df['총 생성 배아 수']) / (df['총 난자 수'] + epsilon)\n",
    "    df['배아 생성 효율'] = df['저장된 배아 수'] / (df['저장된 신선 난자 수'] + epsilon)\n",
    "    df['수정 효율'] = df['총 생성 배아 수'] / (df['혼합된 난자 수'] + epsilon)\n",
    "    df['선별 효율'] = df['저장된 배아 수'] / (df['총 생성 배아 수'] + epsilon)\n",
    "\n",
    "    # 4. 시술 유형 분류 (Vectorized 방식 권장)\n",
    "    def clean_treatment(val):\n",
    "        val = str(val).upper()\n",
    "        if 'ICSI' in val: return 'ICSI'\n",
    "        if 'IVF' in val: return 'IVF'\n",
    "        if 'IUI' in val: return 'IUI'\n",
    "        return 'Other'\n",
    "\n",
    "    df['특정 시술 유형'] = df['특정 시술 유형'].apply(clean_treatment)\n",
    "\n",
    "    # 5. 불임 원인 점수 계산\n",
    "    female_cols = [\n",
    "        '불임 원인 - 여성 요인', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', \n",
    "        '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '여성 주 불임 원인', \n",
    "        '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인'\n",
    "    ]\n",
    "    male_cols = [\n",
    "        '불임 원인 - 남성 요인', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', \n",
    "        '불임 원인 - 정자 형태', '불임 원인 - 정자 면역학적 요인', '남성 주 불임 원인', \n",
    "        '남성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인'\n",
    "    ]\n",
    "    \n",
    "    df['여성_결함_점수'] = df[female_cols].sum(axis=1)\n",
    "    df['남성_결함_점수'] = df[male_cols].sum(axis=1)\n",
    "\n",
    "    # 6. 배아 생성 주요 이유 단순화\n",
    "    def clean_reason(x):\n",
    "        if pd.isna(x): return 'Unknown'\n",
    "        x = str(x)\n",
    "        if '시술용' in x: return 'Treatment'\n",
    "        if '기증' in x: return 'Donation'\n",
    "        if '저장' in x: return 'Storage'\n",
    "        return 'Other'\n",
    "    \n",
    "    df['배아 생성 주요 이유'] = df['배아 생성 주요 이유'].apply(clean_reason)\n",
    "    \n",
    "    # 7. 불필요한 컬럼 삭제\n",
    "    drop_cols = ['ID', '시술 시기 코드']\n",
    "    df.drop(columns=drop_cols + female_cols + male_cols, errors='ignore', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = derive_features(train_df)\n",
    "test_df = derive_features(test_df)\n",
    "\n",
    "# 학습용 데이터 내에서 정답이 있는 '자체 테스트셋' 분리\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 모델 학습 설정\n",
    "# ==========================================\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target, \n",
    "    eval_metric='roc_auc',\n",
    "    path='ag_models_out_v12',\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=7200,\n",
    "    presets='best_quality',\n",
    "    num_stack_levels=1,\n",
    "    num_bag_folds=5,\n",
    "    num_bag_sets=5,\n",
    "    refit_full=True,\n",
    "    dynamic_stacking=False,\n",
    "    included_model_types=['GBM', 'CAT', 'XGB']\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\n",
    "# ==========================================\n",
    "\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "final_probs = pred_probs.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca412e5d-8496-45dd-9636-a0159ca867ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 리더보드 출력 ---\n",
    "lb = predictor.leaderboard(val_data, silent=True)\n",
    "display(lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 피처 중요도 ---\n",
    "fi = predictor.feature_importance(data=train_data.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "fi.to_excel('fi12.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 제출 파일 생성 ---\n",
    "# submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "# submission['probability'] = final_probs.values\n",
    "\n",
    "# # 현재 시간 가져오기 (예: 0206_1031)\n",
    "# now = datetime.now().strftime('%m%d_%H%M')\n",
    "# file_name = f\"{now}_submission.csv\"\n",
    "# submission.to_csv(file_name, index=False)\n",
    "\n",
    "# print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
