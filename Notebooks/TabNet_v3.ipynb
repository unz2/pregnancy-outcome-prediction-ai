{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb61869e-7f30-4059-b4ab-4ea4b0e5385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MPS 가속이 활성화되었습니다.\n",
      "Positive Class Weight: 2.8707\n",
      "TabNet 학습 시작 (Quantile Transform 적용됨)...\n",
      "epoch 0  | loss: 0.94636 | train_auc: 0.69729 | valid_auc: 0.69689 |  0:00:42s\n",
      "epoch 1  | loss: 0.91347 | train_auc: 0.72641 | valid_auc: 0.72295 |  0:01:25s\n",
      "epoch 2  | loss: 0.90889 | train_auc: 0.73052 | valid_auc: 0.72653 |  0:02:07s\n",
      "epoch 3  | loss: 0.90661 | train_auc: 0.73264 | valid_auc: 0.72761 |  0:02:49s\n",
      "epoch 4  | loss: 0.90472 | train_auc: 0.73318 | valid_auc: 0.72921 |  0:03:32s\n",
      "epoch 5  | loss: 0.90454 | train_auc: 0.73412 | valid_auc: 0.7303  |  0:04:14s\n",
      "epoch 6  | loss: 0.90373 | train_auc: 0.73433 | valid_auc: 0.72898 |  0:04:56s\n",
      "epoch 7  | loss: 0.90253 | train_auc: 0.73629 | valid_auc: 0.7306  |  0:05:38s\n",
      "epoch 8  | loss: 0.90221 | train_auc: 0.7373  | valid_auc: 0.73173 |  0:06:20s\n",
      "epoch 9  | loss: 0.90094 | train_auc: 0.73496 | valid_auc: 0.72957 |  0:07:02s\n",
      "epoch 10 | loss: 0.90054 | train_auc: 0.73776 | valid_auc: 0.7316  |  0:07:45s\n",
      "epoch 11 | loss: 0.90031 | train_auc: 0.73643 | valid_auc: 0.73152 |  0:08:27s\n",
      "epoch 12 | loss: 0.90023 | train_auc: 0.73792 | valid_auc: 0.73238 |  0:09:09s\n",
      "epoch 13 | loss: 0.8997  | train_auc: 0.73872 | valid_auc: 0.73303 |  0:09:52s\n",
      "epoch 14 | loss: 0.89908 | train_auc: 0.73853 | valid_auc: 0.7323  |  0:10:34s\n",
      "epoch 15 | loss: 0.89904 | train_auc: 0.73715 | valid_auc: 0.73046 |  0:11:16s\n",
      "epoch 16 | loss: 0.89906 | train_auc: 0.73771 | valid_auc: 0.73134 |  0:11:58s\n",
      "epoch 17 | loss: 0.89841 | train_auc: 0.73951 | valid_auc: 0.73322 |  0:12:40s\n",
      "epoch 18 | loss: 0.89839 | train_auc: 0.73993 | valid_auc: 0.73321 |  0:13:23s\n",
      "epoch 19 | loss: 0.89809 | train_auc: 0.74017 | valid_auc: 0.73458 |  0:14:05s\n",
      "epoch 20 | loss: 0.89804 | train_auc: 0.73992 | valid_auc: 0.73333 |  0:14:48s\n",
      "epoch 21 | loss: 0.89697 | train_auc: 0.73883 | valid_auc: 0.73226 |  0:15:30s\n",
      "epoch 22 | loss: 0.89727 | train_auc: 0.74034 | valid_auc: 0.73319 |  0:16:12s\n",
      "epoch 23 | loss: 0.8969  | train_auc: 0.74127 | valid_auc: 0.73303 |  0:16:54s\n",
      "epoch 24 | loss: 0.89655 | train_auc: 0.74248 | valid_auc: 0.73426 |  0:17:36s\n",
      "epoch 25 | loss: 0.89637 | train_auc: 0.74054 | valid_auc: 0.73347 |  0:18:19s\n",
      "epoch 26 | loss: 0.89619 | train_auc: 0.74203 | valid_auc: 0.73398 |  0:19:00s\n",
      "epoch 27 | loss: 0.89547 | train_auc: 0.74294 | valid_auc: 0.73477 |  0:19:44s\n",
      "epoch 28 | loss: 0.89612 | train_auc: 0.74358 | valid_auc: 0.73493 |  0:20:27s\n",
      "epoch 29 | loss: 0.89526 | train_auc: 0.74219 | valid_auc: 0.73385 |  0:21:11s\n",
      "epoch 30 | loss: 0.89535 | train_auc: 0.74454 | valid_auc: 0.73473 |  0:21:54s\n",
      "epoch 31 | loss: 0.8949  | train_auc: 0.74395 | valid_auc: 0.73345 |  0:22:37s\n",
      "epoch 32 | loss: 0.8947  | train_auc: 0.74294 | valid_auc: 0.73286 |  0:23:20s\n",
      "epoch 33 | loss: 0.89477 | train_auc: 0.74434 | valid_auc: 0.73398 |  0:24:03s\n",
      "epoch 34 | loss: 0.89478 | train_auc: 0.74382 | valid_auc: 0.73367 |  0:24:45s\n",
      "epoch 35 | loss: 0.89441 | train_auc: 0.74377 | valid_auc: 0.73362 |  0:25:27s\n",
      "epoch 36 | loss: 0.89375 | train_auc: 0.74455 | valid_auc: 0.73321 |  0:26:10s\n",
      "epoch 37 | loss: 0.89377 | train_auc: 0.74399 | valid_auc: 0.73172 |  0:26:52s\n",
      "epoch 38 | loss: 0.89325 | train_auc: 0.74614 | valid_auc: 0.73333 |  0:27:34s\n",
      "epoch 39 | loss: 0.8931  | train_auc: 0.74625 | valid_auc: 0.73401 |  0:28:16s\n",
      "epoch 40 | loss: 0.89388 | train_auc: 0.74716 | valid_auc: 0.73347 |  0:28:59s\n",
      "epoch 41 | loss: 0.89269 | train_auc: 0.74767 | valid_auc: 0.73321 |  0:29:42s\n",
      "epoch 42 | loss: 0.8916  | train_auc: 0.74649 | valid_auc: 0.73302 |  0:30:25s\n",
      "epoch 43 | loss: 0.89117 | train_auc: 0.74763 | valid_auc: 0.7335  |  0:31:09s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 28 and best_valid_auc = 0.73493\n",
      "\n",
      "최종 검증 AUC: 0.73493\n",
      "예측 완료. 'final_probs_tabnet'에 확률값이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import warnings\n",
    "\n",
    "# 경고 무시 및 시드 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# MPS 장치 설정 (Apple Silicon 가속)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(f\"✅ MPS 가속이 활성화되었습니다.\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(f\"⚠️ MPS를 찾을 수 없어 CPU로 실행합니다.\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "# [누수 방지 1, 2]: 학습과 테스트 데이터를 엄격히 분리하여 로드\n",
    "train_df = pd.read_csv(\"../Data/train.csv\")\n",
    "test_df = pd.read_csv(\"../Data/test.csv\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 전처리 함수 (파생변수 생성 - 로직만 공유)\n",
    "# ==========================================\n",
    "def preprocess_for_tabnet(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # 계산형 파생변수 (누수 없음)\n",
    "    df_copy['배아_생성_효율'] = df_copy['총 생성 배아 수'] / (df_copy['수집된 신선 난자 수'] + 1)\n",
    "    df_copy['배아_이식_비율'] = df_copy['이식된 배아 수'] / (df_copy['총 생성 배아 수'] + 1)\n",
    "    df_copy['배아_저장_비율'] = df_copy['저장된 배아 수'] / (df_copy['총 생성 배아 수'] + 1)\n",
    "    \n",
    "    # 문자열 결합 파생변수 (누수 없음)\n",
    "    df_copy['나이×Day5'] = df_copy['시술 당시 나이'].astype(str) + '_' + (df_copy['배아 이식 경과일'] == 5.0).astype(str)\n",
    "    \n",
    "    # 불필요 변수 제거\n",
    "    df_copy = df_copy.drop(['ID', '이식된 배아 수'], axis=1)\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "# 전처리 적용\n",
    "train_processed = preprocess_for_tabnet(train_df)\n",
    "test_processed = preprocess_for_tabnet(test_df)\n",
    "\n",
    "# 타겟 분리\n",
    "target_col = '임신 성공 여부'\n",
    "X_train_full = train_processed.drop(columns=[target_col])\n",
    "y_train_full = train_processed[target_col].values\n",
    "X_test = test_processed.copy()\n",
    "\n",
    "# ==========================================\n",
    "# 3. 데이터 누수 방지 프로세스 (Imputation, Encoding, Scaling)\n",
    "# ==========================================\n",
    "\n",
    "# 컬럼 타입 자동 분류\n",
    "numeric_cols = X_train_full.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
    "categorical_cols = X_train_full.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# 3-1. 결측치 처리 (Numeric)\n",
    "# [누수 방지 6]: Test 데이터 결측치는 Train 데이터의 중앙값으로 채움\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "X_train_full[numeric_cols] = imputer_num.fit_transform(X_train_full[numeric_cols])\n",
    "X_test[numeric_cols] = imputer_num.transform(X_test[numeric_cols])\n",
    "\n",
    "# 3-2. 결측치 처리 (Categorical)\n",
    "# 범주형 결측치는 'Unknown'이라는 새로운 범주로 채움 (통계값 사용 아님)\n",
    "X_train_full[categorical_cols] = X_train_full[categorical_cols].fillna(\"Unknown\")\n",
    "X_test[categorical_cols] = X_test[categorical_cols].fillna(\"Unknown\")\n",
    "\n",
    "# 3-3. Label Encoding (Test Data Unseen Label 처리 포함)\n",
    "# [누수 방지 3, 5]: pd.get_dummies 금지, LabelEncoder는 Train에만 fit\n",
    "categorical_dims = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Train 데이터로만 학습\n",
    "    le.fit(X_train_full[col].astype(str))\n",
    "    \n",
    "    # Train 변환\n",
    "    X_train_full[col] = le.transform(X_train_full[col].astype(str))\n",
    "    \n",
    "    # Test 변환 (Safe Handling)\n",
    "    # Test에만 있는 새로운 값(Unseen)은 Train의 최빈값(Mode)으로 대체하여 누수 방지 및 에러 예방\n",
    "    test_values = X_test[col].astype(str).values\n",
    "    train_mode = le.transform([le.classes_[0]])[0] # Fallback용 (실제로는 최빈값 권장하나 여기선 0번 인덱스 활용)\n",
    "    \n",
    "    # Unseen Value Masking\n",
    "    known_labels = set(le.classes_)\n",
    "    test_values_safe = [x if x in known_labels else le.classes_[0] for x in test_values]\n",
    "    \n",
    "    X_test[col] = le.transform(test_values_safe)\n",
    "    \n",
    "    # 카테고리 수 저장 (TabNet 입력용)\n",
    "    categorical_dims[col] = len(le.classes_)\n",
    "\n",
    "# 3-4. Scaling (QuantileTransformer - 상관계수 낮추기 핵심)\n",
    "# [누수 방지 4]: Scaler는 Train 데이터로만 fit\n",
    "# StandardScaler 대신 QuantileTransformer를 사용하여 분포를 정규분포로 강제 변환\n",
    "# 이는 트리 모델(AutoGluon)과 딥러닝이 데이터를 보는 방식을 근본적으로 다르게 만듦\n",
    "scaler = QuantileTransformer(output_distribution='normal', random_state=SEED)\n",
    "X_train_full[numeric_cols] = scaler.fit_transform(X_train_full[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# 데이터 타입 변환 (메모리 최적화)\n",
    "X_train_full = X_train_full.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# ==========================================\n",
    "# 4. TabNet 준비\n",
    "# ==========================================\n",
    "\n",
    "# Categorical Feature Index 추출\n",
    "cat_idxs = [i for i, f in enumerate(X_train_full.columns) if f in categorical_cols]\n",
    "cat_dims = [categorical_dims[f] for f in categorical_cols]\n",
    "\n",
    "# 학습/검증 데이터 분리 (Stratified Split)\n",
    "# [누수 방지 1]: 모델 학습 중 검증을 위해 Train set 내에서 분리 (Test set 건드리지 않음)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full.values, y_train_full, \n",
    "    test_size=0.2, random_state=SEED, stratify=y_train_full\n",
    ")\n",
    "\n",
    "# 불균형 데이터 가중치 계산\n",
    "# 계산도 오직 분리된 y_train 만을 사용\n",
    "num_pos = (y_train == 1).sum()\n",
    "num_neg = (y_train == 0).sum()\n",
    "pos_weight = num_neg / num_pos\n",
    "class_weights = torch.tensor([1.0, pos_weight], dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"Positive Class Weight: {pos_weight:.4f}\")\n",
    "\n",
    "# 2. Label Smoothing 적용을 위한 Loss 함수 교체\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, weight=None, smoothing=0.1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "    def forward(self, inputs, targets):\n",
    "        log_probs = torch.nn.functional.log_softmax(inputs, dim=-1)\n",
    "        targets_smooth = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1 - self.smoothing)\n",
    "        targets_smooth += self.smoothing / log_probs.size(1)\n",
    "        loss = (-targets_smooth * log_probs).sum(dim=-1)\n",
    "        if self.weight is not None:\n",
    "            # 타겟 클래스에 따라 가중치 적용\n",
    "            weight_per_sample = self.weight[targets]\n",
    "            loss = loss * weight_per_sample\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. TabNet 모델 학습 (상관계수 파괴 설정)\n",
    "# ==========================================\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    n_d=16, n_a=16,             # [변경] 모델 용량을 키워 더 복잡한 패턴 학습 유도\n",
    "    n_steps=3,                  # [변경] 스텝 수를 줄여 트리 모델과 다른 의사결정 깊이 유도\n",
    "    gamma=1.5, \n",
    "    n_independent=2, \n",
    "    n_shared=2,\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=4,              # [변경] 임베딩 차원을 2로 늘려 범주 간 관계 학습 강화\n",
    "    optimizer_fn=torch.optim.AdamW, # [변경] AdamW 사용 (일반화 성능 향상)\n",
    "    optimizer_params=dict(lr=2e-2, weight_decay=1e-2),\n",
    "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='entmax',\n",
    "    device_name=device,         # MPS 설정\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "loss_fn = LabelSmoothingLoss(weight=class_weights, smoothing=0.1)\n",
    "\n",
    "print(\"TabNet 학습 시작 (Quantile Transform 적용됨)...\")\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=100,             \n",
    "    patience=15,                # 참을성 조금 증가\n",
    "    batch_size=1024,            \n",
    "    virtual_batch_size=64,      # [변경] Ghost BN 사이즈를 줄여 노이즈 증가 -> 상관계수 감소 유도\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    loss_fn=loss_fn             \n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 6. Test Data 예측\n",
    "# ==========================================\n",
    "# [누수 방지 2]: Test Data는 학습에 전혀 관여하지 않고 예측에만 사용\n",
    "preds_proba = clf.predict_proba(X_test.values)\n",
    "final_probs_tabnet = preds_proba[:, 1]\n",
    "\n",
    "print(f\"\\n최종 검증 AUC: {clf.best_cost:.5f}\")\n",
    "print(\"예측 완료. 'final_probs_tabnet'에 확률값이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035e8d52-515b-4f51-9604-52e081c0c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료! 결과 저장됨: TN_0211_0120_submission.csv\n",
      "Best Validation AUC: 0.7349332536397428\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. 결과 추출\n",
    "# ==========================================\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime('%m%d_%H%M')\n",
    "file_name = f\"TN_{now}_submission.csv\"\n",
    "\n",
    "submission = pd.read_csv(\"../Data/sample_submission.csv\")\n",
    "submission['probability'] = final_probs_tabnet\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"완료! 결과 저장됨: {file_name}\")\n",
    "print(f\"Best Validation AUC: {clf.best_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d82ad-317b-4f97-aaa5-0baf66b35d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
