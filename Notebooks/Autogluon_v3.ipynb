{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_models_out\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       4.38 GB / 16.00 GB (27.4%)\n",
      "Disk Space Avail:   193.55 GB / 460.43 GB (42.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "DyStack: Disabling memory safe fit mode in DyStack because GPUs were detected and num_gpus='auto' (GPUs cannot be used in memory safe fit mode). If you want to use memory safe fit mode, manually set `num_gpus=0`.\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    227867\n",
      "Train Data Columns: 77\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4718.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 478.77 MB (10.1% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 10.1% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 25 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['불임 원인 - 여성 요인']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 3): ['ID', '불임 원인 - 정자 면역학적 요인', '불임 원인 - 정자 운동성']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', [])    : 2 | ['불임 원인 - 정자 면역학적 요인', '불임 원인 - 정자 운동성']\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])     :  2 | ['is_blastocyst', 'is_ah']\n",
      "\t\t('category', []) :  1 | ['이식배아_구간']\n",
      "\t\t('float', [])    : 33 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])      : 17 | ['배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', ...]\n",
      "\t\t('object', [])   : 20 | ['시술 시기 코드', '시술 당시 나이', '시술 유형', '배란 유도 유형', '배아 생성 주요 이유', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 20 | ['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', ...]\n",
      "\t\t('float', [])     : 29 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       :  1 | ['나이_순서']\n",
      "\t\t('int', ['bool']) : 23 | ['시술 유형', '배란 자극 여부', '착상 전 유전 검사 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', ...]\n",
      "\t1.8s = Fit runtime\n",
      "\t73 features in original data used to generate 73 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 61.51 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 598.53s of the 898.01s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=10.40%)\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=68560, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=68560, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=68560, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=68560, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 591.18s of the 890.66s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.09%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=68559, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=68559, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=68559, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=68559, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 587.32s of the 886.81s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/4.1 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 265 due to low memory. Expected memory usage reduced from 16.92% -> 15.0% of available memory...\n",
      "\t0.7285\t = Validation score   (roc_auc)\n",
      "\t9.43s\t = Training   runtime\n",
      "\t5.94s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 571.44s of the 870.92s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 251 due to low memory. Expected memory usage reduced from 17.92% -> 15.0% of available memory...\n",
      "\t0.7292\t = Validation score   (roc_auc)\n",
      "\t9.08s\t = Training   runtime\n",
      "\t5.71s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 556.21s of the 855.70s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.11% memory usage per fold, 48.21%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=24.11%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=68561, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=68561, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 554.00s of the 853.48s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 242 due to low memory. Expected memory usage reduced from 18.54% -> 15.0% of available memory...\n",
      "\t0.7309\t = Validation score   (roc_auc)\n",
      "\t7.37s\t = Training   runtime\n",
      "\t5.36s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 540.85s of the 840.33s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.4 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 223 due to low memory. Expected memory usage reduced from 20.14% -> 15.0% of available memory...\n",
      "\t0.7311\t = Validation score   (roc_auc)\n",
      "\t7.33s\t = Training   runtime\n",
      "\t5.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 528.09s of the 827.58s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.36% memory usage per fold, 77.44%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=19.36%)\n",
      "\t0.7378\t = Validation score   (roc_auc)\n",
      "\t341.29s\t = Training   runtime\n",
      "\t3.51s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 184.48s of the 483.96s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=14.83%)\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t99.14s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 83.12s of the 382.61s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=9.27%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 77.59s of the 377.08s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=13.64%)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=69625, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=69625, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=69625, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=69625, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 75.36s of the 374.85s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.97% memory usage per fold, 75.86%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=18.97%)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=69644, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=69644, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 73.58s of the 373.07s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=8.87%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 68.60s of the 368.09s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=12.09%)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=69654, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=69654, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=69654, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=69654, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 64.50s of the 363.99s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.80% memory usage per fold, 67.20%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=16.80%)\n",
      "\t0.724\t = Validation score   (roc_auc)\n",
      "\t77.89s\t = Training   runtime\n",
      "\t3.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 283.51s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.5 GB\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L1': 0.409, 'RandomForestEntr_BAG_L1': 0.045, 'ExtraTreesEntr_BAG_L1': 0.045}\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t5.08s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 278.38s of the 278.34s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.14%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=69877, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=69877, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=69877, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=69877, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 273.46s of the 273.42s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.23%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=69889, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=69889, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=69889, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=69889, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 268.88s of the 268.84s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/4.2 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 276 due to low memory. Expected memory usage reduced from 16.26% -> 15.0% of available memory...\n",
      "\t0.7441\t = Validation score   (roc_auc)\n",
      "\t17.4s\t = Training   runtime\n",
      "\t6.57s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 244.32s of the 244.28s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.8 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 250 due to low memory. Expected memory usage reduced from 17.97% -> 15.0% of available memory...\n",
      "\t0.7444\t = Validation score   (roc_auc)\n",
      "\t18.93s\t = Training   runtime\n",
      "\t6.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 218.73s of the 218.68s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.06% memory usage per fold, 48.11%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=24.06%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=70003, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=70003, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 215.97s of the 215.92s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 248 due to low memory. Expected memory usage reduced from 18.14% -> 15.0% of available memory...\n",
      "\t0.7448\t = Validation score   (roc_auc)\n",
      "\t7.83s\t = Training   runtime\n",
      "\t5.84s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 201.81s of the 201.77s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.1/3.5 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 234 due to low memory. Expected memory usage reduced from 19.21% -> 15.0% of available memory...\n",
      "\t0.7445\t = Validation score   (roc_auc)\n",
      "\t8.24s\t = Training   runtime\n",
      "\t5.7s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 187.39s of the 187.35s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.76% memory usage per fold, 43.52%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=21.76%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t132.41s\t = Training   runtime\n",
      "\t3.52s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 51.84s of the 51.79s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.37% memory usage per fold, 65.49%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=16.37%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t47.74s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 1.70s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/3.8 GB\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L2': 0.273, 'ExtraTreesGini_BAG_L2': 0.273, 'RandomForestGini_BAG_L2': 0.227, 'ExtraTreesEntr_BAG_L2': 0.227}\n",
      "\t0.7475\t = Validation score   (roc_auc)\n",
      "\t9.49s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 907.86s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2570.3 rows/s (45574 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t9.43s\t = Training   runtime\n",
      "\t5.94s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t9.08s\t = Training   runtime\n",
      "\t5.71s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.37s\t = Training   runtime\n",
      "\t5.36s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.33s\t = Training   runtime\n",
      "\t5.0s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.6/3.2 GB\n",
      "\tStopping at the best epoch learned earlier - 5.\n",
      "\t45.7s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/xgboost/sklearn.py:1118: UserWarning: [11:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/context.cc:207: Device is changed from GPU to CPU as we couldn't find any available GPU on the system.\n",
      "  self.get_booster().save_model(fname)\n",
      "\t1.98s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.6/3.9 GB\n",
      "\tStopping at the best epoch learned earlier - 0.\n",
      "\t12.8s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L1': 0.409, 'RandomForestEntr_BAG_L1': 0.045, 'ExtraTreesEntr_BAG_L1': 0.045}\n",
      "\t5.08s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t17.4s\t = Training   runtime\n",
      "\t6.57s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t18.93s\t = Training   runtime\n",
      "\t6.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t7.83s\t = Training   runtime\n",
      "\t5.84s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t8.24s\t = Training   runtime\n",
      "\t5.7s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.7/3.2 GB\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t15.6s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1\n",
      "\t1.97s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L2': 0.273, 'ExtraTreesGini_BAG_L2': 0.273, 'RandomForestGini_BAG_L2': 0.227, 'ExtraTreesEntr_BAG_L2': 0.227}\n",
      "\t9.49s\t = Training   runtime\n",
      "Refit complete, total runtime = 84.34s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                               model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                WeightedEnsemble_L2       0.743286   0.739574     roc_auc        2.561042      15.407498  461.922071                 0.001851                0.030476           5.078706            2       True          8\n",
      "1             NeuralNetFastAI_BAG_L2       0.743091   0.738640     roc_auc        6.165735      33.999425  683.941595                 1.259639                3.524777         132.409154            2       True         13\n",
      "2                     XGBoost_BAG_L2       0.742937   0.739125     roc_auc        5.532881      31.334913  599.270889                 0.626785                0.860265          47.738448            2       True         14\n",
      "3             NeuralNetFastAI_BAG_L1       0.742811   0.737840     roc_auc        1.095207       3.514432  341.289216                 1.095207                3.514432         341.289216            1       True          5\n",
      "4           WeightedEnsemble_L2_FULL       0.742602        NaN     roc_auc        1.165525            NaN   69.173944                 0.002318                     NaN           5.078706            2       True         23\n",
      "5        NeuralNetFastAI_BAG_L2_FULL       0.742385        NaN     roc_auc        2.573939            NaN  109.290833                 0.150436                     NaN          15.601070            2       True         28\n",
      "6                XGBoost_BAG_L2_FULL       0.741860        NaN     roc_auc        2.514299            NaN   95.657965                 0.090797                     NaN           1.968201            2       True         29\n",
      "7                     XGBoost_BAG_L1       0.741801   0.738452     roc_auc        0.544237       1.156034   99.139565                 0.544237                1.156034          99.139565            1       True          6\n",
      "8        NeuralNetFastAI_BAG_L1_FULL       0.741670        NaN     roc_auc        0.183145            NaN   45.703981                 0.183145                     NaN          45.703981            1       True         20\n",
      "9                XGBoost_BAG_L1_FULL       0.741103        NaN     roc_auc        0.086169            NaN    1.976674                 0.086169                     NaN           1.976674            1       True         21\n",
      "10          WeightedEnsemble_L3_FULL       0.739120        NaN     roc_auc        4.172004            NaN  155.574947                 0.002436                     NaN           9.491838            3       True         30\n",
      "11               WeightedEnsemble_L3       0.739027   0.747479     roc_auc        6.759264      54.797900  613.417624                 0.003971                0.027299           9.491838            3       True         15\n",
      "12        ExtraTreesEntr_BAG_L2_FULL       0.738490        NaN     roc_auc        2.810035            NaN  101.931055                 0.386533                5.699443           8.241291            2       True         27\n",
      "13             ExtraTreesEntr_BAG_L2       0.737827   0.744517     roc_auc        5.329746      36.174091  559.773731                 0.423650                5.699443           8.241291            2       True         12\n",
      "14             ExtraTreesGini_BAG_L2       0.737805   0.744821     roc_auc        5.334159      36.317466  559.359489                 0.428063                5.842818           7.827049            2       True         11\n",
      "15        ExtraTreesGini_BAG_L2_FULL       0.737764        NaN     roc_auc        2.829920            NaN  101.516813                 0.406417                5.842818           7.827049            2       True         26\n",
      "16           RandomForestEntr_BAG_L2       0.737665   0.744351     roc_auc        5.363358      36.658116  570.458837                 0.457263                6.183468          18.926396            2       True         10\n",
      "17      RandomForestGini_BAG_L2_FULL       0.737409        NaN     roc_auc        2.921367            NaN  111.088374                 0.497865                6.570223          17.398610            2       True         24\n",
      "18           RandomForestGini_BAG_L2       0.737364   0.744090     roc_auc        5.446318      37.044871  568.931051                 0.540222                6.570223          17.398610            2       True          9\n",
      "19      RandomForestEntr_BAG_L2_FULL       0.737200        NaN     roc_auc        2.878753            NaN  112.616160                 0.455251                6.183468          18.926396            2       True         25\n",
      "20        ExtraTreesEntr_BAG_L1_FULL       0.736573        NaN     roc_auc        0.396962       5.000357    7.334213                 0.396962                5.000357           7.334213            1       True         19\n",
      "21             ExtraTreesEntr_BAG_L1       0.736573   0.731128     roc_auc        0.458104       5.000357    7.334213                 0.458104                5.000357           7.334213            1       True          4\n",
      "22        ExtraTreesGini_BAG_L1_FULL       0.735761        NaN     roc_auc        0.420321       5.361325    7.368607                 0.420321                5.361325           7.368607            1       True         18\n",
      "23             ExtraTreesGini_BAG_L1       0.735761   0.730921     roc_auc        0.428912       5.361325    7.368607                 0.428912                5.361325           7.368607            1       True          3\n",
      "24       NeuralNetFastAI_r191_BAG_L1       0.735616   0.723961     roc_auc        1.396083       3.793834   77.891705                 1.396083                3.793834          77.891705            1       True          7\n",
      "25           RandomForestEntr_BAG_L1       0.734532   0.729200     roc_auc        0.461643       5.706199    9.080371                 0.461643                5.706199           9.080371            1       True          2\n",
      "26      RandomForestEntr_BAG_L1_FULL       0.734532        NaN     roc_auc        0.496931       5.706199    9.080371                 0.496931                5.706199           9.080371            1       True         17\n",
      "27           RandomForestGini_BAG_L1       0.733819   0.728453     roc_auc        0.521910       5.942467    9.428764                 0.521910                5.942467           9.428764            1       True          1\n",
      "28      RandomForestGini_BAG_L1_FULL       0.733819        NaN     roc_auc        0.551249       5.942467    9.428764                 0.551249                5.942467           9.428764            1       True         16\n",
      "29  NeuralNetFastAI_r191_BAG_L1_FULL       0.727582        NaN     roc_auc        0.288726            NaN   12.797154                 0.288726                     NaN          12.797154            1       True         22\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t1006s\t = DyStack   runtime |\t2594s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 2594s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out\"\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 77\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4937.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 578.74 MB (11.7% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 11.7% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 25 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['불임 원인 - 여성 요인']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['ID', '불임 원인 - 정자 면역학적 요인']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', [])    : 1 | ['불임 원인 - 정자 면역학적 요인']\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])     :  2 | ['is_blastocyst', 'is_ah']\n",
      "\t\t('category', []) :  1 | ['이식배아_구간']\n",
      "\t\t('float', [])    : 33 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])      : 18 | ['배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', ...]\n",
      "\t\t('object', [])   : 20 | ['시술 시기 코드', '시술 당시 나이', '시술 유형', '배란 유도 유형', '배아 생성 주요 이유', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 20 | ['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', ...]\n",
      "\t\t('float', [])     : 29 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       :  1 | ['나이_순서']\n",
      "\t\t('int', ['bool']) : 24 | ['시술 유형', '배란 자극 여부', '착상 전 유전 검사 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t74 features in original data used to generate 74 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 69.44 MB (1.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.51s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2591.26s of the 2591.25s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.76%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=70759, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=70759, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=70759, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=70759, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2587.87s of the 2587.86s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=12.29%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=70758, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=70758, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=70758, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=70758, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2585.65s of the 2585.65s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/3.8 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 249 due to low memory. Expected memory usage reduced from 18.07% -> 15.0% of available memory...\n",
      "\t0.7303\t = Validation score   (roc_auc)\n",
      "\t10.82s\t = Training   runtime\n",
      "\t6.24s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2568.07s of the 2568.06s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/3.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 238 due to low memory. Expected memory usage reduced from 18.85% -> 15.0% of available memory...\n",
      "\t0.731\t = Validation score   (roc_auc)\n",
      "\t9.85s\t = Training   runtime\n",
      "\t6.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2551.79s of the 2551.78s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.15% memory usage per fold, 48.29%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=24.15%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=70770, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=70770, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2549.58s of the 2549.57s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/3.9 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 253 due to low memory. Expected memory usage reduced from 17.74% -> 15.0% of available memory...\n",
      "\t0.7323\t = Validation score   (roc_auc)\n",
      "\t8.72s\t = Training   runtime\n",
      "\t6.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2534.08s of the 2534.08s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/3.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 245 due to low memory. Expected memory usage reduced from 18.33% -> 15.0% of available memory...\n",
      "\t0.7323\t = Validation score   (roc_auc)\n",
      "\t9.08s\t = Training   runtime\n",
      "\t6.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2518.50s of the 2518.50s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.73% memory usage per fold, 78.94%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=19.73%)\n",
      "\t0.7365\t = Validation score   (roc_auc)\n",
      "\t1001.46s\t = Training   runtime\n",
      "\t2.0s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1514.57s of the 1514.56s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=14.34%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t118.25s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1394.05s of the 1394.05s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=7.79%)\n",
      "\t0.7373\t = Validation score   (roc_auc)\n",
      "\t1115.85s\t = Training   runtime\n",
      "\t3.75s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 275.96s of the 275.95s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=12.68%)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=75368, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=75368, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=75368, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=75368, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 273.50s of the 273.50s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.03% memory usage per fold, 68.14%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=17.03%)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tFailed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=75369, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1033, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.UnserializableException: Failed to deserialize exception. Refer to https://docs.ray.io/en/latest/ray-core/objects/serialization.html#custom-serializers-for-exceptions for more information.\n",
      "Original exception:\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_ray_fit()\u001b[39m (pid=75369, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 236, in _fit\n",
      "    params[\"iterations\"] = self._estimate_iter_in_time_gpu(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 292, in _estimate_iter_in_time_gpu\n",
      "    sample_model.fit(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/trainer_env.cpp:9: Environment for task type [GPU] not found\n",
      "\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 270.53s of the 270.53s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=7.89%)\n",
      "\t0.7351\t = Validation score   (roc_auc)\n",
      "\t210.8s\t = Training   runtime\n",
      "\t4.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 57.46s of the 57.46s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.00%)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=75813, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=75813, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\n",
      "    out = self.ray.get(finished)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 2972, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=75813, ip=127.0.0.1)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 3660, in __init__\n",
      "    _safe_call(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=75813, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 360, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/engine.py\", line 301, in train\n",
      "    booster.add_valid(valid_set, name_valid_set)\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 4058, in add_valid\n",
      "    data.construct()._handle,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2539, in construct\n",
      "    self._lazy_init(\n",
      "  File \"/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/lightgbm/basic.py\", line 2153, in _lazy_init\n",
      "    raise TypeError(f\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\")\n",
      "TypeError: Wrong type(str) or unknown name(시술 시기 코드) in categorical_feature\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 55.10s of the 55.10s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=14.32%)\n",
      "\t0.7247\t = Validation score   (roc_auc)\n",
      "\t77.65s\t = Training   runtime\n",
      "\t3.72s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -24.60s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.4 GB\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.44, 'NeuralNetTorch_BAG_L1': 0.24, 'NeuralNetFastAI_BAG_L1': 0.2, 'RandomForestEntr_BAG_L1': 0.08, 'NeuralNetFastAI_r191_BAG_L1': 0.04}\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t6.7s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2625.15s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4216.7 rows/s (51271 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.82s\t = Training   runtime\n",
      "\t6.24s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t9.85s\t = Training   runtime\n",
      "\t6.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t8.72s\t = Training   runtime\n",
      "\t6.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t9.08s\t = Training   runtime\n",
      "\t6.07s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.7/4.0 GB\n",
      "\tStopping at the best epoch learned earlier - 9.\n",
      "\t82.88s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1\n",
      "\t2.13s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.3/4.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t127.24s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.3/4.0 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t47.33s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=1, mem=0.7/4.0 GB\n",
      "\tStopping at the best epoch learned earlier - 0.\n",
      "\t13.27s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.44, 'NeuralNetTorch_BAG_L1': 0.24, 'NeuralNetFastAI_BAG_L1': 0.2, 'RandomForestEntr_BAG_L1': 0.08, 'NeuralNetFastAI_r191_BAG_L1': 0.04}\n",
      "\t6.7s\t = Training   runtime\n",
      "Refit complete, total runtime = 275.56s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. 파생변수 생성\n",
    "# ==========================================\n",
    "\n",
    "def derive_features(df):\n",
    "    \n",
    "    df['is_blastocyst'] = df['특정 시술 유형'].str.contains('BLASTOCYST', case=False, na=False)\n",
    "    df['is_ah'] = df['특정 시술 유형'].str.contains('AH', case=False, na=False)\n",
    "    \n",
    "    elderly_categories = ['만35-37세', '만38-39세', '만40-42세', '만43-44세', '만45-50세']\n",
    "    df['고령 여부'] = df['시술 당시 나이'].isin(elderly_categories).astype(int)\n",
    "\n",
    "    age_order = {'만18-34세': 1, '만35-37세': 2, '만38-39세': 3, '만40-42세': 4, '만43-44세': 5, '만45-50세': 6, '알 수 없음': 0}\n",
    "    df['나이_순서'] = df['시술 당시 나이'].map(age_order)\n",
    "    df['나이x배아'] = df['나이_순서'] * df['이식된 배아 수']\n",
    "\n",
    "    df['배아 발달 기간'] = df['배아 이식 경과일'] - df['난자 혼합 경과일']\n",
    "    df['배아 생성 효율'] = df['저장된 배아 수'] / (df['저장된 신선 난자 수'] + 1e-6)\n",
    "    df['이식 비중'] = df['이식된 배아 수'] / (df['이식된 배아 수'] + df['저장된 배아 수'] + 1e-6)\n",
    "\n",
    "    df['이식배아_구간'] = pd.cut(\n",
    "    df['이식된 배아 수'].fillna(0),\n",
    "    bins=[-float('inf'), 0, 2, float('inf')],\n",
    "    labels=['0개', '1-2개', '3개 이상']\n",
    "    )\n",
    "\n",
    "    def clean_treatment(text): \n",
    "        text = str(text).upper()\n",
    "        if 'ICSI' in text:\n",
    "            return 'ICSI'\n",
    "        if 'IVF' in text:\n",
    "            return 'IVF'\n",
    "        if 'IUI' in text:\n",
    "            return 'IUI'\n",
    "        return 'Other'\n",
    "\n",
    "    df['시술유형_정제'] = df['특정 시술 유형'].apply(clean_treatment)\n",
    "    \n",
    "    df.drop('특정 시술 유형', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = derive_features(train_df)\n",
    "test_df = derive_features(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 모델 학습 설정\n",
    "# ==========================================\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target, \n",
    "    eval_metric='roc_auc',\n",
    "    path='ag_models_out',\n",
    ").fit(\n",
    "    train_data=train_df,\n",
    "    time_limit=3600,\n",
    "    presets='best_quality',\n",
    "    ag_args_fit={'num_gpus': 1},\n",
    "    num_stack_levels=3,\n",
    "    num_bag_folds=5,\n",
    "    refit_full=True\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\n",
    "# ==========================================\n",
    "\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "final_probs = pred_probs.iloc[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c7c3f8-495c-4d28-9be8-c868762a4046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.740187</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>16.987759</td>\n",
       "      <td>2329.772244</td>\n",
       "      <td>0.030427</td>\n",
       "      <td>6.704284</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.738915</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.477447</td>\n",
       "      <td>118.253129</td>\n",
       "      <td>1.477447</td>\n",
       "      <td>118.253129</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.737321</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.753271</td>\n",
       "      <td>1115.854576</td>\n",
       "      <td>3.753271</td>\n",
       "      <td>1115.854576</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.736483</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.998977</td>\n",
       "      <td>1001.462465</td>\n",
       "      <td>1.998977</td>\n",
       "      <td>1001.462465</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
       "      <td>0.735102</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.045673</td>\n",
       "      <td>210.800935</td>\n",
       "      <td>4.045673</td>\n",
       "      <td>210.800935</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.732316</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.073806</td>\n",
       "      <td>9.081410</td>\n",
       "      <td>6.073806</td>\n",
       "      <td>9.081410</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.732260</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.307771</td>\n",
       "      <td>8.722309</td>\n",
       "      <td>6.307771</td>\n",
       "      <td>8.722309</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.731049</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.005398</td>\n",
       "      <td>9.848547</td>\n",
       "      <td>6.005398</td>\n",
       "      <td>9.848547</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.730288</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.243716</td>\n",
       "      <td>10.821787</td>\n",
       "      <td>6.243716</td>\n",
       "      <td>10.821787</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
       "      <td>0.724671</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.722238</td>\n",
       "      <td>77.649243</td>\n",
       "      <td>3.722238</td>\n",
       "      <td>77.649243</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.005398</td>\n",
       "      <td>9.848547</td>\n",
       "      <td>6.005398</td>\n",
       "      <td>9.848547</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.073806</td>\n",
       "      <td>9.081410</td>\n",
       "      <td>6.073806</td>\n",
       "      <td>9.081410</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestGini_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.243716</td>\n",
       "      <td>10.821787</td>\n",
       "      <td>6.243716</td>\n",
       "      <td>10.821787</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExtraTreesGini_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.307771</td>\n",
       "      <td>8.722309</td>\n",
       "      <td>6.307771</td>\n",
       "      <td>8.722309</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130708</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242.069875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.704284</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeuralNetTorch_r79_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.329916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.329916</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.236393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.236393</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.273635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.273635</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.876308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.876308</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model  score_val eval_metric  pred_time_val  \\\n",
       "0                WeightedEnsemble_L2   0.740187     roc_auc      16.987759   \n",
       "1                     XGBoost_BAG_L1   0.738915     roc_auc       1.477447   \n",
       "2              NeuralNetTorch_BAG_L1   0.737321     roc_auc       3.753271   \n",
       "3             NeuralNetFastAI_BAG_L1   0.736483     roc_auc       1.998977   \n",
       "4          NeuralNetTorch_r79_BAG_L1   0.735102     roc_auc       4.045673   \n",
       "5              ExtraTreesEntr_BAG_L1   0.732316     roc_auc       6.073806   \n",
       "6              ExtraTreesGini_BAG_L1   0.732260     roc_auc       6.307771   \n",
       "7            RandomForestEntr_BAG_L1   0.731049     roc_auc       6.005398   \n",
       "8            RandomForestGini_BAG_L1   0.730288     roc_auc       6.243716   \n",
       "9        NeuralNetFastAI_r191_BAG_L1   0.724671     roc_auc       3.722238   \n",
       "10      RandomForestEntr_BAG_L1_FULL        NaN     roc_auc       6.005398   \n",
       "11        ExtraTreesEntr_BAG_L1_FULL        NaN     roc_auc       6.073806   \n",
       "12      RandomForestGini_BAG_L1_FULL        NaN     roc_auc       6.243716   \n",
       "13        ExtraTreesGini_BAG_L1_FULL        NaN     roc_auc       6.307771   \n",
       "14               XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "15          WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN   \n",
       "16    NeuralNetTorch_r79_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "17        NeuralNetTorch_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "18  NeuralNetFastAI_r191_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "19       NeuralNetFastAI_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "\n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   2329.772244                0.030427           6.704284            2   \n",
       "1    118.253129                1.477447         118.253129            1   \n",
       "2   1115.854576                3.753271        1115.854576            1   \n",
       "3   1001.462465                1.998977        1001.462465            1   \n",
       "4    210.800935                4.045673         210.800935            1   \n",
       "5      9.081410                6.073806           9.081410            1   \n",
       "6      8.722309                6.307771           8.722309            1   \n",
       "7      9.848547                6.005398           9.848547            1   \n",
       "8     10.821787                6.243716          10.821787            1   \n",
       "9     77.649243                3.722238          77.649243            1   \n",
       "10     9.848547                6.005398           9.848547            1   \n",
       "11     9.081410                6.073806           9.081410            1   \n",
       "12    10.821787                6.243716          10.821787            1   \n",
       "13     8.722309                6.307771           8.722309            1   \n",
       "14     2.130708                     NaN           2.130708            1   \n",
       "15   242.069875                     NaN           6.704284            2   \n",
       "16    47.329916                     NaN          47.329916            1   \n",
       "17   127.236393                     NaN         127.236393            1   \n",
       "18    13.273635                     NaN          13.273635            1   \n",
       "19    82.876308                     NaN          82.876308            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         10  \n",
       "1        True          6  \n",
       "2        True          7  \n",
       "3        True          5  \n",
       "4        True          8  \n",
       "5        True          4  \n",
       "6        True          3  \n",
       "7        True          2  \n",
       "8        True          1  \n",
       "9        True          9  \n",
       "10       True         12  \n",
       "11       True         14  \n",
       "12       True         11  \n",
       "13       True         13  \n",
       "14       True         16  \n",
       "15       True         20  \n",
       "16       True         18  \n",
       "17       True         17  \n",
       "18       True         19  \n",
       "19       True         15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. 리더보드 (오름차순 정렬) ---\n",
    "lb = predictor.leaderboard(silent=True)\n",
    "display(lb.sort_values(by='score_val', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ID', '불임 원인 - 여성 요인', '불임 원인 - 정자 면역학적 요인']\n",
      "Computing feature importance via permutation shuffling for 74 features using 5000 rows with 5 shuffle sets...\n",
      "\t479.31s\t= Expected runtime (95.86s per shuffle set)\n",
      "\t320.08s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>혼합된 난자 수</th>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>3.748945e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.007552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파트너 정자와 혼합된 난자 수</th>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>7.814105e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007140</td>\n",
       "      <td>0.006351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총 시술 횟수</th>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2.156670e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.004574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입 후 저장된 배아 수</th>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>8.448503e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수집된 신선 난자 수</th>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>9.254406e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.008545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불임 원인 - 배란 장애</th>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1.235072e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>배아 생성 효율</th>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>1.249304e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.002625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>고령 여부</th>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>1.325257e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.003118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술 당시 나이</th>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>1.549788e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>0.006891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저장된 배아 수</th>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1.581407e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불명확 불임 원인</th>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>1.654863e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.001651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>배아 이식 경과일</th>\n",
       "      <td>0.012384</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>1.771557e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013966</td>\n",
       "      <td>0.010801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입에서 생성된 배아 수</th>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>2.209543e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.005566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술유형_정제</th>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>2.486495e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>클리닉 내 총 시술 횟수</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>2.497908e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.006204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DI 시술 횟수</th>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2.567416e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>나이_순서</th>\n",
       "      <td>0.035122</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>2.582114e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.040055</td>\n",
       "      <td>0.030189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>정자 기증자 나이</th>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>4.161279e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.001675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입된 난자 수</th>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>4.442488e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.004889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>해동된 배아 수</th>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>4.820695e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.001337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입 배아 이식 수</th>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>5.129839e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기증자 정자와 혼합된 난자 수</th>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>5.197882e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>나이x배아</th>\n",
       "      <td>0.039224</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>5.748299e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.032490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IVF 시술 횟수</th>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>6.080278e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.006114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>남성 부 불임 원인</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.071725e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IVF 임신 횟수</th>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>1.139742e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술 시기 코드</th>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>1.232856e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.007031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이식된 배아 수</th>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>1.549199e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.027091</td>\n",
       "      <td>0.017309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불임 원인 - 남성 요인</th>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.780887e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총 생성 배아 수</th>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>2.158821e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021669</td>\n",
       "      <td>0.013294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance    stddev       p_value  n  p99_high   p99_low\n",
       "혼합된 난자 수            0.007939  0.000188  3.748945e-08  5  0.008325  0.007552\n",
       "파트너 정자와 혼합된 난자 수    0.006745  0.000192  7.814105e-08  5  0.007140  0.006351\n",
       "총 시술 횟수             0.004947  0.000181  2.156670e-07  5  0.005320  0.004574\n",
       "미세주입 후 저장된 배아 수     0.002102  0.000108  8.448503e-07  5  0.002325  0.001879\n",
       "수집된 신선 난자 수         0.009586  0.000506  9.254406e-07  5  0.010627  0.008545\n",
       "불임 원인 - 배란 장애       0.001691  0.000096  1.235072e-06  5  0.001888  0.001494\n",
       "배아 생성 효율            0.002973  0.000169  1.249304e-06  5  0.003321  0.002625\n",
       "고령 여부               0.003539  0.000204  1.325257e-06  5  0.003959  0.003118\n",
       "시술 당시 나이            0.007863  0.000472  1.549788e-06  5  0.008834  0.006891\n",
       "저장된 배아 수            0.003230  0.000195  1.581407e-06  5  0.003631  0.002829\n",
       "불명확 불임 원인           0.001888  0.000115  1.654863e-06  5  0.002125  0.001651\n",
       "배아 이식 경과일           0.012384  0.000769  1.771557e-06  5  0.013966  0.010801\n",
       "미세주입에서 생성된 배아 수     0.006435  0.000422  2.209543e-06  5  0.007304  0.005566\n",
       "시술유형_정제             0.002925  0.000198  2.486495e-06  5  0.003332  0.002518\n",
       "클리닉 내 총 시술 횟수       0.007208  0.000488  2.497908e-06  5  0.008212  0.006204\n",
       "DI 시술 횟수            0.000976  0.000066  2.567416e-06  5  0.001113  0.000839\n",
       "나이_순서               0.035122  0.002396  2.582114e-06  5  0.040055  0.030189\n",
       "정자 기증자 나이           0.001990  0.000153  4.161279e-06  5  0.002305  0.001675\n",
       "미세주입된 난자 수          0.005827  0.000455  4.442488e-06  5  0.006765  0.004889\n",
       "해동된 배아 수            0.001600  0.000128  4.820695e-06  5  0.001863  0.001337\n",
       "미세주입 배아 이식 수        0.003136  0.000254  5.129839e-06  5  0.003659  0.002613\n",
       "기증자 정자와 혼합된 난자 수    0.001187  0.000097  5.197882e-06  5  0.001386  0.000989\n",
       "나이x배아               0.039224  0.003271  5.748299e-06  5  0.045959  0.032490\n",
       "IVF 시술 횟수           0.007403  0.000626  6.080278e-06  5  0.008693  0.006114\n",
       "남성 부 불임 원인          0.000269  0.000026  1.071725e-05  5  0.000323  0.000215\n",
       "IVF 임신 횟수           0.001874  0.000186  1.139742e-05  5  0.002256  0.001492\n",
       "시술 시기 코드            0.008878  0.000897  1.232856e-05  5  0.010724  0.007031\n",
       "이식된 배아 수            0.022200  0.002375  1.549199e-05  5  0.027091  0.017309\n",
       "불임 원인 - 남성 요인       0.004284  0.000475  1.780887e-05  5  0.005261  0.003306\n",
       "총 생성 배아 수           0.017482  0.002034  2.158821e-05  5  0.021669  0.013294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 2. 피처 중요도 ---\n",
    "fi = predictor.feature_importance(data=train_df.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "display(fi.sort_values(by='p_value', ascending=True).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b83f3690-df0d-4851-bd9c-23cfedce0194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>혼합된 난자 수</th>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>3.748945e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.007552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파트너 정자와 혼합된 난자 수</th>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>7.814105e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007140</td>\n",
       "      <td>0.006351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총 시술 횟수</th>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2.156670e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.004574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입 후 저장된 배아 수</th>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>8.448503e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수집된 신선 난자 수</th>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>9.254406e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.008545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불임 원인 - 배란 장애</th>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1.235072e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>배아 생성 효율</th>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>1.249304e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.002625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>고령 여부</th>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>1.325257e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.003118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술 당시 나이</th>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>1.549788e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>0.006891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저장된 배아 수</th>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1.581407e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불명확 불임 원인</th>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>1.654863e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.001651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>배아 이식 경과일</th>\n",
       "      <td>0.012384</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>1.771557e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013966</td>\n",
       "      <td>0.010801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입에서 생성된 배아 수</th>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>2.209543e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.005566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술유형_정제</th>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>2.486495e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>클리닉 내 총 시술 횟수</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>2.497908e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.006204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DI 시술 횟수</th>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2.567416e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>나이_순서</th>\n",
       "      <td>0.035122</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>2.582114e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.040055</td>\n",
       "      <td>0.030189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>정자 기증자 나이</th>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>4.161279e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.001675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입된 난자 수</th>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>4.442488e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.004889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>해동된 배아 수</th>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>4.820695e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.001337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미세주입 배아 이식 수</th>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>5.129839e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기증자 정자와 혼합된 난자 수</th>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>5.197882e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>나이x배아</th>\n",
       "      <td>0.039224</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>5.748299e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.032490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IVF 시술 횟수</th>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>6.080278e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.006114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>남성 부 불임 원인</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.071725e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IVF 임신 횟수</th>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>1.139742e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시술 시기 코드</th>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>1.232856e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.007031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이식된 배아 수</th>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>1.549199e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.027091</td>\n",
       "      <td>0.017309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불임 원인 - 남성 요인</th>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.780887e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총 생성 배아 수</th>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>2.158821e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021669</td>\n",
       "      <td>0.013294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance    stddev       p_value  n  p99_high   p99_low\n",
       "혼합된 난자 수            0.007939  0.000188  3.748945e-08  5  0.008325  0.007552\n",
       "파트너 정자와 혼합된 난자 수    0.006745  0.000192  7.814105e-08  5  0.007140  0.006351\n",
       "총 시술 횟수             0.004947  0.000181  2.156670e-07  5  0.005320  0.004574\n",
       "미세주입 후 저장된 배아 수     0.002102  0.000108  8.448503e-07  5  0.002325  0.001879\n",
       "수집된 신선 난자 수         0.009586  0.000506  9.254406e-07  5  0.010627  0.008545\n",
       "불임 원인 - 배란 장애       0.001691  0.000096  1.235072e-06  5  0.001888  0.001494\n",
       "배아 생성 효율            0.002973  0.000169  1.249304e-06  5  0.003321  0.002625\n",
       "고령 여부               0.003539  0.000204  1.325257e-06  5  0.003959  0.003118\n",
       "시술 당시 나이            0.007863  0.000472  1.549788e-06  5  0.008834  0.006891\n",
       "저장된 배아 수            0.003230  0.000195  1.581407e-06  5  0.003631  0.002829\n",
       "불명확 불임 원인           0.001888  0.000115  1.654863e-06  5  0.002125  0.001651\n",
       "배아 이식 경과일           0.012384  0.000769  1.771557e-06  5  0.013966  0.010801\n",
       "미세주입에서 생성된 배아 수     0.006435  0.000422  2.209543e-06  5  0.007304  0.005566\n",
       "시술유형_정제             0.002925  0.000198  2.486495e-06  5  0.003332  0.002518\n",
       "클리닉 내 총 시술 횟수       0.007208  0.000488  2.497908e-06  5  0.008212  0.006204\n",
       "DI 시술 횟수            0.000976  0.000066  2.567416e-06  5  0.001113  0.000839\n",
       "나이_순서               0.035122  0.002396  2.582114e-06  5  0.040055  0.030189\n",
       "정자 기증자 나이           0.001990  0.000153  4.161279e-06  5  0.002305  0.001675\n",
       "미세주입된 난자 수          0.005827  0.000455  4.442488e-06  5  0.006765  0.004889\n",
       "해동된 배아 수            0.001600  0.000128  4.820695e-06  5  0.001863  0.001337\n",
       "미세주입 배아 이식 수        0.003136  0.000254  5.129839e-06  5  0.003659  0.002613\n",
       "기증자 정자와 혼합된 난자 수    0.001187  0.000097  5.197882e-06  5  0.001386  0.000989\n",
       "나이x배아               0.039224  0.003271  5.748299e-06  5  0.045959  0.032490\n",
       "IVF 시술 횟수           0.007403  0.000626  6.080278e-06  5  0.008693  0.006114\n",
       "남성 부 불임 원인          0.000269  0.000026  1.071725e-05  5  0.000323  0.000215\n",
       "IVF 임신 횟수           0.001874  0.000186  1.139742e-05  5  0.002256  0.001492\n",
       "시술 시기 코드            0.008878  0.000897  1.232856e-05  5  0.010724  0.007031\n",
       "이식된 배아 수            0.022200  0.002375  1.549199e-05  5  0.027091  0.017309\n",
       "불임 원인 - 남성 요인       0.004284  0.000475  1.780887e-05  5  0.005261  0.003306\n",
       "총 생성 배아 수           0.017482  0.002034  2.158821e-05  5  0.021669  0.013294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fi.sort_values(by='p_value').head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 제출 파일 생성 ---\n",
    "# submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "# submission['probability'] = final_probs.values\n",
    "\n",
    "# # 현재 시간 가져오기 (예: 0206_1031)\n",
    "# now = datetime.now().strftime('%m%d_%H%M')\n",
    "# file_name = f\"{now}_submission.csv\"\n",
    "# submission.to_csv(file_name, index=False)\n",
    "\n",
    "# print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835eaff4-be75-49e5-afb1-cd1e4c4982f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
