{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_models_out\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       4.12 GB / 16.00 GB (25.8%)\n",
      "Disk Space Avail:   173.06 GB / 460.43 GB (37.6%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "DyStack: Disabling memory safe fit mode in DyStack because GPUs were detected and num_gpus='auto' (GPUs cannot be used in memory safe fit mode). If you want to use memory safe fit mode, manually set `num_gpus=0`.\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    182293\n",
      "Train Data Columns: 63\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4528.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 348.63 MB (7.7% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 7.7% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 38 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])    :  6 | ['배란 자극 여부', '불명확 불임 원인', '나이_순서', '나이_세분화', '여성_결함_점수', ...]\n",
      "\t\t('object', []) : 18 | ['시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', '클리닉 내 총 시술 횟수', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 18 | ['시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', '클리닉 내 총 시술 횟수', ...]\n",
      "\t\t('float', [])     : 34 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       :  4 | ['나이_순서', '나이_세분화', '여성_결함_점수', '남성_결함_점수']\n",
      "\t\t('int', ['bool']) :  6 | ['배란 자극 여부', '착상 전 유전 검사 사용 여부', '불명확 불임 원인', 'PGD 시술 여부', 'PGS 시술 여부', ...]\n",
      "\t1.3s = Fit runtime\n",
      "\t62 features in original data used to generate 62 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 57.03 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Included models: ['GBM', 'CAT', 'XGB', 'RF', 'XT', 'NN_TORCH'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 85 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1198.72s of the 1798.53s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.90%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t4.69s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1191.35s of the 1791.16s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.58%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t3.88s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1185.56s of the 1785.37s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/4.2 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 292 due to low memory. Expected memory usage reduced from 15.36% -> 15.0% of available memory...\n",
      "\t0.7222\t = Validation score   (roc_auc)\n",
      "\t8.97s\t = Training   runtime\n",
      "\t5.39s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1170.77s of the 1770.57s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/3.5 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 237 due to low memory. Expected memory usage reduced from 18.97% -> 15.0% of available memory...\n",
      "\t0.7228\t = Validation score   (roc_auc)\n",
      "\t7.75s\t = Training   runtime\n",
      "\t4.62s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1157.95s of the 1757.76s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.27% memory usage per fold, 46.55%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=23.27%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t437.57s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 718.25s of the 1318.05s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/4.2 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 282 due to low memory. Expected memory usage reduced from 15.92% -> 15.0% of available memory...\n",
      "\t0.7278\t = Validation score   (roc_auc)\n",
      "\t7.35s\t = Training   runtime\n",
      "\t5.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 705.29s of the 1305.10s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/4.0 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 268 due to low memory. Expected memory usage reduced from 16.74% -> 15.0% of available memory...\n",
      "\t0.728\t = Validation score   (roc_auc)\n",
      "\t7.22s\t = Training   runtime\n",
      "\t4.84s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 692.79s of the 1292.59s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.78%)\n",
      "\t0.7374\t = Validation score   (roc_auc)\n",
      "\t10.13s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 680.30s of the 1280.11s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.11%)\n",
      "\t0.7362\t = Validation score   (roc_auc)\n",
      "\t80.68s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 597.53s of the 1197.34s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.31%)\n",
      "\t0.7364\t = Validation score   (roc_auc)\n",
      "\t8.3s\t = Training   runtime\n",
      "\t1.93s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 586.53s of the 1186.33s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.46% memory usage per fold, 77.85%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=19.46%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t39.03s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 545.58s of the 1145.39s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.99%)\n",
      "\t0.7359\t = Validation score   (roc_auc)\n",
      "\t132.36s\t = Training   runtime\n",
      "\t1.6s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 410.70s of the 1010.51s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.86%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t12.97s\t = Training   runtime\n",
      "\t4.31s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 394.51s of the 994.32s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.36% memory usage per fold, 73.46%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=18.36%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t95.35s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 297.08s of the 896.89s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.81%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t23.4s\t = Training   runtime\n",
      "\t5.44s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 270.02s of the 869.82s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.41%)\n",
      "\t0.7318\t = Validation score   (roc_auc)\n",
      "\t205.49s\t = Training   runtime\n",
      "\t2.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 62.52s of the 662.32s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=15.51%)\n",
      "\t0.7353\t = Validation score   (roc_auc)\n",
      "\t29.41s\t = Training   runtime\n",
      "\t1.9s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 30.33s of the 630.14s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/5.3 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 172 due to low time. Expected time usage reduced from 52.4s -> 30.2s...\n",
      "\t0.7103\t = Validation score   (roc_auc)\n",
      "\t17.49s\t = Training   runtime\n",
      "\t3.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 9.19s of the 609.00s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.58% memory usage per fold, 66.33%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=16.58%)\n",
      "\t0.7291\t = Validation score   (roc_auc)\n",
      "\t7.03s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 599.60s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/3.7 GB\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.391, 'CatBoost_r9_BAG_L1': 0.217, 'LightGBMXT_BAG_L1': 0.13, 'NeuralNetTorch_BAG_L1': 0.087, 'NeuralNetTorch_r79_BAG_L1': 0.087, 'RandomForestEntr_BAG_L1': 0.043, 'LightGBM_r96_BAG_L1': 0.043}\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t10.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Included models: ['GBM', 'CAT', 'XGB', 'RF', 'XT', 'NN_TORCH'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 85 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 589.03s of the 588.94s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.26%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t4.01s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 583.05s of the 582.96s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.86%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t3.73s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 577.35s of the 577.26s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/3.4 GB\n",
      "\t0.7444\t = Validation score   (roc_auc)\n",
      "\t32.2s\t = Training   runtime\n",
      "\t6.4s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 538.17s of the 538.08s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/3.8 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 251 due to low memory. Expected memory usage reduced from 17.88% -> 15.0% of available memory...\n",
      "\t0.744\t = Validation score   (roc_auc)\n",
      "\t35.9s\t = Training   runtime\n",
      "\t6.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 495.42s of the 495.33s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.21% memory usage per fold, 48.42%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=24.21%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t250.31s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 242.69s of the 242.61s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/4.8 GB\n",
      "\t0.7488\t = Validation score   (roc_auc)\n",
      "\t9.52s\t = Training   runtime\n",
      "\t6.19s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 226.34s of the 226.25s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.8/3.8 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 255 due to low memory. Expected memory usage reduced from 17.65% -> 15.0% of available memory...\n",
      "\t0.7476\t = Validation score   (roc_auc)\n",
      "\t9.29s\t = Training   runtime\n",
      "\t5.24s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 211.26s of the 211.17s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.57% memory usage per fold, 66.29%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=16.57%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t12.34s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 196.14s of the 196.05s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.49%)\n",
      "\t0.7376\t = Validation score   (roc_auc)\n",
      "\t78.32s\t = Training   runtime\n",
      "\t1.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 115.30s of the 115.22s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.57%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t10.27s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 102.22s of the 102.13s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.77% memory usage per fold, 75.08%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=18.77%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t41.53s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 58.61s of the 58.52s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.83%)\n",
      "\t0.7378\t = Validation score   (roc_auc)\n",
      "\t45.76s\t = Training   runtime\n",
      "\t1.85s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 10.01s of the 9.92s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.15%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t7.98s\t = Training   runtime\n",
      "\t2.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -1.25s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/3.6 GB\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.421, 'ExtraTreesEntr_BAG_L2': 0.263, 'RandomForestGini_BAG_L2': 0.158, 'RandomForestEntr_BAG_L2': 0.158}\n",
      "\t0.7507\t = Validation score   (roc_auc)\n",
      "\t18.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1819.36s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1167.8 rows/s (36459 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.9 GB\n",
      "\t2.11s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.9 GB\n",
      "\t1.83s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t8.97s\t = Training   runtime\n",
      "\t5.39s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.75s\t = Training   runtime\n",
      "\t4.62s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t70.06s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.35s\t = Training   runtime\n",
      "\t5.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.22s\t = Training   runtime\n",
      "\t4.84s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.67s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/3.9 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t24.19s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.0 GB\n",
      "\t6.2s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t9.85s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.0 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t49.47s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.1 GB\n",
      "\t8.49s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t27.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.2 GB\n",
      "\t9.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.2 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t71.81s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t3.7s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t17.49s\t = Training   runtime\n",
      "\t3.32s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.79s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.391, 'CatBoost_r9_BAG_L1': 0.217, 'LightGBMXT_BAG_L1': 0.13, 'NeuralNetTorch_BAG_L1': 0.087, 'NeuralNetTorch_r79_BAG_L1': 0.087, 'RandomForestEntr_BAG_L1': 0.043, 'LightGBM_r96_BAG_L1': 0.043}\n",
      "\t10.52s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.4 GB\n",
      "\t1.87s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.4 GB\n",
      "\t1.72s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t32.2s\t = Training   runtime\n",
      "\t6.4s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t35.9s\t = Training   runtime\n",
      "\t6.29s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t41.96s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t9.52s\t = Training   runtime\n",
      "\t6.19s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t9.29s\t = Training   runtime\n",
      "\t5.24s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.84s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.2 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t22.25s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.0 GB\n",
      "\t7.52s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t10.88s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t31.82s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.4 GB\n",
      "\t6.19s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.421, 'ExtraTreesEntr_BAG_L2': 0.263, 'RandomForestGini_BAG_L2': 0.158, 'RandomForestEntr_BAG_L2': 0.158}\n",
      "\t18.03s\t = Training   runtime\n",
      "Refit complete, total runtime = 421.68s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                             model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             CatBoost_BAG_L2_FULL       0.736369        NaN     roc_auc        4.460700            NaN   378.497806                 0.022586                     NaN          41.960926            2       True         59\n",
      "1                  CatBoost_BAG_L2       0.736303   0.739219     roc_auc        9.957397      45.103846  1389.375966                 0.064512                0.105370         250.309547            2       True         25\n",
      "2             CatBoost_r177_BAG_L2       0.736294   0.739210     roc_auc        9.935189      45.104379  1180.598859                 0.042304                0.105903          41.532440            2       True         31\n",
      "3          CatBoost_r9_BAG_L1_FULL       0.736273        NaN     roc_auc        0.035517            NaN    27.288214                 0.035517                     NaN          27.288214            1       True         48\n",
      "4             LightGBM_r131_BAG_L2       0.736262   0.739522     roc_auc       10.362370      47.856256  1147.047558                 0.469485                2.857780           7.981138            2       True         33\n",
      "5         WeightedEnsemble_L2_FULL       0.736258        NaN     roc_auc        1.368996            NaN   200.672661                 0.003760                     NaN          10.515897            2       True         54\n",
      "6                   XGBoost_BAG_L2       0.736254   0.739017     roc_auc       10.292415      45.717921  1151.404612                 0.399530                0.719444          12.338193            2       True         28\n",
      "7   NeuralNetTorch_r79_BAG_L2_FULL       0.736252        NaN     roc_auc        4.893687            NaN   368.357817                 0.455573                     NaN          31.820937            2       True         66\n",
      "8                LightGBMXT_BAG_L1       0.736166   0.738810     roc_auc        0.217959       1.255858     4.687878                 0.217959                1.255858           4.687878            1       True          1\n",
      "9                  LightGBM_BAG_L2       0.736163   0.739217     roc_auc       10.005696      45.512875  1142.801090                 0.112811                0.514399           3.734670            2       True         22\n",
      "10            LightGBMLarge_BAG_L2       0.736138   0.739666     roc_auc       10.161107      46.232265  1149.341324                 0.268222                1.233789          10.274905            2       True         30\n",
      "11               LightGBMXT_BAG_L2       0.736111   0.739044     roc_auc       10.041571      45.685925  1143.074916                 0.148686                0.687449           4.008497            2       True         21\n",
      "12       NeuralNetTorch_r79_BAG_L2       0.736087   0.737752     roc_auc       11.254777      46.844222  1184.823919                 1.361892                1.845746          45.757500            2       True         32\n",
      "13        LightGBM_r96_BAG_L1_FULL       0.736085        NaN     roc_auc        0.249393            NaN     9.286471                 0.249393                     NaN           9.286471            1       True         49\n",
      "14              CatBoost_r9_BAG_L1       0.736079   0.739059     roc_auc        0.143166       0.272875    95.346356                 0.143166                0.272875          95.346356            1       True         14\n",
      "15            CatBoost_BAG_L1_FULL       0.736041        NaN     roc_auc        0.023739            NaN    70.062094                 0.023739                     NaN          70.062094            1       True         39\n",
      "16             LightGBM_r96_BAG_L1       0.735991   0.739006     roc_auc        0.987720       5.437096    23.400549                 0.987720                5.437096          23.400549            1       True         15\n",
      "17            LightGBM_BAG_L2_FULL       0.735984        NaN     roc_auc        4.465069            NaN   338.252040                 0.026955                     NaN           1.715160            2       True         56\n",
      "18             WeightedEnsemble_L2       0.735976   0.739641     roc_auc        4.175392      14.628153   792.316357                 0.002018                0.022326          10.515897            2       True         20\n",
      "19          LightGBMXT_BAG_L1_FULL       0.735974        NaN     roc_auc        0.048213            NaN     2.114724                 0.048213                     NaN           2.114724            1       True         35\n",
      "20          LightGBMXT_BAG_L2_FULL       0.735949        NaN     roc_auc        4.470517            NaN   338.408291                 0.032403                     NaN           1.871411            2       True         55\n",
      "21       LightGBM_r131_BAG_L2_FULL       0.735827        NaN     roc_auc        4.518598            NaN   342.728911                 0.080484                     NaN           6.192031            2       True         67\n",
      "22                 CatBoost_BAG_L1       0.735826   0.739241     roc_auc        0.082627       0.148008   437.574515                 0.082627                0.148008         437.574515            1       True          5\n",
      "23                 LightGBM_BAG_L1       0.735751   0.738208     roc_auc        0.177070       0.847530     3.877110                 0.177070                0.847530           3.877110            1       True          2\n",
      "24            LightGBM_r131_BAG_L1       0.735725   0.738165     roc_auc        0.755863       4.305629    12.968623                 0.755863                4.305629          12.968623            1       True         13\n",
      "25       CatBoost_r177_BAG_L2_FULL       0.735685        NaN     roc_auc        4.453693            NaN   347.417491                 0.015579                     NaN          10.880611            2       True         65\n",
      "26       LightGBM_r131_BAG_L1_FULL       0.735596        NaN     roc_auc        0.149709            NaN     8.487986                 0.149709                     NaN           8.487986            1       True         47\n",
      "27            LightGBM_BAG_L1_FULL       0.735533        NaN     roc_auc        0.038236            NaN     1.834598                 0.038236                     NaN           1.834598            1       True         36\n",
      "28           NeuralNetTorch_BAG_L2       0.735450   0.737554     roc_auc       11.105392      46.307799  1217.389504                 1.212508                1.309323          78.323085            2       True         29\n",
      "29            CatBoost_r177_BAG_L1       0.735371   0.738813     roc_auc        0.045641       0.070341    39.025895                 0.045641                0.070341          39.025895            1       True         11\n",
      "30      NeuralNetTorch_BAG_L2_FULL       0.735265        NaN     roc_auc        4.668322            NaN   358.782734                 0.230208                     NaN          22.245854            2       True         63\n",
      "31       CatBoost_r177_BAG_L1_FULL       0.735131        NaN     roc_auc        0.012640            NaN     9.849707                 0.012640                     NaN           9.849707            1       True         45\n",
      "32             XGBoost_BAG_L2_FULL       0.735117        NaN     roc_auc        4.538781            NaN   338.381512                 0.100667                     NaN           1.844632            2       True         62\n",
      "33             XGBoost_BAG_L1_FULL       0.735063        NaN     roc_auc        0.077948            NaN     1.673799                 0.077948                     NaN           1.673799            1       True         42\n",
      "34                  XGBoost_BAG_L1       0.734945   0.737438     roc_auc        0.363671       0.641589    10.132599                 0.363671                0.641589          10.132599            1       True          8\n",
      "35            LightGBMLarge_BAG_L1       0.734745   0.736424     roc_auc        0.348789       1.926099     8.299268                 0.348789                1.926099           8.299268            1       True         10\n",
      "36       LightGBMLarge_BAG_L2_FULL       0.734531        NaN     roc_auc        4.492771            NaN   344.060684                 0.054657                     NaN           7.523804            2       True         64\n",
      "37       LightGBMLarge_BAG_L1_FULL       0.734470        NaN     roc_auc        0.071492            NaN     6.204837                 0.071492                     NaN           6.204837            1       True         44\n",
      "38              XGBoost_r33_BAG_L1       0.734187   0.735346     roc_auc        0.716461       1.902309    29.412666                 0.716461                1.902309          29.412666            1       True         17\n",
      "39        WeightedEnsemble_L3_FULL       0.733798        NaN     roc_auc        7.333140            NaN   441.476015                 0.003270                     NaN          18.031676            3       True         68\n",
      "40         XGBoost_r33_BAG_L1_FULL       0.733791        NaN     roc_auc        0.155629            NaN     3.695074                 0.155629                     NaN           3.695074            1       True         51\n",
      "41       NeuralNetTorch_r79_BAG_L1       0.733690   0.735902     roc_auc        1.101848       1.595173   132.356959                 1.101848                1.595173         132.356959            1       True         12\n",
      "42  NeuralNetTorch_r79_BAG_L1_FULL       0.733376        NaN     roc_auc        0.296087            NaN    49.467575                 0.296087                     NaN          49.467575            1       True         46\n",
      "43           NeuralNetTorch_BAG_L1       0.733056   0.736174     roc_auc        1.200397       1.275845    80.683833                 1.200397                1.275845          80.683833            1       True          9\n",
      "44       NeuralNetTorch_r22_BAG_L1       0.732999   0.731793     roc_auc        1.405108       2.010646   205.488870                 1.405108                2.010646         205.488870            1       True         16\n",
      "45      ExtraTreesEntr_BAG_L2_FULL       0.732869        NaN     roc_auc        4.989886            NaN   345.828781                 0.551772                5.244902           9.291901            2       True         61\n",
      "46      ExtraTreesGini_BAG_L2_FULL       0.732733        NaN     roc_auc        5.176758            NaN   346.058301                 0.738644                6.194719           9.521421            2       True         60\n",
      "47             WeightedEnsemble_L3       0.732733   0.750685     roc_auc       11.752148      69.148461  1244.005554                 0.007334                0.024009          18.031676            3       True         34\n",
      "48           ExtraTreesEntr_BAG_L2       0.732207   0.747571     roc_auc       10.318347      50.243378  1148.358320                 0.425462                5.244902           9.291901            2       True         27\n",
      "49      NeuralNetTorch_BAG_L1_FULL       0.732055        NaN     roc_auc        0.235199            NaN    24.187317                 0.235199                     NaN          24.187317            1       True         43\n",
      "50    RandomForestGini_BAG_L2_FULL       0.731827        NaN     roc_auc        5.356497            NaN   368.734673                 0.918383                6.400845          32.197793            2       True         57\n",
      "51  NeuralNetTorch_r22_BAG_L1_FULL       0.731497        NaN     roc_auc        0.311967            NaN    71.814448                 0.311967                     NaN          71.814448            1       True         50\n",
      "52           ExtraTreesGini_BAG_L2       0.731269   0.748813     roc_auc       10.350351      51.193195  1148.587840                 0.457466                6.194719           9.521421            2       True         26\n",
      "53         RandomForestGini_BAG_L2       0.730990   0.744353     roc_auc       10.409642      51.399321  1171.264212                 0.516757                6.400845          32.197793            2       True         23\n",
      "54    RandomForestEntr_BAG_L2_FULL       0.730531        NaN     roc_auc        5.121071            NaN   372.433224                 0.682957                6.285510          35.896344            2       True         58\n",
      "55         RandomForestEntr_BAG_L2       0.730021   0.743973     roc_auc       10.345129      51.283986  1174.962763                 0.452244                6.285510          35.896344            2       True         24\n",
      "56           ExtraTreesEntr_BAG_L1       0.725901   0.728038     roc_auc        0.480197       4.844959     7.219334                 0.480197                4.844959           7.219334            1       True          7\n",
      "57      ExtraTreesEntr_BAG_L1_FULL       0.725901        NaN     roc_auc        0.498577       4.844959     7.219334                 0.498577                4.844959           7.219334            1       True         41\n",
      "58            CatBoost_r137_BAG_L1       0.724979   0.729077     roc_auc        0.035348       0.047567     7.032893                 0.035348                0.047567           7.032893            1       True         19\n",
      "59       CatBoost_r137_BAG_L1_FULL       0.724815        NaN     roc_auc        0.011062            NaN     1.791631                 0.011062                     NaN           1.791631            1       True         53\n",
      "60           ExtraTreesGini_BAG_L1       0.724623   0.727797     roc_auc        0.481454       5.087286     7.350046                 0.481454                5.087286           7.350046            1       True          6\n",
      "61      ExtraTreesGini_BAG_L1_FULL       0.724623        NaN     roc_auc        0.622316       5.087286     7.350046                 0.622316                5.087286           7.350046            1       True         40\n",
      "62         RandomForestEntr_BAG_L1       0.718962   0.722816     roc_auc        0.439657       4.620971     7.750369                 0.439657                4.620971           7.750369            1       True          4\n",
      "63    RandomForestEntr_BAG_L1_FULL       0.718962        NaN     roc_auc        0.477088       4.620971     7.750369                 0.477088                4.620971           7.750369            1       True         38\n",
      "64         RandomForestGini_BAG_L1       0.718181   0.722186     roc_auc        0.537567       5.391462     8.971400                 0.537567                5.391462           8.971400            1       True          3\n",
      "65    RandomForestGini_BAG_L1_FULL       0.718181        NaN     roc_auc        0.656380       5.391462     8.971400                 0.656380                5.391462           8.971400            1       True         37\n",
      "66           ExtraTrees_r42_BAG_L1       0.706960   0.710348     roc_auc        0.372341       3.317233    17.487256                 0.372341                3.317233          17.487256            1       True         18\n",
      "67      ExtraTrees_r42_BAG_L1_FULL       0.706960        NaN     roc_auc        0.466922       3.317233    17.487256                 0.466922                3.317233          17.487256            1       True         52\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t2266s\t = DyStack   runtime |\t4934s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 4934s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out\"\n",
      "Train Data Rows:    205080\n",
      "Train Data Columns: 63\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5131.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 424.27 MB (8.3% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 8.3% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 38 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])    :  6 | ['배란 자극 여부', '불명확 불임 원인', '나이_순서', '나이_세분화', '여성_결함_점수', ...]\n",
      "\t\t('object', []) : 18 | ['시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', '클리닉 내 총 시술 횟수', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 18 | ['시술 당시 나이', '배란 유도 유형', '배아 생성 주요 이유', '총 시술 횟수', '클리닉 내 총 시술 횟수', ...]\n",
      "\t\t('float', [])     : 34 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       :  4 | ['나이_순서', '나이_세분화', '여성_결함_점수', '남성_결함_점수']\n",
      "\t\t('int', ['bool']) :  6 | ['배란 자극 여부', '착상 전 유전 검사 사용 여부', '불명확 불임 원인', 'PGD 시술 여부', 'PGS 시술 여부', ...]\n",
      "\t1.7s = Fit runtime\n",
      "\t62 features in original data used to generate 62 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 64.16 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.83s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Included models: ['GBM', 'CAT', 'XGB', 'RF', 'XT', 'NN_TORCH'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 85 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4931.75s of the 4931.75s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.26%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t5.8s\t = Training   runtime\n",
      "\t1.55s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4922.89s of the 4922.89s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.03%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t3.97s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 4916.77s of the 4916.77s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.0/4.7 GB\n",
      "\t0.7228\t = Validation score   (roc_auc)\n",
      "\t12.25s\t = Training   runtime\n",
      "\t6.66s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 4897.38s of the 4897.38s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.0/4.0 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 269 due to low memory. Expected memory usage reduced from 16.68% -> 15.0% of available memory...\n",
      "\t0.7237\t = Validation score   (roc_auc)\n",
      "\t9.46s\t = Training   runtime\n",
      "\t5.98s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4881.50s of the 4881.49s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 20.55% memory usage per fold, 41.10%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=20.55%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t528.24s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 4351.32s of the 4351.32s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.0/4.3 GB\n",
      "\t0.7286\t = Validation score   (roc_auc)\n",
      "\t7.96s\t = Training   runtime\n",
      "\t6.34s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4336.57s of the 4336.56s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.0/4.4 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 294 due to low memory. Expected memory usage reduced from 15.3% -> 15.0% of available memory...\n",
      "\t0.729\t = Validation score   (roc_auc)\n",
      "\t8.23s\t = Training   runtime\n",
      "\t6.39s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4321.44s of the 4321.44s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=14.30%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t11.91s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4306.83s of the 4306.83s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.40%)\n",
      "\t0.7361\t = Validation score   (roc_auc)\n",
      "\t98.79s\t = Training   runtime\n",
      "\t1.97s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4205.43s of the 4205.43s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.60%)\n",
      "\t0.7372\t = Validation score   (roc_auc)\n",
      "\t8.85s\t = Training   runtime\n",
      "\t1.98s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 4193.66s of the 4193.65s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.26% memory usage per fold, 73.05%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=18.26%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t63.77s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 4127.86s of the 4127.86s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.76%)\n",
      "\t0.7364\t = Validation score   (roc_auc)\n",
      "\t155.82s\t = Training   runtime\n",
      "\t2.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 3969.27s of the 3969.26s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.01%)\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t14.67s\t = Training   runtime\n",
      "\t4.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 3951.26s of the 3951.25s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 20.16% memory usage per fold, 40.32%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=20.16%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t127.19s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 3822.06s of the 3822.06s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.95%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t24.82s\t = Training   runtime\n",
      "\t6.65s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 3794.04s of the 3794.04s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.05%)\n",
      "\t0.7347\t = Validation score   (roc_auc)\n",
      "\t258.57s\t = Training   runtime\n",
      "\t2.85s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 3533.22s of the 3533.21s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.09% memory usage per fold, 76.34%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=19.09%)\n",
      "\t0.7358\t = Validation score   (roc_auc)\n",
      "\t36.41s\t = Training   runtime\n",
      "\t2.71s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 3494.01s of the 3494.01s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.0/4.0 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 242 due to low memory. Expected memory usage reduced from 18.59% -> 15.0% of available memory...\n",
      "\t0.7128\t = Validation score   (roc_auc)\n",
      "\t29.43s\t = Training   runtime\n",
      "\t5.6s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 3458.51s of the 3458.50s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.33% memory usage per fold, 46.67%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=23.33%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t514.71s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 2941.64s of the 2941.64s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.92% memory usage per fold, 47.85%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=23.92%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t191.42s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 2747.92s of the 2747.91s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.0/3.4 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 104 due to low memory. Expected memory usage reduced from 43.19% -> 15.0% of available memory...\n",
      "\t0.6835\t = Validation score   (roc_auc)\n",
      "\t19.9s\t = Training   runtime\n",
      "\t3.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 2724.29s of the 2724.29s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.40% memory usage per fold, 65.61%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=16.40%)\n",
      "\t0.738\t = Validation score   (roc_auc)\n",
      "\t9.31s\t = Training   runtime\n",
      "\t2.27s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 2712.01s of the 2712.01s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=15.39%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t16.6s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 2693.15s of the 2693.15s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.64%)\n",
      "\t0.7356\t = Validation score   (roc_auc)\n",
      "\t1294.17s\t = Training   runtime\n",
      "\t2.8s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 1396.44s of the 1396.43s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.74%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t6.23s\t = Training   runtime\n",
      "\t1.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1387.45s of the 1387.44s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.26%)\n",
      "\t0.7353\t = Validation score   (roc_auc)\n",
      "\t313.06s\t = Training   runtime\n",
      "\t2.42s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 1072.19s of the 1072.18s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.47% memory usage per fold, 77.87%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=19.47%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t95.59s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 974.20s of the 974.20s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=13.44%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t5.67s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 966.17s of the 966.16s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.0/4.7 GB\n",
      "\t0.7162\t = Validation score   (roc_auc)\n",
      "\t35.46s\t = Training   runtime\n",
      "\t6.21s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 924.11s of the 924.11s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.84% memory usage per fold, 75.36%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=18.84%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t544.14s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 377.87s of the 377.86s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.89%)\n",
      "\t0.736\t = Validation score   (roc_auc)\n",
      "\t55.86s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 319.42s of the 319.42s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=14.20%)\n",
      "\t0.7364\t = Validation score   (roc_auc)\n",
      "\t36.39s\t = Training   runtime\n",
      "\t7.94s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 279.16s of the 279.16s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 20.49% memory usage per fold, 40.99%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=20.49%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t101.71s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 175.41s of the 175.40s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.82%)\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t71.92s\t = Training   runtime\n",
      "\t31.6s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 96.04s of the 96.04s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.0/4.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 174 due to low memory. Expected memory usage reduced from 25.81% -> 15.0% of available memory...\n",
      "\t0.695\t = Validation score   (roc_auc)\n",
      "\t27.51s\t = Training   runtime\n",
      "\t4.65s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 63.27s of the 63.27s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.61% memory usage per fold, 43.23%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=21.61%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t53.33s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 493.17s of the 7.66s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/4.1 GB\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.182, 'CatBoost_r137_BAG_L1': 0.136, 'CatBoost_r70_BAG_L1': 0.136, 'XGBoost_r89_BAG_L1': 0.091, 'LightGBM_r130_BAG_L1': 0.091, 'NeuralNetTorch_r14_BAG_L1': 0.091, 'CatBoost_r177_BAG_L1': 0.045, 'NeuralNetTorch_r79_BAG_L1': 0.045, 'CatBoost_r9_BAG_L1': 0.045, 'LightGBM_r96_BAG_L1': 0.045, 'NeuralNetTorch_r22_BAG_L1': 0.045, 'NeuralNetTorch_r30_BAG_L1': 0.045}\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t22.63s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4948.64s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2024.9 rows/s (41016 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.4 GB\n",
      "\t2.28s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.2 GB\n",
      "\t1.84s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t12.25s\t = Training   runtime\n",
      "\t6.66s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t9.46s\t = Training   runtime\n",
      "\t5.98s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t79.05s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t7.96s\t = Training   runtime\n",
      "\t6.34s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t8.23s\t = Training   runtime\n",
      "\t6.39s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.78s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/3.9 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t30.27s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/3.9 GB\n",
      "\t5.56s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t13.3s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/3.9 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t54.88s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.0 GB\n",
      "\t9.82s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t28.86s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.1 GB\n",
      "\t10.83s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t85.33s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t4.13s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t29.43s\t = Training   runtime\n",
      "\t5.6s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t89.15s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t37.68s\t = Training   runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t19.9s\t = Training   runtime\n",
      "\t3.25s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.1 GB\n",
      "\t5.66s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.83s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t733.63s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.5 GB\n",
      "\t3.22s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.4 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t118.57s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t19.0s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.11s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t35.46s\t = Training   runtime\n",
      "\t6.21s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t88.51s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/4.3 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t13.48s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r161_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.5/4.4 GB\n",
      "\t27.4s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r70_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t20.22s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r196_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/4.4 GB\n",
      "\t43.75s\t = Training   runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t27.51s\t = Training   runtime\n",
      "\t4.65s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r167_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t10.41s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.182, 'CatBoost_r137_BAG_L1': 0.136, 'CatBoost_r70_BAG_L1': 0.136, 'XGBoost_r89_BAG_L1': 0.091, 'LightGBM_r130_BAG_L1': 0.091, 'NeuralNetTorch_r14_BAG_L1': 0.091, 'CatBoost_r177_BAG_L1': 0.045, 'NeuralNetTorch_r79_BAG_L1': 0.045, 'CatBoost_r9_BAG_L1': 0.045, 'LightGBM_r96_BAG_L1': 0.045, 'NeuralNetTorch_r22_BAG_L1': 0.045, 'NeuralNetTorch_r30_BAG_L1': 0.045}\n",
      "\t22.63s\t = Training   runtime\n",
      "Refit complete, total runtime = 1550.15s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>0.738729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2.705830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1156.430262</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.631629</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_r70_BAG_L1</td>\n",
       "      <td>0.738726</td>\n",
       "      <td>0.739352</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.228771</td>\n",
       "      <td>0.213204</td>\n",
       "      <td>101.705258</td>\n",
       "      <td>0.228771</td>\n",
       "      <td>0.213204</td>\n",
       "      <td>101.705258</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_r9_BAG_L1</td>\n",
       "      <td>0.738664</td>\n",
       "      <td>0.739256</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.260637</td>\n",
       "      <td>0.249517</td>\n",
       "      <td>127.191046</td>\n",
       "      <td>0.260637</td>\n",
       "      <td>0.249517</td>\n",
       "      <td>127.191046</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.738656</td>\n",
       "      <td>0.739939</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>12.850500</td>\n",
       "      <td>20.276842</td>\n",
       "      <td>3170.323006</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.026124</td>\n",
       "      <td>22.631629</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_r69_BAG_L1</td>\n",
       "      <td>0.738631</td>\n",
       "      <td>0.739276</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.154437</td>\n",
       "      <td>0.208363</td>\n",
       "      <td>544.139547</td>\n",
       "      <td>0.154437</td>\n",
       "      <td>0.208363</td>\n",
       "      <td>544.139547</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_test  score_val eval_metric  \\\n",
       "0  WeightedEnsemble_L2_FULL    0.738729        NaN     roc_auc   \n",
       "1       CatBoost_r70_BAG_L1    0.738726   0.739352     roc_auc   \n",
       "2        CatBoost_r9_BAG_L1    0.738664   0.739256     roc_auc   \n",
       "3       WeightedEnsemble_L2    0.738656   0.739939     roc_auc   \n",
       "4       CatBoost_r69_BAG_L1    0.738631   0.739276     roc_auc   \n",
       "\n",
       "   pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0        2.705830            NaN  1156.430262                 0.005955   \n",
       "1        0.228771       0.213204   101.705258                 0.228771   \n",
       "2        0.260637       0.249517   127.191046                 0.260637   \n",
       "3       12.850500      20.276842  3170.323006                 0.004451   \n",
       "4        0.154437       0.208363   544.139547                 0.154437   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                     NaN          22.631629            2       True   \n",
       "1                0.213204         101.705258            1       True   \n",
       "2                0.249517         127.191046            1       True   \n",
       "3                0.026124          22.631629            2       True   \n",
       "4                0.208363         544.139547            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0         74  \n",
       "1         33  \n",
       "2         14  \n",
       "3         37  \n",
       "4         30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. 파생변수 생성\n",
    "# ==========================================\n",
    "\n",
    "def derive_features(df):\n",
    "\n",
    "    age_order = {'만18-34세': 1, '만35-37세': 2, '만38-39세': 3, '만40-42세': 4, '만43-44세': 5, '만45-50세': 6, '알 수 없음': 0}\n",
    "    df['나이_순서'] = df['시술 당시 나이'].map(age_order)\n",
    "    df['나이x배아'] = df['나이_순서'] * df['이식된 배아 수']\n",
    "    df['연령별 배아 효율'] = df['이식된 배아 수'] / (df['나이_순서'] + 1e-5) # '나이가 적으면서 배아가 많은 그룹' vs '나이가 많으면서 배아가 적은 그룹' 강조\n",
    "\n",
    "    df['배아 발달 기간'] = df['배아 이식 경과일'] - df['난자 혼합 경과일']\n",
    "    df['이식 비중'] = df['이식된 배아 수'] / (df['이식된 배아 수'] + df['저장된 배아 수'] + 1e-5)\n",
    "\n",
    "    oocyte_cols = ['수집된 신선 난자 수', '혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '해동 난자 수']\n",
    "    df['총 난자 수'] = df[oocyte_cols].fillna(0).sum(axis=1)\n",
    "    df['배아 손실률'] = (df['총 난자 수'] - df['총 생성 배아 수']) / df['총 난자 수']\n",
    "    \n",
    "    df['배아 생성 효율'] = df['저장된 배아 수'] / (df['저장된 신선 난자 수'] + 1e-6)\n",
    "    df['수정 효율'] = df['총 생성 배아 수'] / (df['혼합된 난자 수'] + 1e-6)\n",
    "    df['선별 효율'] = df['저장된 배아 수'] / (df['총 생성 배아 수'] + 1e-6)\n",
    "    \n",
    "    def categorize_age_optimized(age_label):\n",
    "        if age_label in ['만35-37세', '만38-39세']:\n",
    "            return 1  # Middle\n",
    "        elif age_label in ['만40-42세', '만43-44세', '만45-50세']:\n",
    "            return 2  # Senior\n",
    "        else:\n",
    "            return 0  # '만18-34세'와 '알 수 없음'을 모두 0으로 처리\n",
    "        \n",
    "    df['나이_세분화'] = df['시술 당시 나이'].apply(categorize_age_optimized)\n",
    "\n",
    "    def clean_treatment(text): \n",
    "        text = str(text).upper()\n",
    "        if 'ICSI' in text:\n",
    "            return 'ICSI'\n",
    "        if 'IVF' in text:\n",
    "            return 'IVF'\n",
    "        if 'IUI' in text:\n",
    "            return 'IUI'\n",
    "        return 'Other'\n",
    "\n",
    "    df['시술유형_정제'] = df['특정 시술 유형'].apply(clean_treatment)\n",
    "\n",
    "    female_cols = ['불임 원인 - 여성 요인', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', '불임 원인 - 자궁경부 문제', \n",
    "                   '불임 원인 - 자궁내막증', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인']\n",
    "    \n",
    "    male_cols = ['불임 원인 - 남성 요인', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', \n",
    "                 '불임 원인 - 정자 면역학적 요인', '남성 주 불임 원인', '남성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인']\n",
    "    \n",
    "    df['여성_결함_점수'] = df[female_cols].sum(axis=1)\n",
    "    df['남성_결함_점수'] = df[male_cols].sum(axis=1)\n",
    "    \n",
    "    drop_cols = ['시술 시기 코드', '특정 시술 유형', '시술 유형']\n",
    "    df.drop(drop_cols + female_cols + male_cols, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = derive_features(train_df)\n",
    "test_df = derive_features(test_df)\n",
    "\n",
    "# 학습용 데이터 내에서 정답이 있는 '자체 테스트셋' 분리\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 모델 학습 설정\n",
    "# ==========================================\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target, \n",
    "    eval_metric='roc_auc',\n",
    "    path='ag_models_out',\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=7200,\n",
    "    presets='best_quality',\n",
    "    included_model_types=['GBM', 'CAT', 'XGB', 'RF', 'XT', 'NN_TORCH'],\n",
    "    num_stack_levels=1,\n",
    "    num_bag_folds=5,\n",
    "    refit_full=True\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\n",
    "# ==========================================\n",
    "\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "final_probs = pred_probs.iloc[:, 1]\n",
    "\n",
    "# ==========================================\n",
    "# 5. 리더보드 출력\n",
    "# ==========================================\n",
    "\n",
    "lb = predictor.leaderboard(val_data, silent=True)\n",
    "display(lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ID']\n",
      "Computing feature importance via permutation shuffling for 62 features using 5000 rows with 5 shuffle sets...\n",
      "\t579.19s\t= Expected runtime (115.84s per shuffle set)\n",
      "\t373.51s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 피처 중요도 ---\n",
    "fi = predictor.feature_importance(data=train_data.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "fi.to_excel('fi10.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 제출 파일 생성 ---\n",
    "# submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "# submission['probability'] = final_probs.values\n",
    "\n",
    "# # 현재 시간 가져오기 (예: 0206_1031)\n",
    "# now = datetime.now().strftime('%m%d_%H%M')\n",
    "# file_name = f\"{now}_submission.csv\"\n",
    "# submission.to_csv(file_name, index=False)\n",
    "\n",
    "# print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
