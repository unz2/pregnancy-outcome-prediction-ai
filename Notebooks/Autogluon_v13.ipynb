{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_models_out_v13\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       7.85 GB / 16.00 GB (49.1%)\n",
      "Disk Space Avail:   165.15 GB / 460.43 GB (35.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=2\n",
      "Beginning AutoGluon training ... Time limit = 10800s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v13\"\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 55\n",
      "Label Column:       임신 성공 여부\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8091.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 240.76 MB (3.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 34 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])    : 14 | ['시술 당시 나이', '배란 자극 여부', '불명확 불임 원인', '총 시술 횟수', '클리닉 내 총 시술 횟수', ...]\n",
      "\t\t('object', []) :  7 | ['특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', '난자 출처', '정자 출처', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  7 | ['특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', '난자 출처', '정자 출처', ...]\n",
      "\t\t('float', [])     : 32 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', '미세주입된 난자 수', ...]\n",
      "\t\t('int', [])       : 12 | ['시술 당시 나이', '총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', ...]\n",
      "\t\t('int', ['bool']) :  4 | ['배란 자극 여부', '불명확 불임 원인', 'PGD 시술 여부', '난자 채취 경과일']\n",
      "\t0.9s = Fit runtime\n",
      "\t55 features in original data used to generate 55 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 88.75 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Included models: ['GBM', 'CAT', 'XGB'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 46 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 7197.55s of the 10799.02s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.82%)\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t9.95s\t = Training   runtime\n",
      "\t6.66s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 7182.39s of the 10783.86s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.16%)\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t6.69s\t = Training   runtime\n",
      "\t4.84s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 7173.23s of the 10774.70s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.75% memory usage per fold, 50.98%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.75%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t5839.89s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1331.57s of the 4933.04s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.81% memory usage per fold, 78.45%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.81%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t1354.52s\t = Training   runtime\n",
      "\t2.82s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 719.75s of the 3575.97s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/9.5 GB\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.556, 'LightGBMXT_BAG_L1': 0.333, 'XGBoost_BAG_L1': 0.111}\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t2.85s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Included models: ['GBM', 'CAT', 'XGB'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 46 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3573.07s of the 3573.05s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.29%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t5.82s\t = Training   runtime\n",
      "\t3.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3563.56s of the 3563.54s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.06%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t1072.44s\t = Training   runtime\n",
      "\t2.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1454.78s of the 1454.76s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.99% memory usage per fold, 47.96%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.99%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t2412.04s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -958.98s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/6.8 GB\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.556, 'LightGBMXT_BAG_L1': 0.333, 'XGBoost_BAG_L1': 0.111}\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t6.57s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11765.63s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5250.2 rows/s (51271 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.5/8.4 GB\n",
      "\t2.69s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.5/8.2 GB\n",
      "\t2.06s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t5165.76s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1002.69s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.556, 'LightGBMXT_BAG_L1': 0.333, 'XGBoost_BAG_L1': 0.111}\n",
      "\t2.85s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.5/7.3 GB\n",
      "\t1.8s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.5/7.3 GB\n",
      "\t1.65s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t985.8s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.556, 'LightGBMXT_BAG_L1': 0.333, 'XGBoost_BAG_L1': 0.111}\n",
      "\t6.57s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 7163.42s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v13\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. 파생변수 생성\n",
    "# ==========================================\n",
    "\n",
    "def derive_features(df):\n",
    "\n",
    "    # 1. 수치형 변환 및 클리닝 (정규표현식 활용)\n",
    "    count_cols = [\n",
    "        '총 시술 횟수', '클리닉 내 총 시술 횟수', '총 임신 횟수', '총 출산 횟수',\n",
    "        'IVF 시술 횟수', 'DI 시술 횟수', 'IVF 임신 횟수', 'DI 임신 횟수',\n",
    "        'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '이식된 배아 수', \n",
    "        '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '저장된 배아 수'\n",
    "    ]\n",
    "    \n",
    "    for col in count_cols:\n",
    "        if df[col].dtype == 'object':\n",
    "            # '회', ' 이상' 등을 제거하고 공백 정리 후 숫자형으로 변환\n",
    "            df[col] = df[col].astype(str).str.replace(r'회| 이상', '', regex=True).str.strip()\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    target_cols = [\n",
    "            '총 생성 배아 수', '기증자 정자와 혼합된 난자 수', '파트너 정자와 혼합된 난자 수',\n",
    "            '미세주입된 난자 수', '혼합된 난자 수', '저장된 신선 난자 수', '해동 난자 수',\n",
    "            '해동된 배아 수', '미세주입 후 저장된 배아 수', '저장된 배아 수',\n",
    "            '미세주입 배아 이식 수', '이식된 배아 수', '미세주입에서 생성된 배아 수',\n",
    "            '수집된 신선 난자 수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '대리모 여부',\n",
    "            '기증 배아 사용 여부', '신선 배아 사용 여부', '동결 배아 사용 여부'\n",
    "        ]\n",
    "\n",
    "    # 시술 유형이 DI인 행에 대해서만 지정된 컬럼들의 NaN을 0으로 채움\n",
    "    df.loc[df['특정 시술 유형'] == 'DI', target_cols] = df.loc[df['특정 시술 유형'] == 'DI', target_cols].fillna(0)\n",
    "\n",
    "\n",
    "    # 2. 연령 관련 변수 생성\n",
    "    age_order = {\n",
    "        '만18-34세': 1, '만35-37세': 2, '만38-39세': 3, \n",
    "        '만40-42세': 4, '만43-44세': 5, '만45-50세': 6, '알 수 없음': 7\n",
    "    }\n",
    "    df['시술 당시 나이'] = df['시술 당시 나이'].map(age_order).fillna(7)\n",
    "    \n",
    "    # 파생 변수 계산 (Zero Division 방지를 위해 1e-6 활용)\n",
    "    epsilon = 1e-6\n",
    "    df['나이 이식배아 비율'] = df['시술 당시 나이'] * df['이식된 배아 수']\n",
    "    df['연령별 배아 효율'] = df['이식된 배아 수'] / (df['시술 당시 나이'] + epsilon)\n",
    "    df['이식 배아 효율'] = df['이식된 배아 수'] * df['연령별 배아 효율']\n",
    "    df['배아 발달 기간'] = df['배아 이식 경과일'] - df['난자 혼합 경과일']\n",
    "    df['이식 비중'] = df['이식된 배아 수'] / (df['이식된 배아 수'] + df['저장된 배아 수'] + epsilon)\n",
    "\n",
    "    # 3. 난자 및 배아 효율성 변수\n",
    "    oocyte_cols = ['수집된 신선 난자 수', '혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '해동 난자 수']\n",
    "    df['총 난자 수'] = df[oocyte_cols].fillna(0).sum(axis=1)\n",
    "    \n",
    "    # 0으로 나누기 방지를 위해 총 난자 수가 0인 경우 0으로 처리하거나 epsilon 추가\n",
    "    df['배아 손실률'] = (df['총 난자 수'] - df['총 생성 배아 수']) / (df['총 난자 수'] + epsilon)\n",
    "    df['배아 생성 효율'] = df['저장된 배아 수'] / (df['저장된 신선 난자 수'] + epsilon)\n",
    "    df['수정 효율'] = df['총 생성 배아 수'] / (df['혼합된 난자 수'] + epsilon)\n",
    "    df['선별 효율'] = df['저장된 배아 수'] / (df['총 생성 배아 수'] + epsilon)\n",
    "\n",
    "    # 4. 시술 유형 분류 (Vectorized 방식 권장)\n",
    "    def clean_treatment(val):\n",
    "        val = str(val).upper()\n",
    "        if 'ICSI' in val: return 'ICSI'\n",
    "        if 'IVF' in val: return 'IVF'\n",
    "        if 'IUI' in val: return 'IUI'\n",
    "        return 'Other'\n",
    "\n",
    "    df['특정 시술 유형'] = df['특정 시술 유형'].apply(clean_treatment)\n",
    "\n",
    "    # 5. 불임 원인 점수 계산\n",
    "    female_cols = [\n",
    "        '불임 원인 - 여성 요인', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', \n",
    "        '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '여성 주 불임 원인', \n",
    "        '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인'\n",
    "    ]\n",
    "    male_cols = [\n",
    "        '불임 원인 - 남성 요인', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', \n",
    "        '불임 원인 - 정자 형태', '불임 원인 - 정자 면역학적 요인', '남성 주 불임 원인', \n",
    "        '남성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인'\n",
    "    ]\n",
    "    \n",
    "    df['여성_결함_점수'] = df[female_cols].sum(axis=1)\n",
    "    df['남성_결함_점수'] = df[male_cols].sum(axis=1)\n",
    "\n",
    "    # 6. 배아 생성 주요 이유 단순화\n",
    "    def clean_reason(x):\n",
    "        if pd.isna(x): return 'Unknown'\n",
    "        x = str(x)\n",
    "        if '시술용' in x: return 'Treatment'\n",
    "        if '기증' in x: return 'Donation'\n",
    "        if '저장' in x: return 'Storage'\n",
    "        return 'Other'\n",
    "    \n",
    "    df['배아 생성 주요 이유'] = df['배아 생성 주요 이유'].apply(clean_reason)\n",
    "    \n",
    "    # 7. 불필요한 컬럼 삭제\n",
    "    drop_cols = [\n",
    "    'ID', \n",
    "    '시술 시기 코드',\n",
    "    '저장된 배아 수', \n",
    "    '착상 전 유전 검사 사용 여부', \n",
    "    'PGS 시술 여부', \n",
    "    'DI 출산 횟수', \n",
    "    '대리모 여부', \n",
    "    '시술 유형',\n",
    "    '저장된 신선 난자 수'\n",
    "    ]\n",
    "    df.drop(columns=drop_cols + female_cols + male_cols, errors='ignore', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = derive_features(train_df)\n",
    "test_df = derive_features(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 모델 학습 설정\n",
    "# ==========================================\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target, \n",
    "    eval_metric='roc_auc',\n",
    "    path='ag_models_out_v13',\n",
    ").fit(\n",
    "    train_data=train_df,\n",
    "    time_limit=10800,\n",
    "    presets='best_quality',\n",
    "    num_stack_levels=1,\n",
    "    num_bag_folds=5,\n",
    "    num_bag_sets=2,\n",
    "    refit_full=True,\n",
    "    dynamic_stacking=False,\n",
    "    included_model_types=['GBM', 'CAT', 'XGB'],\n",
    "    save_space=True,\n",
    "    set_best_to_refit_full=True\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\n",
    "# ==========================================\n",
    "\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "final_probs = pred_probs.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca412e5d-8496-45dd-9636-a0159ca867ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.750913</td>\n",
       "      <td>0.738708</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2601.421287</td>\n",
       "      <td>16.753472</td>\n",
       "      <td>8283.483121</td>\n",
       "      <td>935.752620</td>\n",
       "      <td>2.155791</td>\n",
       "      <td>1072.441664</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.749942</td>\n",
       "      <td>0.738709</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1667.925298</td>\n",
       "      <td>17.711616</td>\n",
       "      <td>7216.860340</td>\n",
       "      <td>2.256631</td>\n",
       "      <td>3.113935</td>\n",
       "      <td>5.818883</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.749704</td>\n",
       "      <td>0.738410</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.963178</td>\n",
       "      <td>2.817726</td>\n",
       "      <td>1354.521579</td>\n",
       "      <td>5.963178</td>\n",
       "      <td>2.817726</td>\n",
       "      <td>1354.521579</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L2_FULL</td>\n",
       "      <td>0.749674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.609164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6174.843809</td>\n",
       "      <td>0.168152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.648463</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT_BAG_L2_FULL</td>\n",
       "      <td>0.749657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.688752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6174.998364</td>\n",
       "      <td>0.247740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.803018</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0         LightGBM_BAG_L2    0.750913   0.738708     roc_auc     2601.421287   \n",
       "1       LightGBMXT_BAG_L2    0.749942   0.738709     roc_auc     1667.925298   \n",
       "2          XGBoost_BAG_L1    0.749704   0.738410     roc_auc        5.963178   \n",
       "3    LightGBM_BAG_L2_FULL    0.749674        NaN     roc_auc        1.609164   \n",
       "4  LightGBMXT_BAG_L2_FULL    0.749657        NaN     roc_auc        1.688752   \n",
       "\n",
       "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0      16.753472  8283.483121               935.752620   \n",
       "1      17.711616  7216.860340                 2.256631   \n",
       "2       2.817726  1354.521579                 5.963178   \n",
       "3            NaN  6174.843809                 0.168152   \n",
       "4            NaN  6174.998364                 0.247740   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                2.155791        1072.441664            2       True   \n",
       "1                3.113935           5.818883            2       True   \n",
       "2                2.817726        1354.521579            1       True   \n",
       "3                     NaN           1.648463            2       True   \n",
       "4                     NaN           1.803018            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0          7  \n",
       "1          6  \n",
       "2          4  \n",
       "3         16  \n",
       "4         15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 리더보드 출력 ---\n",
    "lb = predictor.leaderboard(train_df, silent=True)\n",
    "display(lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 및 예측이 완료되었습니다. 결과가 0210_1010_submission.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# --- 제출 파일 생성 ---\n",
    "submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "submission['probability'] = final_probs.values\n",
    "\n",
    "# 현재 시간 가져오기 (예: 0206_1031)\n",
    "now = datetime.now().strftime('%m%d_%H%M')\n",
    "file_name = f\"{now}_submission.csv\"\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 55 features using 5000 rows with 5 shuffle sets...\n",
      "\t18.85s\t= Expected runtime (3.77s per shuffle set)\n",
      "\t7.86s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "# --- 피처 중요도 ---\n",
    "fi = predictor.feature_importance(data=train_df.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "fi.to_excel('fi13.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22277552-52e4-4bf9-8fcf-f5dac0d3325c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
