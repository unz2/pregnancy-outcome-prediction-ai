{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08205e02-c19c-4747-90b8-b1a82b1c4fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_models_out_v17\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:09:40 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       7.25 GB / 16.00 GB (45.3%)\n",
      "Disk Space Avail:   136.02 GB / 460.43 GB (29.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=10, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 10800s\n",
      "AutoGluon will save models to \"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v17\"\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 90\n",
      "Label Column:       임신 성공 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7495.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 70.42 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 31 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['불임 원인 - 여성 요인']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['ID', '불임 원인 - 정자 면역학적 요인']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('category', []) : 1 | ['ID']\n",
      "\t\t('int', [])      : 1 | ['불임 원인 - 정자 면역학적 요인']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 14 | ['시술 시기 코드', '시술 당시 나이', '시술 유형', '특정 시술 유형', '배란 유도 유형', ...]\n",
      "\t\t('float', [])    : 42 | ['임신 시도 또는 마지막 임신 경과 연수', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '총 생성 배아 수', ...]\n",
      "\t\t('int', [])      : 31 | ['배란 자극 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 13 | ['시술 시기 코드', '시술 당시 나이', '특정 시술 유형', '배란 유도 유형', '배아 생성 주요 이유', ...]\n",
      "\t\t('float', [])     : 32 | ['임신 시도 또는 마지막 임신 경과 연수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', ...]\n",
      "\t\t('int', [])       : 12 | ['총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', ...]\n",
      "\t\t('int', ['bool']) : 30 | ['시술 유형', '배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t87 features in original data used to generate 87 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 44.74 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.56s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4798.55s of the 10799.43s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.41%)\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t11.74s\t = Training   runtime\n",
      "\t3.46s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4781.61s of the 10782.49s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.24%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t9.1s\t = Training   runtime\n",
      "\t2.89s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 4770.07s of the 10770.95s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/8.4 GB\n",
      "\t0.7297\t = Validation score   (roc_auc)\n",
      "\t12.46s\t = Training   runtime\n",
      "\t7.89s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 4749.30s of the 10750.18s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.7 GB\n",
      "\t0.7303\t = Validation score   (roc_auc)\n",
      "\t13.13s\t = Training   runtime\n",
      "\t7.81s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4727.93s of the 10728.81s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.81% memory usage per fold, 78.45%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.81%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t1100.47s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3625.46s of the 9626.34s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/9.4 GB\n",
      "\t0.732\t = Validation score   (roc_auc)\n",
      "\t10.3s\t = Training   runtime\n",
      "\t7.6s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3607.08s of the 9607.96s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/8.5 GB\n",
      "\t0.7324\t = Validation score   (roc_auc)\n",
      "\t10.73s\t = Training   runtime\n",
      "\t7.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3588.13s of the 9589.01s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.77%)\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t119.8s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3465.52s of the 9466.40s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.12%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t20.02s\t = Training   runtime\n",
      "\t1.44s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3442.62s of the 9443.50s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.80%)\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t147.25s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3293.19s of the 9294.07s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.30%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t12.02s\t = Training   runtime\n",
      "\t4.77s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 3278.39s of the 9279.28s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.66%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t85.46s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 3190.96s of the 9191.84s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.72%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t177.42s\t = Training   runtime\n",
      "\t3.0s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 3011.35s of the 9012.23s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.57%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t27.64s\t = Training   runtime\n",
      "\t14.64s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2979.56s of the 8980.45s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.95%)\n",
      "\t0.7352\t = Validation score   (roc_auc)\n",
      "\t1201.37s\t = Training   runtime\n",
      "\t3.0s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1775.92s of the 7776.80s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.86% memory usage per fold, 78.88%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.86%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t248.31s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1524.89s of the 7525.77s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.33%)\n",
      "\t0.7403\t = Validation score   (roc_auc)\n",
      "\t106.85s\t = Training   runtime\n",
      "\t23.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1412.48s of the 7413.36s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.88%)\n",
      "\t0.7374\t = Validation score   (roc_auc)\n",
      "\t314.06s\t = Training   runtime\n",
      "\t2.65s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1096.14s of the 7097.02s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.57%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t54.0s\t = Training   runtime\n",
      "\t5.65s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1039.50s of the 7040.38s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/9.6 GB\n",
      "\t0.7229\t = Validation score   (roc_auc)\n",
      "\t82.72s\t = Training   runtime\n",
      "\t8.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 948.14s of the 6949.02s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.40% memory usage per fold, 75.19%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.40%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t1602.25s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 479.85s of the 5344.00s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/6.6 GB\n",
      "\tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.167, 'CatBoost_BAG_L1': 0.111, 'NeuralNetFastAI_BAG_L1': 0.111, 'CatBoost_r177_BAG_L1': 0.111, 'NeuralNetTorch_r79_BAG_L1': 0.111, 'NeuralNetTorch_r22_BAG_L1': 0.111, 'XGBoost_r33_BAG_L1': 0.111, 'LightGBMXT_BAG_L1': 0.056, 'LightGBM_BAG_L1': 0.056, 'NeuralNetTorch_BAG_L1': 0.056}\n",
      "\t0.741\t = Validation score   (roc_auc)\n",
      "\t16.09s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3551.02s of the 5327.79s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.93%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t11.98s\t = Training   runtime\n",
      "\t1.66s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3536.25s of the 5313.02s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.24%)\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t8.51s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 3525.62s of the 5302.39s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/9.7 GB\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t653.6s\t = Training   runtime\n",
      "\t8.82s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 2862.69s of the 4639.46s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.4 GB\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t49.48s\t = Training   runtime\n",
      "\t9.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 2803.40s of the 4580.17s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.87% memory usage per fold, 47.47%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.87%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t339.55s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 2461.89s of the 4238.66s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.9 GB\n",
      "\t0.7428\t = Validation score   (roc_auc)\n",
      "\t12.03s\t = Training   runtime\n",
      "\t8.39s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 2440.92s of the 4217.70s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.7 GB\n",
      "\t0.7427\t = Validation score   (roc_auc)\n",
      "\t12.72s\t = Training   runtime\n",
      "\t8.66s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 2419.01s of the 4195.78s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.16% memory usage per fold, 73.27%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.16%)\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t121.81s\t = Training   runtime\n",
      "\t1.37s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 2294.19s of the 4070.96s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.11%)\n",
      "\t0.7404\t = Validation score   (roc_auc)\n",
      "\t14.15s\t = Training   runtime\n",
      "\t1.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 2277.04s of the 4053.81s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.05%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t108.07s\t = Training   runtime\n",
      "\t1.67s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 2166.61s of the 3943.38s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.34%)\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t14.69s\t = Training   runtime\n",
      "\t3.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 2149.10s of the 3925.87s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.97% memory usage per fold, 71.79%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.97%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t56.98s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 2089.96s of the 3866.73s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.93%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t158.73s\t = Training   runtime\n",
      "\t3.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 1928.77s of the 3705.54s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.00%)\n",
      "\t0.7408\t = Validation score   (roc_auc)\n",
      "\t37.78s\t = Training   runtime\n",
      "\t9.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 1886.47s of the 3663.24s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.16%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t1145.12s\t = Training   runtime\n",
      "\t3.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 738.88s of the 2515.65s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.60% memory usage per fold, 42.41%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.60%)\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t153.5s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 582.75s of the 2359.52s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.86%)\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t36.99s\t = Training   runtime\n",
      "\t4.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 542.90s of the 2319.67s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.79%)\n",
      "\t0.7366\t = Validation score   (roc_auc)\n",
      "\t215.01s\t = Training   runtime\n",
      "\t2.76s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 325.46s of the 2102.23s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.67% memory usage per fold, 69.37%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.67%)\n",
      "\t0.7403\t = Validation score   (roc_auc)\n",
      "\t61.23s\t = Training   runtime\n",
      "\t3.93s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 261.46s of the 2038.23s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/10.4 GB\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t88.24s\t = Training   runtime\n",
      "\t10.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 162.57s of the 1939.34s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.64% memory usage per fold, 42.55%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.64%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t130.73s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 29.12s of the 1805.90s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.92% memory usage per fold, 71.36%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.92%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t25.47s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 1.22s of the 1777.99s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.37% memory usage per fold, 41.48%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.37%)\n",
      "\tTime limit exceeded... Skipping CatBoost_r13_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 1774.73s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/7.8 GB\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.375, 'ExtraTreesEntr_BAG_L2': 0.333, 'RandomForestEntr_BAG_L2': 0.125, 'ExtraTrees_r42_BAG_L2': 0.125, 'RandomForestGini_BAG_L2': 0.042}\n",
      "\t0.7442\t = Validation score   (roc_auc)\n",
      "\t16.85s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 1757.83s of the 1757.75s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=4.84%)\n",
      "\t0.7435\t = Validation score   (roc_auc)\n",
      "\t9.76s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 1746.14s of the 1746.06s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.00%)\n",
      "\t0.7436\t = Validation score   (roc_auc)\n",
      "\t8.12s\t = Training   runtime\n",
      "\t1.58s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 1735.54s of the 1735.46s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/8.7 GB\n",
      "\t0.7375\t = Validation score   (roc_auc)\n",
      "\t930.91s\t = Training   runtime\n",
      "\t8.47s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 795.65s of the 795.57s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=1.2/7.6 GB\n",
      "\t0.7376\t = Validation score   (roc_auc)\n",
      "\t944.62s\t = Training   runtime\n",
      "\t8.87s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the -158.54s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/7.3 GB\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.32, 'ExtraTreesEntr_BAG_L2': 0.28, 'ExtraTrees_r42_BAG_L2': 0.12, 'LightGBM_BAG_L3': 0.12, 'RandomForestEntr_BAG_L2': 0.08, 'RandomForestGini_BAG_L2': 0.04, 'LightGBMXT_BAG_L3': 0.04}\n",
      "\t0.7442\t = Validation score   (roc_auc)\n",
      "\t35.6s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10994.21s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 212.1 rows/s (25636 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.6 GB\n",
      "\t3.03s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.6 GB\n",
      "\t2.75s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t12.46s\t = Training   runtime\n",
      "\t7.89s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t13.13s\t = Training   runtime\n",
      "\t7.81s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t83.23s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.3s\t = Training   runtime\n",
      "\t7.6s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.73s\t = Training   runtime\n",
      "\t7.74s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.3 GB\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t52.31s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.94s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/6.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t732.56s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.1 GB\n",
      "\t7.03s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t9.22s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/6.0 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t59.19s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.3 GB\n",
      "\t12.03s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.1 GB\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t80.62s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t28.3s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.5 GB\n",
      "\t860.64s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.2/6.4 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t121.04s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t5.5s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t82.72s\t = Training   runtime\n",
      "\t8.12s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t79.19s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.167, 'CatBoost_BAG_L1': 0.111, 'NeuralNetFastAI_BAG_L1': 0.111, 'CatBoost_r177_BAG_L1': 0.111, 'NeuralNetTorch_r79_BAG_L1': 0.111, 'NeuralNetTorch_r22_BAG_L1': 0.111, 'XGBoost_r33_BAG_L1': 0.111, 'LightGBMXT_BAG_L1': 0.056, 'LightGBM_BAG_L1': 0.056, 'NeuralNetTorch_BAG_L1': 0.056}\n",
      "\t16.09s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t2.36s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t2.34s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t653.6s\t = Training   runtime\n",
      "\t8.82s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t49.48s\t = Training   runtime\n",
      "\t9.29s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t27.73s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t12.03s\t = Training   runtime\n",
      "\t8.39s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t12.72s\t = Training   runtime\n",
      "\t8.66s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.6/5.9 GB\n",
      "\tStopping at the best epoch learned earlier - 9.\n",
      "\t45.05s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t2.35s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t29.93s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t9.89s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t4.32s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.2 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t46.35s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t12.64s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.6/6.2 GB\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t91.84s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t16.3s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.1 GB\n",
      "\t6.2s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.3/6.1 GB\n",
      "/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t38.48s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t6.55s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t88.24s\t = Training   runtime\n",
      "\t10.01s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t13.71s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.6/5.9 GB\n",
      "\tStopping at the best epoch learned earlier - 3.\n",
      "\t9.05s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.375, 'ExtraTreesEntr_BAG_L2': 0.333, 'RandomForestEntr_BAG_L2': 0.125, 'ExtraTrees_r42_BAG_L2': 0.125, 'RandomForestGini_BAG_L2': 0.042}\n",
      "\t16.85s\t = Training   runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L3_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t2.47s\t = Training   runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L3_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.4/6.2 GB\n",
      "\t2.14s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t930.91s\t = Training   runtime\n",
      "\t8.47s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t944.62s\t = Training   runtime\n",
      "\t8.87s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.32, 'ExtraTreesEntr_BAG_L2': 0.28, 'ExtraTrees_r42_BAG_L2': 0.12, 'LightGBM_BAG_L3': 0.12, 'RandomForestEntr_BAG_L2': 0.08, 'RandomForestGini_BAG_L2': 0.04, 'LightGBMXT_BAG_L3': 0.04}\n",
      "\t35.6s\t = Training   runtime\n",
      "Refit complete, total runtime = 2522.44s ... Best model: \"WeightedEnsemble_L4\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/00 임신 예측/pregnancy-outcome-prediction-ai/Notebooks/ag_models_out_v17\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"2 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 2 missing columns: ['최종_배아_활용률', '미세주입_성공률'] | 88 available columns: ['ID', '시술 시기 코드', '시술 당시 나이', '임신 시도 또는 마지막 임신 경과 연수', '시술 유형', '특정 시술 유형', '배란 자극 여부', '배란 유도 유형', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 여성 요인', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 면역학적 요인', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '배아 생성 주요 이유', '총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부', '난자 채취 경과일', '난자 해동 경과일', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', 'BLASTOCYST_포함', 'AH_포함', '남성 결함 개수', '여성 결함 개수', '불임 원인 개수', '총 시술 bin3', '나이x이식배아', '연령별 배아 효율', '배아 생성 효율', '배아 이식 비율', '배아 저장 비율', '이상적 배양 기간', 'IVF 시술 대비 임신율', 'IVF 시술 대비 출산율', 'IVF 임신 유지력', 'DI 시술 대비 임신율', 'DI 시술 대비 출산율', 'DI 임신 유지력', '상세_진행_단계', '이식_취소_사유']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/features/generators/abstract.py:405\u001b[39m, in \u001b[36mAbstractFeatureGenerator.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(X.columns) != \u001b[38;5;28mself\u001b[39m.features_in:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# It comes at a cost when making a copy of the DataFrame,\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;66;03m# therefore, try avoid copying by checking the expected features first.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m         X = \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures_in\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['최종_배아_활용률', '미세주입_성공률'] not in index\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 255\u001b[39m\n\u001b[32m    234\u001b[39m predictor = TabularPredictor(\n\u001b[32m    235\u001b[39m     label=target,\n\u001b[32m    236\u001b[39m     eval_metric=\u001b[33m'\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    248\u001b[39m     save_space=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    249\u001b[39m )\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m pred_probs = \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m final_probs = pred_probs.iloc[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:2554\u001b[39m, in \u001b[36mTabularPredictor.predict_proba\u001b[39m\u001b[34m(self, data, model, as_pandas, as_multiclass, transform_features)\u001b[39m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m   2549\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m`predictor.predict_proba` is not supported when problem_type=\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.problem_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2550\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease call `predictor.predict` instead. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2551\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou can check the value of `predictor.can_predict_proba` to tell if predict_proba is valid.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2552\u001b[39m     )\n\u001b[32m   2553\u001b[39m data = \u001b[38;5;28mself\u001b[39m._get_dataset(data)\n\u001b[32m-> \u001b[39m\u001b[32m2554\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_learner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_multiclass\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_multiclass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:188\u001b[39m, in \u001b[36mAbstractTabularLearner.predict_proba\u001b[39m\u001b[34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m transform_features:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m     y_pred_proba = \u001b[38;5;28mself\u001b[39m.load_trainer().predict_proba(X, model=model)\n\u001b[32m    190\u001b[39m y_pred_proba = \u001b[38;5;28mself\u001b[39m._post_process_predict_proba(\n\u001b[32m    191\u001b[39m     y_pred_proba=y_pred_proba, as_pandas=as_pandas, index=X_index, as_multiclass=as_multiclass, inverse_transform=inverse_transform\n\u001b[32m    192\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:488\u001b[39m, in \u001b[36mAbstractTabularLearner.transform_features\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    487\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m feature_generator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_generators:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m         X = \u001b[43mfeature_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pregnancy/lib/python3.11/site-packages/autogluon/features/generators/abstract.py:411\u001b[39m, in \u001b[36mAbstractFeatureGenerator.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    409\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m X.columns:\n\u001b[32m    410\u001b[39m             missing_cols.append(col)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    412\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing_cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m required columns are missing from the provided dataset to transform using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing_cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m missing columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    414\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(X.columns))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m available columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(X.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    415\u001b[39m     )\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pre_astype_generator:\n\u001b[32m    417\u001b[39m     X = \u001b[38;5;28mself\u001b[39m._pre_astype_generator.transform(X)\n",
      "\u001b[31mKeyError\u001b[39m: \"2 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 2 missing columns: ['최종_배아_활용률', '미세주입_성공률'] | 88 available columns: ['ID', '시술 시기 코드', '시술 당시 나이', '임신 시도 또는 마지막 임신 경과 연수', '시술 유형', '특정 시술 유형', '배란 자극 여부', '배란 유도 유형', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 여성 요인', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 면역학적 요인', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '배아 생성 주요 이유', '총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부', '난자 채취 경과일', '난자 해동 경과일', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', 'BLASTOCYST_포함', 'AH_포함', '남성 결함 개수', '여성 결함 개수', '불임 원인 개수', '총 시술 bin3', '나이x이식배아', '연령별 배아 효율', '배아 생성 효율', '배아 이식 비율', '배아 저장 비율', '이상적 배양 기간', 'IVF 시술 대비 임신율', 'IVF 시술 대비 출산율', 'IVF 임신 유지력', 'DI 시술 대비 임신율', 'DI 시술 대비 출산율', 'DI 임신 유지력', '상세_진행_단계', '이식_취소_사유']\""
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드\n",
    "# ==========================================\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "target = '임신 성공 여부'\n",
    "\n",
    "# ==========================================\n",
    "# 2. feature_engineering\n",
    "# ==========================================\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \n",
    "    # 수치형 변환 ('회', ' 이상' 등을 제거하고 공백 정리 후 숫자형으로 변환)\n",
    "    count_cols = [\n",
    "        '총 시술 횟수', '클리닉 내 총 시술 횟수', '총 임신 횟수', '총 출산 횟수',\n",
    "        'IVF 시술 횟수', 'DI 시술 횟수', 'IVF 임신 횟수', 'DI 임신 횟수',\n",
    "        'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '이식된 배아 수', \n",
    "        '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '저장된 배아 수'\n",
    "    ]\n",
    "    \n",
    "    for col in count_cols:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype(str).str.replace(r'회| 이상', '', regex=True).str.strip()\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    \n",
    "    # 시술 유형 DI에 대한 결측치 처리 (0으로 채우기)\n",
    "    target_cols = [\n",
    "            '총 생성 배아 수', '기증자 정자와 혼합된 난자 수', '파트너 정자와 혼합된 난자 수',\n",
    "            '미세주입된 난자 수', '혼합된 난자 수', '저장된 신선 난자 수', '해동 난자 수',\n",
    "            '해동된 배아 수', '미세주입 후 저장된 배아 수', '저장된 배아 수',\n",
    "            '미세주입 배아 이식 수', '이식된 배아 수', '미세주입에서 생성된 배아 수',\n",
    "            '수집된 신선 난자 수', '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '대리모 여부',\n",
    "            '기증 배아 사용 여부', '신선 배아 사용 여부', '동결 배아 사용 여부'\n",
    "        ]\n",
    "    existing_target_cols = [c for c in target_cols if c in df.columns]\n",
    "    mask_di = df['시술 유형'] == 'DI'\n",
    "    df.loc[mask_di, existing_target_cols] = df.loc[mask_di, existing_target_cols].fillna(0)\n",
    "\n",
    "    \n",
    "    # 배아 생성 이유 정제\n",
    "    def clean_reason(row):\n",
    "        if row['시술 유형'] == 'DI':\n",
    "            return '해당없음'\n",
    "    \n",
    "        x = row['배아 생성 주요 이유']\n",
    "        if pd.isna(x): return 'Unknown'\n",
    "    \n",
    "        x = str(x)\n",
    "        if '시술용' in x: return '시술용'\n",
    "        if '기증' in x: return '기증용'\n",
    "        if '저장' in x: return '저장용'\n",
    "        return 'Other'\n",
    "    \n",
    "    df['배아 생성 주요 이유'] = df.apply(clean_reason, axis=1)\n",
    "\n",
    "    \n",
    "    # 이진 분류 컬럼 결측 0으로 채우기\n",
    "    binary_cols = ['PGS 시술 여부', 'PGD 시술 여부', '착상 전 유전 검사 사용 여부']\n",
    "    df[binary_cols] = df[binary_cols].fillna(0)\n",
    "    \n",
    "    \n",
    "    if '특정 시술 유형' in df.columns:\n",
    "        df[\"BLASTOCYST_포함\"] = df[\"특정 시술 유형\"].str.contains(\"BLASTOCYST\", case=False, na=False).astype(int)\n",
    "        df[\"AH_포함\"] = df[\"특정 시술 유형\"].str.contains(\"AH\", case=False, na=False).astype(int)\n",
    "        \n",
    "        def major_procedure(x):\n",
    "            if pd.isna(x): return \"Unknown\"\n",
    "            x = str(x).upper()\n",
    "\n",
    "            # 1. ICSI (ICSI:IVF나 ICSI:ICSI 등을 모두 포함)\n",
    "            if \"ICSI\" in x: return \"ICSI\"\n",
    "            # 2. IVF (ICSI가 없으면서 IVF가 포함된 경우)\n",
    "            if \"IVF\" in x: return \"IVF\"\n",
    "            # 3. DI (기증자 인공수정)\n",
    "            if \"DI\" in x: return \"DI\"\n",
    "            # 4. IUI, ICI, IVI (모두 넓은 의미의 인공수정 계열)\n",
    "            if any(keyword in x for keyword in [\"IUI\", \"ICI\", \"IVI\"]): return \"IUI\"\n",
    "            # 5. 기타 (GIFT, FER 등 아주 적은 수의 데이터)\n",
    "            if \"UNKNOWN\" in x: return \"Unknown\"\n",
    "            return \"Other\"\n",
    "        \n",
    "        df[\"특정 시술 유형\"] = df[\"특정 시술 유형\"].apply(major_procedure)\n",
    "\n",
    "    \n",
    "    # 불임 원인 및 복잡도 계산\n",
    "    female_cols = [\n",
    "        '불임 원인 - 여성 요인', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', \n",
    "        '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증'\n",
    "    ]\n",
    "    male_cols = [\n",
    "        '불임 원인 - 남성 요인', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', \n",
    "        '불임 원인 - 정자 형태', '불임 원인 - 정자 면역학적 요인'\n",
    "    ]\n",
    "    infertility_cols = [\n",
    "        \"남성 주 불임 원인\", \"남성 부 불임 원인\", \"여성 주 불임 원인\", \"여성 부 불임 원인\",\n",
    "        \"부부 주 불임 원인\", \"부부 부 불임 원인\", \"불명확 불임 원인\",\n",
    "        \"불임 원인 - 난관 질환\", \"불임 원인 - 남성 요인\", \"불임 원인 - 배란 장애\",\n",
    "        \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\",\n",
    "        \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\",\n",
    "        \"불임 원인 - 정자 형태\"\n",
    "    ]\n",
    "\n",
    "    df['남성 결함 개수'] = df[male_cols].sum(axis=1)\n",
    "    df['여성 결함 개수'] = df[female_cols].sum(axis=1)\n",
    "    df['불임 원인 개수'] = df[infertility_cols].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df['불임 원인 개수'] = df['불임 원인 개수'].apply(infertility_complexity)\n",
    "\n",
    "    \n",
    "    # 총 시술 횟수 -> 3구간으로 구간화\n",
    "    def collapse_trials(x):\n",
    "        if pd.isna(x): return 'Unknown'\n",
    "        if x <= 0: return '0회' \n",
    "        elif 1 <= x <= 2: return '1–2회'\n",
    "        elif 3 <= x <= 5: return '3–5회'\n",
    "        else: return '6회 이상'\n",
    "\n",
    "    df[\"총 시술 bin3\"] = df[\"총 시술 횟수\"].apply(collapse_trials)\n",
    "\n",
    "\n",
    "    def div(num1, num2):\n",
    "        return np.where(num2 == 0, -1, num1 / num2)\n",
    "\n",
    "    if '시술 당시 나이' in df.columns:\n",
    "        temp_age = df['시술 당시 나이'].astype(str).str.extract(r'(\\d+)')[0].astype(float)\n",
    "    else:\n",
    "        temp_age = np.nan\n",
    "    \n",
    "    df['나이x이식배아'] = (temp_age + 1) * df['이식된 배아 수']\n",
    "    df['연령별 배아 효율'] = div(df['이식된 배아 수'], (temp_age + 1))\n",
    "    \n",
    "    df['배아 생성 효율'] = div(df['총 생성 배아 수'], df['수집된 신선 난자 수'])\n",
    "    df['배아 이식 비율'] = div(df['이식된 배아 수'], df['총 생성 배아 수'])\n",
    "    df['배아 저장 비율'] = div(df['저장된 배아 수'], df['총 생성 배아 수'])\n",
    "    \n",
    "    df['이상적 배양 기간'] = df['배아 이식 경과일'].isin([3, 5]).astype(int)\n",
    "\n",
    "    df['IVF 시술 대비 임신율'] = div(df['IVF 임신 횟수'], df['IVF 시술 횟수'])\n",
    "    df['IVF 시술 대비 출산율'] = div(df['IVF 출산 횟수'], df['IVF 시술 횟수'])\n",
    "    df['IVF 임신 유지력'] = div(df['IVF 출산 횟수'], df['IVF 임신 횟수'])\n",
    "\n",
    "    df['DI 시술 대비 임신율'] = div(df['DI 임신 횟수'], df['DI 시술 횟수'])\n",
    "    df['DI 시술 대비 출산율'] = div(df['DI 출산 횟수'], df['DI 시술 횟수'])\n",
    "    df['DI 임신 유지력'] = div(df['DI 출산 횟수'], df['DI 임신 횟수'])\n",
    "\n",
    "    \n",
    "    # 시술 중단 단계\n",
    "    def define_detailed_stage(row):\n",
    "        if row['이식된 배아 수'] > 0: # 1. 이식이 실제로 이루어진 경우 (가장 성공에 근접)\n",
    "            return '4_이식완료'\n",
    "        elif row['저장된 배아 수'] > 0: # 2. 이식은 안 했지만, 냉동 보관된 배아가 있는 경우 (이번엔 실패/연기지만 배아는 확보됨)\n",
    "            return '3_전체동결(이식보류)'\n",
    "        elif row['총 생성 배아 수'] > 0: # 3. 배아는 생성되었으나 이식도 못 하고 저장도 못한 경우 (배아 발달 중지 등)\n",
    "            return '2_배아생성후_소실'\n",
    "        elif row['수집된 신선 난자 수'] > 0 or row['혼합된 난자 수'] > 0: # 4. 난자는 채취했으나 수정(배아 생성)에 실패한 경우\n",
    "            return '1_수정실패'\n",
    "        else: # 5. 난자 채취조차 실패했거나 기록이 없는 경우\n",
    "            return '0_채취단계_실패_또는_정보없음'\n",
    "\n",
    "    df['상세_진행_단계'] = df.apply(define_detailed_stage, axis=1)\n",
    "    \n",
    "\n",
    "    # 이식 취소 원인\n",
    "    def explain_cancellation(row):\n",
    "        if row['이식된 배아 수'] > 0:\n",
    "            return 'Normal_Transfer' # 정상 이식\n",
    "        if row['총 생성 배아 수'] == 0:\n",
    "            return 'Fail_No_Embryos' # 배아가 없어서 못함\n",
    "        if row['저장된 배아 수'] > 0:\n",
    "            return 'Freeze_All' # 의도적인 전체 동결 (Freeze-all 전략 등)\n",
    "        if row['착상 전 유전 진단 사용 여부'] == 1:\n",
    "            return 'PGT_Fail' # 유전 검사 탈락 가능성\n",
    "        return 'Unknown_Fail'\n",
    "\n",
    "    df['이식_취소_사유'] = df.apply(explain_cancellation, axis=1)\n",
    "\n",
    "    # 배아 생존율 및 생산 효율\n",
    "    df['최종_배아_활용률'] = div(df['이식된 배아 수'] + df['저장된 배아 수'], df['수집된 신선 난자 수'])\n",
    "    df['미세주입_성공률'] = div(df['미세주입에서 생성된 배아 수'], df['미세주입된 난자 수'])\n",
    "    \n",
    "    df.drop('ID', errors='ignore', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 데이터 타입 최적화\n",
    "# ==========================================\n",
    "\n",
    "def optimize_memory(df):\n",
    "    for col in df.columns:\n",
    "        # 숫자형 데이터 최적화\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            if df[col].dtype == 'int64':\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        \n",
    "        # 문자열(object) 데이터 -> 범주형(category) 변환\n",
    "        elif df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "train_df = optimize_memory(train_df)\n",
    "test_df = optimize_memory(test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 4. 모델 학습 설정\n",
    "# ==========================================\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target,\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='ag_models_out_v17',\n",
    ").fit(\n",
    "    train_data=train_df,\n",
    "    time_limit=10800,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=10,\n",
    "    num_bag_sets=1,\n",
    "    num_stack_levels=2,\n",
    "    refit_full=True,\n",
    "    dynamic_stacking=False,\n",
    "    save_space=True,\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 예측 (Test Data 활용) - 최종 결과를 확률로 출력 (Positive 클래스에 대한 확률만 추출)\n",
    "# ==========================================\n",
    "\n",
    "pred_probs = predictor.predict_proba(test_df)\n",
    "final_probs = pred_probs.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca412e5d-8496-45dd-9636-a0159ca867ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 리더보드 출력 ---\n",
    "lb = predictor.leaderboard(train_df, silent=True)\n",
    "display(lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985a34d-f1b7-46bf-8070-07e7ac57b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 제출 파일 생성 ---\n",
    "submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "submission['probability'] = final_probs.values\n",
    "\n",
    "# 현재 시간 가져오기 (예: 0206_1031)\n",
    "now = datetime.now().strftime('%m%d_%H%M')\n",
    "file_name = f\"{now}_submission.csv\"\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"학습 및 예측이 완료되었습니다. 결과가 {file_name}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071af307-e3fb-4ed3-849a-315f093665cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 피처 중요도 ---\n",
    "# fi = predictor.feature_importance(data=train_df.sample(n=min(5000, len(train_df)), random_state=42))\n",
    "# fi.to_excel('fi17.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e70433-c8c3-4a0c-b3d0-374a517651d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pregnancy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
