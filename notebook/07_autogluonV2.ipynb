{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ecf535",
   "metadata": {},
   "source": [
    "1. í™•ì • ì¼€ì´ìŠ¤ (3ê°œ)\n",
    "í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤ (ì €ì¥ìš©/ê¸°ì¦ìš©/ë‚˜ì´ë¶ˆëª…)\n",
    "\n",
    "\n",
    "2. í™•ì •_ì„±ê³µ_ê°€ëŠ¥_ì¼€ì´ìŠ¤ (ìµœì  ì¡°ê±´)\n",
    "\n",
    "\n",
    "3. ê³ ìœ„í—˜_ì¼€ì´ìŠ¤ (ê³ ë ¹ + ë‹¤íšŒì‹œìˆ  + ë°°ì•„ë¶€ì¡±)2. í’ˆì§ˆ ì ìˆ˜ë“¤ (4ê°œ)\n",
    "ë°°ì•„_í’ˆì§ˆ_ì ìˆ˜ (Day5 + 1-2ê°œ + íš¨ìœ¨)\n",
    "\n",
    "\n",
    "5. ë‚œì_í’ˆì§ˆ_ì ìˆ˜ (ìˆ˜ì§‘ìˆ˜ + í˜¼í•©ë¹„ìœ¨)\n",
    "\n",
    "\n",
    "6. ì‹œìˆ _í’ˆì§ˆ_ì ìˆ˜ (BLASTOCYST + ICSI)\n",
    "\n",
    "\n",
    "7. ì¢…í•©_ì„ì‹ _ê°€ëŠ¥_ì ìˆ˜ (ë‚˜ì´ + ë°°ì•„ + ì‹œìˆ )3. ê³¼ê±° ì„±ê³µë¥  (4ê°œ)\n",
    "IVF_ê³¼ê±°_ì„±ê³µë¥ \n",
    "\n",
    "\n",
    "9. DI_ê³¼ê±°_ì„±ê³µë¥ \n",
    "\n",
    "\n",
    "10. ì „ì²´_ì„ì‹ _ì„±ê³µë¥  (ì´ ì„ì‹ /ì´ ì‹œìˆ )\n",
    "\n",
    "\n",
    "11. ì „ì²´_ì¶œì‚°_ì„±ê³µë¥  (ì´ ì¶œì‚°/ì´ ì„ì‹ )4. ê²½ê³¼ì¼ ê°„ê²© (3ê°œ)\n",
    "ì±„ì·¨_í˜¼í•©_ê°„ê²© (ë‚œì ì±„ì·¨â†’í˜¼í•©)\n",
    "\n",
    "\n",
    "13. í˜¼í•©_ì´ì‹_ê°„ê²© (í˜¼í•©â†’ì´ì‹)\n",
    "\n",
    "\n",
    "14. ì±„ì·¨_ì´ì‹_ì´ê°„ê²© (ì±„ì·¨â†’ì´ì‹)5. ë°°ì•„ íš¨ìœ¨ ì‹¬í™” (3ê°œ)\n",
    "ë°°ì•„_í™œìš©ë¥  ((ì´ì‹+ì €ì¥)/ìƒì„±)\n",
    "\n",
    "\n",
    "16. ë°°ì•„_ì„ ë³„ë¥  ((ìƒì„±-ì´ì‹)/ìƒì„±)\n",
    "\n",
    "\n",
    "17. ë¯¸ì„¸ì£¼ì…_ì„±ê³µë¥  (ë¯¸ì„¸ì£¼ì… ë°°ì•„/ë‚œì)6. êµí˜¸ì‘ìš© ì‹¬í™” (3ê°œ)\n",
    "ë‚˜ì´Ã—ë°°ì•„ìˆ˜Ã—Day5 (3-way)\n",
    "\n",
    "\n",
    "19. ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´Ã—ë¶ˆì„ì›ì¸\n",
    "\n",
    "\n",
    "20. ê³ ë ¹Ã—ICSIÃ—ë‹¤ë°°ì•„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85c784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AutoGluon Weekend Special - 35+ Features\n",
      "================================================================================\n",
      "\n",
      "ì „ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=10, num_bag_sets=2\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 28800 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: ../outputs/autogluon_weekend_special/ds_sub_fit/sub_fit_ho.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (256351, 104)\n",
      "âœ… Test shape: (90067, 103)\n",
      "\n",
      "ìµœì¢… Feature ê°œìˆ˜: 101ê°œ\n",
      "\n",
      "================================================================================\n",
      "AutoGluon Training - Weekend Special\n",
      "================================================================================\n",
      "\n",
      "â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 5~8ì‹œê°„\n",
      "ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 8-16GB ì˜ˆìƒ\n",
      "\n",
      "í•™ìŠµ ì‹œì‘...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 19:13:42,274\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 6645 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 22155 seconds.\n",
      "Starting full fit now with num_stack_levels 2.\n",
      "Beginning AutoGluon training ... Time limit = 22155s\n",
      "AutoGluon will save models to \"../outputs/autogluon_weekend_special\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       4.84 GB / 16.00 GB (30.2%)\n",
      "Disk Space Avail:   215.51 GB / 460.43 GB (46.8%)\n",
      "===================================================\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 101\n",
      "Label Column:       ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5820.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 863.01 MB (14.8% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 14.8% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 29 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 37 | ['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])    : 27 | ['ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t\t('object', []) : 31 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ì‹œìˆ  ìœ í˜•', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 30 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', 'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ', ...]\n",
      "\t\t('float', [])     : 36 | ['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])       :  5 | ['ë¶ˆì„_ì›ì¸_ê°œìˆ˜', 'ë°°ì•„_í’ˆì§ˆ_ì ìˆ˜', 'ë‚œì_í’ˆì§ˆ_ì ìˆ˜', 'ì‹œìˆ _í’ˆì§ˆ_ì ìˆ˜', 'ì¢…í•©_ì„ì‹ _ê°€ëŠ¥_ì ìˆ˜']\n",
      "\t\t('int', ['bool']) : 24 | ['ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t3.3s = Fit runtime\n",
      "\t95 features in original data used to generate 95 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 93.40 MB (1.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.76s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'AG_AUTOMM': {},\n",
      "\t'VW': {},\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 8 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 9842.53s of the 22151.23s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.90% memory usage per fold, 47.58%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.90%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t16.12s\t = Training   runtime\n",
      "\t1.82s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9824.35s of the 22133.05s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.34% memory usage per fold, 45.36%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.34%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t18.17s\t = Training   runtime\n",
      "\t2.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 9804.11s of the 22112.81s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.63% memory usage per fold, 42.52%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.63%)\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t2644.19s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 7158.07s of the 19466.78s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.81% memory usage per fold, 67.25%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=16.81%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t462.63s\t = Training   runtime\n",
      "\t1.97s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 6692.74s of the 19001.44s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.64% memory usage per fold, 42.55%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.64%)\n",
      "\t0.7369\t = Validation score   (roc_auc)\n",
      "\t341.74s\t = Training   runtime\n",
      "\t2.54s\t = Validation runtime\n",
      "Fitting model: VowpalWabbit_BAG_L1 ... Training model for up to 6347.88s of the 18656.58s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.05% memory usage per fold, 72.37%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.05%)\n",
      "\tWarning: Exception caused VowpalWabbit_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=25914, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=25914, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 6344.88s of the 18653.58s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.55% memory usage per fold, 46.19%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.55%)\n",
      "2026-02-06 22:02:54,901\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-06 22:02:54,906\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-06 22:02:54,906\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-06 22:02:54,907\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-06 22:02:54,909\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-06 22:02:54,910\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-06 22:02:54,910\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-06 22:02:54,911\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-06 22:02:54,912\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.738\t = Validation score   (roc_auc)\n",
      "\t27.48s\t = Training   runtime\n",
      "\t2.9s\t = Validation runtime\n",
      "Fitting model: MultiModalPredictor_BAG_L1 ... Training model for up to 6315.25s of the 18623.95s of remaining time.\n",
      "\tWarning: Exception caused MultiModalPredictor_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe total system num_gpus=0 is less than minimum num_gpus=1 to fit StackerEnsembleModel. Consider using a machine with more GPUs.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 847, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 528, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 759, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 704, in _calculate_total_resources\n",
      "    system_num_gpus >= minimum_model_num_gpus\n",
      "AssertionError: The total system num_gpus=0 is less than minimum num_gpus=1 to fit StackerEnsembleModel. Consider using a machine with more GPUs.\n",
      "Repeating k-fold bagging: 2/2\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 6312.51s of the 18621.21s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.86% memory usage per fold, 43.44%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.86%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t30.34s\t = Training   runtime\n",
      "\t3.48s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 6296.34s of the 18605.05s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.73% memory usage per fold, 46.92%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.73%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t36.54s\t = Training   runtime\n",
      "\t4.39s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 6276.02s of the 18584.72s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.52% memory usage per fold, 50.08%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.52%)\n",
      "\t0.7404\t = Validation score   (roc_auc)\n",
      "\t5155.87s\t = Training   runtime\n",
      "\t1.31s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3762.4s of the 16071.1s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.86% memory usage per fold, 75.44%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=18.86%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t938.79s\t = Training   runtime\n",
      "\t3.89s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3283.4s of the 15592.1s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.28% memory usage per fold, 45.11%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.28%)\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t597.47s\t = Training   runtime\n",
      "\t5.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3025.04s of the 15333.74s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.94% memory usage per fold, 47.77%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.94%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t54.83s\t = Training   runtime\n",
      "\t5.98s\t = Validation runtime\n",
      "Completed 2/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 984.25s of the 15303.7s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.529, 'NeuralNetTorch_BAG_L1': 0.176, 'LightGBMXT_BAG_L1': 0.118, 'XGBoost_BAG_L1': 0.118, 'LightGBMLarge_BAG_L1': 0.059}\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t7.1s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting 6 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 10195.14s of the 15296.51s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.38% memory usage per fold, 49.51%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.38%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t11.74s\t = Training   runtime\n",
      "\t0.96s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 10181.24s of the 15282.61s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.99% memory usage per fold, 47.98%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.99%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t12.03s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 10167.27s of the 15268.64s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.58% memory usage per fold, 50.32%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.58%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t971.02s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 9194.34s of the 14295.71s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.67% memory usage per fold, 78.66%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=19.67%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t268.05s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 8923.69s of the 14025.06s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.52% memory usage per fold, 42.09%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.52%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t248.47s\t = Training   runtime\n",
      "\t2.55s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 8672.5s of the 13773.87s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.92% memory usage per fold, 55.67%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=13.92%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t26.47s\t = Training   runtime\n",
      "\t2.02s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/2\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 8643.35s of the 13744.72s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.35% memory usage per fold, 49.41%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.35%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t23.54s\t = Training   runtime\n",
      "\t1.85s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 8629.68s of the 13731.05s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.89% memory usage per fold, 47.56%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.89%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t24.35s\t = Training   runtime\n",
      "\t2.37s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 8615.44s of the 13716.81s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.24% memory usage per fold, 44.96%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.24%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t1537.82s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 8046.88s of the 13148.25s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.50% memory usage per fold, 73.99%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=18.50%)\n",
      "\t0.74\t = Validation score   (roc_auc)\n",
      "\t502.42s\t = Training   runtime\n",
      "\t3.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 7809.93s of the 12911.3s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.85% memory usage per fold, 43.38%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.85%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t480.17s\t = Training   runtime\n",
      "\t5.16s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 7575.86s of the 12677.23s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.06% memory usage per fold, 56.24%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=14.06%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t50.49s\t = Training   runtime\n",
      "\t3.95s\t = Validation runtime\n",
      "Completed 2/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 1019.51s of the 12650.57s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.5, 'XGBoost_BAG_L2': 0.3, 'NeuralNetTorch_BAG_L2': 0.1, 'LightGBMLarge_BAG_L2': 0.1}\n",
      "\t0.7403\t = Validation score   (roc_auc)\n",
      "\t7.17s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting 6 L3 models ...\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 12643.34s of the 12643.31s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.25% memory usage per fold, 48.99%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.25%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t12.22s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 12629.15s of the 12629.11s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.83% memory usage per fold, 51.30%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.83%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t12.16s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 12615.05s of the 12615.01s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.66% memory usage per fold, 46.65%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.66%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t604.15s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 12009.07s of the 12009.03s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.50% memory usage per fold, 70.01%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=17.50%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t235.19s\t = Training   runtime\n",
      "\t1.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 11771.48s of the 11771.44s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.54% memory usage per fold, 76.29%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.54%)\n",
      "\t0.7383\t = Validation score   (roc_auc)\n",
      "\t124.39s\t = Training   runtime\n",
      "\t2.38s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 11644.52s of the 11644.48s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.25% memory usage per fold, 49.00%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.25%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t19.62s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/2\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 11622.29s of the 11622.26s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.70% memory usage per fold, 46.81%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.70%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t22.47s\t = Training   runtime\n",
      "\t1.77s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 11610.32s of the 11610.29s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.62% memory usage per fold, 46.50%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.62%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t22.6s\t = Training   runtime\n",
      "\t2.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 11598.19s of the 11598.15s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.95% memory usage per fold, 51.80%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.95%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t1162.18s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 11038.5s of the 11038.46s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.15% memory usage per fold, 64.60%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=16.15%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t513.82s\t = Training   runtime\n",
      "\t2.84s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 10757.57s of the 10757.53s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.81% memory usage per fold, 78.51%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.81%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t237.59s\t = Training   runtime\n",
      "\t4.64s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 10642.04s of the 10642.0s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.03% memory usage per fold, 48.11%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.03%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t38.61s\t = Training   runtime\n",
      "\t3.46s\t = Validation runtime\n",
      "Completed 2/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 1264.33s of the 10620.53s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.471, 'XGBoost_BAG_L1': 0.176, 'NeuralNetTorch_BAG_L1': 0.176, 'LightGBMXT_BAG_L1': 0.118, 'LightGBMLarge_BAG_L2': 0.059}\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t14.23s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11548.79s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../outputs/autogluon_weekend_special\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AutoGluon Results\n",
      "================================================================================\n",
      "\n",
      "=== Model Leaderboard (Top 20) ===\n",
      "                    model  score_test  score_val eval_metric  pred_time_test  pred_time_val      fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    LightGBMLarge_BAG_L1    0.774003   0.738555     roc_auc       14.162534       5.977197     54.827851                14.162534                5.977197          54.827851            1       True          6\n",
      "1    LightGBMLarge_BAG_L3    0.762386   0.739199     roc_auc      203.024789      44.941889   9471.225227                 9.423077                3.457149          38.608250            3       True         20\n",
      "2    LightGBMLarge_BAG_L2    0.762203   0.739440     roc_auc      114.846477      28.013019   6864.321937                 9.976334                3.954448          50.494509            2       True         13\n",
      "3       LightGBMXT_BAG_L3    0.757374   0.739274     roc_auc      199.486732      43.603050   9455.214053                 5.885020                2.118311          22.597075            3       True         16\n",
      "4         LightGBM_BAG_L3    0.756871   0.739540     roc_auc      198.821425      43.256395   9455.087332                 5.219713                1.771655          22.470355            3       True         15\n",
      "5          XGBoost_BAG_L3    0.756460   0.739459     roc_auc      218.431225      44.325578   9946.435179                24.829513                2.840839         513.818201            3       True         18\n",
      "6       LightGBMXT_BAG_L2    0.756208   0.739677     roc_auc      110.831289      26.424645   6838.181838                 5.961146                2.366073          24.354410            2       True          9\n",
      "7         CatBoost_BAG_L3    0.755874   0.739821     roc_auc      195.631888      42.216064  10594.794313                 2.030176                0.731324        1162.177336            3       True         17\n",
      "8     WeightedEnsemble_L3    0.755239   0.740260     roc_auc      182.300236      37.313524   9391.893329                 0.002911                0.046210           7.166315            3       True         14\n",
      "9         CatBoost_BAG_L2    0.754673   0.740132     roc_auc      107.021237      24.860706   8351.645335                 2.151095                0.802134        1537.817907            2       True         10\n",
      "10        LightGBM_BAG_L2    0.754660   0.739856     roc_auc      110.213383      25.909924   6837.362982                 5.343241                1.851353          23.535554            2       True          8\n",
      "11         XGBoost_BAG_L2    0.753986   0.739982     roc_auc      129.938990      27.349382   7316.246343                25.068847                3.290810         502.418915            2       True         11\n",
      "12  NeuralNetTorch_BAG_L2    0.753099   0.739355     roc_auc      145.101048      29.219921   7293.995683                40.230906                5.161350         480.168255            2       True         12\n",
      "13        LightGBM_BAG_L1    0.752876   0.739322     roc_auc        9.081858       3.479709     30.336174                 9.081858                3.479709          30.336174            1       True          1\n",
      "14         XGBoost_BAG_L1    0.752840   0.739507     roc_auc       25.777915       3.888253    938.790304                25.777915                3.888253         938.790304            1       True          4\n",
      "15  NeuralNetTorch_BAG_L3    0.752697   0.739090     roc_auc      232.988117      46.122767   9670.209090                39.386405                4.638028         237.592113            3       True         19\n",
      "16      LightGBMXT_BAG_L1    0.752291   0.739759     roc_auc       10.941568       4.392112     36.537014                10.941568                4.392112          36.537014            1       True          2\n",
      "17    WeightedEnsemble_L2    0.751321   0.740629     roc_auc       95.792839      20.625690   6790.594445                 0.004555                0.046827           7.103191            2       True          7\n",
      "18    WeightedEnsemble_L4    0.750794   0.740628     roc_auc      114.850622      28.051624   6878.548694                 0.004146                0.038605          14.226757            4       True         21\n",
      "19        CatBoost_BAG_L1    0.749176   0.740381     roc_auc        5.211622       1.308800   5155.869257                 5.211622                1.308800        5155.869257            1       True          3\n",
      "\n",
      "ğŸ† Best Model: LightGBMLarge_BAG_L1\n",
      "ğŸ¯ Best CV AUC: 0.738555\n",
      "\n",
      "ğŸ“ˆ Previous Best (03ë²ˆ): 0.7407\n",
      "ğŸš€ Improvement: +-0.002145\n",
      "\n",
      "================================================================================\n",
      "Generating Predictions\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  í™•ì • ì‹¤íŒ¨ ì¼€ì´ìŠ¤ 4205ê°œ â†’ ê°•ì œë¡œ 0.0 ì„¤ì •\n",
      "\n",
      "ì˜ˆì¸¡ê°’ í†µê³„:\n",
      "Min:  0.000000\n",
      "Max:  0.742801\n",
      "Mean: 0.258838\n",
      "Std:  0.159289\n",
      "\n",
      "âœ… Submission saved!\n",
      "   File: ../outputs/07_submission_autogluon_weekend(0206).csv\n",
      "âœ… Leaderboard saved: ../07_outputs/autogluon_weekend_leaderboard.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 95 features using 5000 rows with 5 shuffle sets...\n",
      "\t1270.16s\t= Expected runtime (254.03s per shuffle set)\n",
      "\t887.85s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature importance saved\n",
      "\n",
      "=== Top 30 Features ===\n",
      "               importance    stddev   p_value  n  p99_high   p99_low\n",
      "ì´ì‹ëœ ë°°ì•„ ìˆ˜         0.015188  0.003746  0.000410  5  0.022900  0.007475\n",
      "ì´ì‹ë°°ì•„_êµ¬ê°„          0.015000  0.003622  0.000378  5  0.022458  0.007543\n",
      "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´         0.008095  0.003016  0.001939  5  0.014306  0.001885\n",
      "ì €ì¥ëœ ë°°ì•„ ìˆ˜         0.004096  0.003161  0.022111  5  0.010603 -0.002412\n",
      "ì‹œìˆ  ì‹œê¸° ì½”ë“œ         0.003289  0.000579  0.000111  5  0.004481  0.002096\n",
      "ë‚˜ì´_3êµ¬ê°„           0.002990  0.002046  0.015431  5  0.007202 -0.001223\n",
      "ë‚˜ì´Ã—ë°°ì•„ìˆ˜Ã—Day5      0.002738  0.001918  0.016566  5  0.006686 -0.001210\n",
      "ë‚œì ì¶œì²˜            0.002446  0.000771  0.001040  5  0.004033  0.000859\n",
      "ë°°ì•„_ì €ì¥_ë¹„ìœ¨         0.002251  0.001885  0.027891  5  0.006133 -0.001630\n",
      "ë‚˜ì´Ã—Day5          0.002159  0.001078  0.005494  5  0.004378 -0.000060\n",
      "ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´Ã—ë¶ˆì„       0.002061  0.000306  0.000057  5  0.002692  0.001430\n",
      "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜      0.002051  0.000853  0.002892  5  0.003807  0.000295\n",
      "ë°°ì•„_ìƒì„±_íš¨ìœ¨         0.001568  0.000334  0.000233  5  0.002256  0.000881\n",
      "ë°°ë€ ìœ ë„ ìœ í˜•         0.001559  0.000502  0.001128  5  0.002592  0.000526\n",
      "ë‚œì ê¸°ì¦ì ë‚˜ì´        0.001428  0.000806  0.008343  5  0.003088 -0.000232\n",
      "í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜    0.001330  0.000880  0.013904  5  0.003142 -0.000482\n",
      "ë‚œì ì±„ì·¨ ê²½ê³¼ì¼        0.001071  0.000525  0.005165  5  0.002151 -0.000010\n",
      "ë¯¸ì„¸ì£¼ì…_ì„±ê³µë¥          0.001040  0.000453  0.003409  5  0.001972  0.000107\n",
      "í˜¼í•©_ì´ì‹_ê°„ê²©         0.001029  0.001229  0.067330  5  0.003560 -0.001502\n",
      "ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜    0.000983  0.000336  0.001418  5  0.001676  0.000290\n",
      "ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼        0.000968  0.000714  0.019371  5  0.002437 -0.000502\n",
      "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ       0.000944  0.000402  0.003140  5  0.001771  0.000117\n",
      "ì´ ìƒì„± ë°°ì•„ ìˆ˜        0.000934  0.001440  0.110425  5  0.003899 -0.002032\n",
      "í•´ë™ëœ ë°°ì•„ ìˆ˜         0.000896  0.000362  0.002598  5  0.001640  0.000151\n",
      "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜       0.000838  0.000262  0.001016  5  0.001379  0.000298\n",
      "ì •ì ì¶œì²˜            0.000824  0.000754  0.035478  5  0.002377 -0.000729\n",
      "ë°°ì•„_ì´ì‹_ë¹„ìœ¨         0.000824  0.000860  0.049468  5  0.002594 -0.000947\n",
      "ë°°ì•„_ì§„í–‰_ë‹¨ê³„         0.000774  0.000897  0.063008  5  0.002621 -0.001073\n",
      "ë°°ì•„_í™œìš©ë¥            0.000770  0.000331  0.003244  5  0.001452  0.000089\n",
      "IVF_ê³¼ê±°_ì„±ê³µë¥        0.000770  0.000837  0.054399  5  0.002494 -0.000954\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== AutoGluon Weekend Special Summary ===\n",
      "\n",
      "Total Features: 101\n",
      "  - ì›ë³¸: 64ê°œ (ê³ ê²°ì¸¡ 5ê°œ ì œê±°)\n",
      "  - íŒŒìƒ: 37ê°œ\n",
      "\n",
      "Best Model: LightGBMLarge_BAG_L1\n",
      "CV AUC: 0.738555\n",
      "\n",
      "Training Time: 8ì‹œê°„\n",
      "Models Trained: 21\n",
      "\n",
      "Top 5 Models:\n",
      "  1. LightGBMLarge_BAG_L1: 0.738555\n",
      "  2. LightGBMLarge_BAG_L3: 0.739199\n",
      "  3. LightGBMLarge_BAG_L2: 0.739440\n",
      "  4. LightGBMXT_BAG_L3: 0.739274\n",
      "  5. LightGBM_BAG_L3: 0.739540\n",
      "\n",
      "Improvement from 03ë²ˆ: +-0.002145\n",
      "================================================================================\n",
      "\n",
      "âœ… Summary saved: ../outputs/07_autogluon_weekend_summary.txt\n",
      "\n",
      "================================================================================\n",
      "WEEKEND SPECIAL COMPLETE! ğŸ‰\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AutoGluon Weekend Special - 35+ Features\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 0) Load\n",
    "# ============================================================\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "TEST_PATH  = \"../data/test.csv\"\n",
    "SUB_PATH   = \"../data/sample_submission.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "sub   = pd.read_csv(SUB_PATH)\n",
    "\n",
    "TARGET_COL = \"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"\n",
    "ID_COL = \"ID\"\n",
    "\n",
    "# ============================================================\n",
    "# 1) Feature Engineering (35+ Features)\n",
    "# ============================================================\n",
    "\n",
    "# ê³ ê²°ì¸¡ ë³€ìˆ˜ ì œê±°\n",
    "HIGH_MISSING_COLS = [\n",
    "    'ë‚œì í•´ë™ ê²½ê³¼ì¼',           # 99.4%\n",
    "    'PGS ì‹œìˆ  ì—¬ë¶€',             # 99.2%\n",
    "    'PGD ì‹œìˆ  ì—¬ë¶€',             # 99.1%\n",
    "    'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', # 98.9%\n",
    "    'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜',  # 96.3%\n",
    "]\n",
    "\n",
    "EMBRYO_STAGE_COLS = [\n",
    "    \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\",\"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\",\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "    \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\",\"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ ë‚œì ìˆ˜\",\n",
    "    \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "]\n",
    "\n",
    "INFERTILITY_COLS = [\n",
    "    \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\",\"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\",\"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\",\"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\",\"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\",\"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"\n",
    "]\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return np.where(b == 0, 0.0, a / b)\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ê³ ê²°ì¸¡ ì œê±°\n",
    "    df = df.drop(columns=HIGH_MISSING_COLS, errors='ignore')\n",
    "    \n",
    "    # === ê¸°ë³¸ íŒŒìƒë³€ìˆ˜ (03ë²ˆê³¼ ë™ì¼) ===\n",
    "    \n",
    "    # 1. ì‹œìˆ _ëŒ€ë¶„ë¥˜\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        x = str(x)\n",
    "        if \"IUI\" in x: return \"IUI\"\n",
    "        if \"ICSI\" in x: return \"ICSI\"\n",
    "        if \"IVF\" in x: return \"IVF\"\n",
    "        if \"DI\" in x: return \"DI\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df[\"ì‹œìˆ _ëŒ€ë¶„ë¥˜\"] = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(major_procedure)\n",
    "    \n",
    "    # 2. BLASTOCYST_í¬í•¨\n",
    "    s = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].astype(\"object\").fillna(\"Unknown\").astype(str)\n",
    "    df[\"BLASTOCYST_í¬í•¨\"] = s.str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    df[\"AH_í¬í•¨\"] = s.str.contains(\"AH\", na=False).astype(int)\n",
    "    df[\"ICSI_í¬í•¨\"] = s.str.contains(\"ICSI\", na=False).astype(int)\n",
    "    \n",
    "    # 3. ë°°ì•„_ì´ì‹_ì—¬ë¶€\n",
    "    df[\"ë°°ì•„_stage_missing_count\"] = df[EMBRYO_STAGE_COLS].isna().sum(axis=1)\n",
    "    df[\"ë°°ì•„_ì´ì‹_ì—¬ë¶€\"] = (df[\"ë°°ì•„_stage_missing_count\"] < len(EMBRYO_STAGE_COLS)).astype(int)\n",
    "    \n",
    "    # 4. ë°°ì•„_ì§„í–‰_ë‹¨ê³„\n",
    "    def embryo_stage(row):\n",
    "        if row['ë°°ì•„_ì´ì‹_ì—¬ë¶€'] == 0:\n",
    "            return 'ë°°ì•„ë‹¨ê³„_ë¯¸ë„ë‹¬'\n",
    "        total = pd.to_numeric(row.get('ì´ ìƒì„± ë°°ì•„ ìˆ˜'), errors='coerce')\n",
    "        implanted = pd.to_numeric(row.get('ì´ì‹ëœ ë°°ì•„ ìˆ˜'), errors='coerce')\n",
    "        if pd.isna(total) or total == 0:\n",
    "            return 'ë°°ì•„ìƒì„±_ì‹¤íŒ¨'\n",
    "        elif pd.isna(implanted) or implanted == 0:\n",
    "            return 'ì´ì‹_ë¯¸ì‹¤ì‹œ'\n",
    "        else:\n",
    "            return 'ì´ì‹_ì™„ë£Œ'\n",
    "    \n",
    "    df['ë°°ì•„_ì§„í–‰_ë‹¨ê³„'] = df.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    # 5. ì´ì‹œìˆ _bin3\n",
    "    def collapse_trials(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        if x == \"0íšŒ\": return \"0íšŒ\"\n",
    "        if x in [\"1íšŒ\", \"2íšŒ\"]: return \"1-2íšŒ\"\n",
    "        return \"3íšŒ ì´ìƒ\"\n",
    "    \n",
    "    df[\"ì´ì‹œìˆ _bin3\"] = df[\"ì´ ì‹œìˆ  íšŸìˆ˜\"].apply(collapse_trials)\n",
    "    \n",
    "    # 6. ë‚˜ì´_3êµ¬ê°„\n",
    "    def age_group_simple(age):\n",
    "        if pd.isna(age) or age == \"ì•Œ ìˆ˜ ì—†ìŒ\": return \"Unknown\"\n",
    "        if age == \"ë§Œ18-34ì„¸\": return \"34ì„¸ ì´í•˜\"\n",
    "        if age in [\"ë§Œ35-37ì„¸\", \"ë§Œ38-39ì„¸\"]: return \"35-39ì„¸\"\n",
    "        return \"40ì„¸ ì´ìƒ\"\n",
    "    \n",
    "    df[\"ë‚˜ì´_3êµ¬ê°„\"] = df[\"ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´\"].apply(age_group_simple)\n",
    "    \n",
    "    # 7. ì´ì‹ë°°ì•„_êµ¬ê°„\n",
    "    def embryo_count_bin(count):\n",
    "        count = pd.to_numeric(count, errors='coerce')\n",
    "        if pd.isna(count) or count == 0: return \"0ê°œ\"\n",
    "        elif count <= 2: return \"1-2ê°œ\"\n",
    "        else: return \"3ê°œ ì´ìƒ\"\n",
    "    \n",
    "    df['ì´ì‹ë°°ì•„_êµ¬ê°„'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].apply(embryo_count_bin)\n",
    "    \n",
    "    # 8. Day5_ì´ì‹_ì—¬ë¶€\n",
    "    d = pd.to_numeric(df[\"ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼\"], errors=\"coerce\")\n",
    "    df[\"Day5_ì´ì‹_ì—¬ë¶€\"] = (d == 5).astype(int)\n",
    "    \n",
    "    # 9. ë¶ˆì„ì›ì¸_ë³µì¡ë„\n",
    "    tmp = df[INFERTILITY_COLS].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    df[\"ë¶ˆì„_ì›ì¸_ê°œìˆ˜\"] = tmp.sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df['ë¶ˆì„ì›ì¸_ë³µì¡ë„'] = df['ë¶ˆì„_ì›ì¸_ê°œìˆ˜'].apply(infertility_complexity)\n",
    "    \n",
    "    # 10. ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€\n",
    "    df['ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€'] = df['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].notna().astype(int)\n",
    "    \n",
    "    # ìˆ«ìí˜• ì•ˆì „ ë³€í™˜\n",
    "    num_cols = [\n",
    "        \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\", \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\", \"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼\", \"ë‚œì ì±„ì·¨ ê²½ê³¼ì¼\", \"ë‚œì í˜¼í•© ê²½ê³¼ì¼\"\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    \n",
    "    # 11-13. ë¹„ìœ¨ ë³€ìˆ˜\n",
    "    df[\"ë°°ì•„_ìƒì„±_íš¨ìœ¨\"] = safe_div(\n",
    "        df[\"ì´ ìƒì„± ë°°ì•„ ìˆ˜\"].fillna(0),\n",
    "        df[\"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\"].fillna(0)\n",
    "    )\n",
    "    \n",
    "    df[\"ë°°ì•„_ì´ì‹_ë¹„ìœ¨\"] = safe_div(\n",
    "        df[\"ì´ì‹ëœ ë°°ì•„ ìˆ˜\"].fillna(0),\n",
    "        df[\"ì´ ìƒì„± ë°°ì•„ ìˆ˜\"].fillna(0)\n",
    "    )\n",
    "    \n",
    "    df[\"ë°°ì•„_ì €ì¥_ë¹„ìœ¨\"] = safe_div(\n",
    "        df[\"ì €ì¥ëœ ë°°ì•„ ìˆ˜\"].fillna(0),\n",
    "        df[\"ì´ ìƒì„± ë°°ì•„ ìˆ˜\"].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 14-15. êµí˜¸ì‘ìš©\n",
    "    df['ë‚˜ì´Ã—Day5'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].astype(str) + '_' + df['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    df['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´'] = df['ì´ì‹œìˆ _bin3'].astype(str) + '_' + df['ë‚˜ì´_3êµ¬ê°„'].astype(str)\n",
    "    \n",
    "    # === ğŸ†• ì¶”ê°€ Feature 20ê°œ ===\n",
    "    \n",
    "    # 1. í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤\n",
    "    storage_keywords = ['ë‚œì ì €ì¥ìš©', 'ê¸°ì¦ìš©', 'ë°°ì•„ ì €ì¥ìš©', 'ì—°êµ¬ìš©']\n",
    "    df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] = 0\n",
    "    if 'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ' in df.columns:\n",
    "        df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] = df['ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ '].isin(storage_keywords).astype(int)\n",
    "    if 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´' in df.columns:\n",
    "        df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] = df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] | (df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'] == 'ì•Œ ìˆ˜ ì—†ìŒ').astype(int)\n",
    "    \n",
    "    # 2. ìµœì _ì´ì‹_ì¡°ê±´\n",
    "    df['ìµœì _ì´ì‹_ì¡°ê±´'] = (\n",
    "        (df['Day5_ì´ì‹_ì—¬ë¶€'] == 1) &\n",
    "        (df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].fillna(0).between(1, 2))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 3. ê³ ìœ„í—˜_ì¼€ì´ìŠ¤\n",
    "    age_map = {'ë§Œ40-42ì„¸': 1, 'ë§Œ43-44ì„¸': 1, 'ë§Œ45-50ì„¸': 1}\n",
    "    df['ê³ ë ¹_ì—¬ë¶€'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].map(age_map).fillna(0).astype(int)\n",
    "    \n",
    "    df['ê³ ìœ„í—˜_ì¼€ì´ìŠ¤'] = (\n",
    "        (df['ê³ ë ¹_ì—¬ë¶€'] == 1) &\n",
    "        (df['ì´ì‹œìˆ _bin3'] == '3íšŒ ì´ìƒ') &\n",
    "        (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'].fillna(0) < 3)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 4. ë°°ì•„_í’ˆì§ˆ_ì ìˆ˜\n",
    "    df['ë°°ì•„_í’ˆì§ˆ_ì ìˆ˜'] = (\n",
    "        (df['Day5_ì´ì‹_ì—¬ë¶€'] * 3) +\n",
    "        ((df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].fillna(0).between(1, 2)).astype(int) * 2) +\n",
    "        ((df['ë°°ì•„_ìƒì„±_íš¨ìœ¨'].fillna(0) > 0.5).astype(int))\n",
    "    )\n",
    "    \n",
    "    # 5. ë‚œì_í’ˆì§ˆ_ì ìˆ˜\n",
    "    df['ë‚œì_í’ˆì§ˆ_ì ìˆ˜'] = (\n",
    "        ((df['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'].fillna(0) >= 10).astype(int) * 2) +\n",
    "        ((df['ë°°ì•„_ìƒì„±_íš¨ìœ¨'].fillna(0) > 0.6).astype(int))\n",
    "    )\n",
    "    \n",
    "    # 6. ì‹œìˆ _í’ˆì§ˆ_ì ìˆ˜\n",
    "    df['ì‹œìˆ _í’ˆì§ˆ_ì ìˆ˜'] = (\n",
    "        df['BLASTOCYST_í¬í•¨'] * 2 +\n",
    "        df['ICSI_í¬í•¨'] * 1\n",
    "    )\n",
    "    \n",
    "    # 7. ì¢…í•©_ì„ì‹ _ê°€ëŠ¥_ì ìˆ˜\n",
    "    df['ì¢…í•©_ì„ì‹ _ê°€ëŠ¥_ì ìˆ˜'] = (\n",
    "        df['ë°°ì•„_í’ˆì§ˆ_ì ìˆ˜'] +\n",
    "        df['ë‚œì_í’ˆì§ˆ_ì ìˆ˜'] +\n",
    "        df['ì‹œìˆ _í’ˆì§ˆ_ì ìˆ˜'] -\n",
    "        (df['ê³ ë ¹_ì—¬ë¶€'] * 2) -\n",
    "        (df['ê³ ìœ„í—˜_ì¼€ì´ìŠ¤'] * 3)\n",
    "    )\n",
    "    \n",
    "    # 8-11. ê³¼ê±° ì„±ê³µë¥ \n",
    "    trials_map = {'0íšŒ': 0, '1íšŒ': 1, '2íšŒ': 2, '3íšŒ': 3, '4íšŒ': 4, '5íšŒ': 5, '6íšŒ ì´ìƒ': 7}\n",
    "    \n",
    "    ivf_trials = df['IVF ì‹œìˆ  íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    ivf_preg = df['IVF ì„ì‹  íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    df['IVF_ê³¼ê±°_ì„±ê³µë¥ '] = safe_div(ivf_preg, ivf_trials)\n",
    "    \n",
    "    di_trials = df['DI ì‹œìˆ  íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    di_preg = df['DI ì„ì‹  íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    df['DI_ê³¼ê±°_ì„±ê³µë¥ '] = safe_div(di_preg, di_trials)\n",
    "    \n",
    "    total_trials = df['ì´ ì‹œìˆ  íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    total_preg = df['ì´ ì„ì‹  íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    df['ì „ì²´_ì„ì‹ _ì„±ê³µë¥ '] = safe_div(total_preg, total_trials)\n",
    "    \n",
    "    total_birth = df['ì´ ì¶œì‚° íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    df['ì „ì²´_ì¶œì‚°_ì„±ê³µë¥ '] = safe_div(total_birth, total_preg)\n",
    "    \n",
    "    # 12-14. ê²½ê³¼ì¼ ê°„ê²©\n",
    "    df['ì±„ì·¨_í˜¼í•©_ê°„ê²©'] = df['ë‚œì í˜¼í•© ê²½ê³¼ì¼'].fillna(0) - df['ë‚œì ì±„ì·¨ ê²½ê³¼ì¼'].fillna(0)\n",
    "    df['í˜¼í•©_ì´ì‹_ê°„ê²©'] = df['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'].fillna(0) - df['ë‚œì í˜¼í•© ê²½ê³¼ì¼'].fillna(0)\n",
    "    df['ì±„ì·¨_ì´ì‹_ì´ê°„ê²©'] = df['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'].fillna(0) - df['ë‚œì ì±„ì·¨ ê²½ê³¼ì¼'].fillna(0)\n",
    "    \n",
    "    # 15. ë°°ì•„_í™œìš©ë¥ \n",
    "    df['ë°°ì•„_í™œìš©ë¥ '] = safe_div(\n",
    "        (df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].fillna(0) + df['ì €ì¥ëœ ë°°ì•„ ìˆ˜'].fillna(0)),\n",
    "        df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 16. ë°°ì•„_ì„ ë³„ë¥ \n",
    "    df['ë°°ì•„_ì„ ë³„ë¥ '] = safe_div(\n",
    "        (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'].fillna(0) - df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].fillna(0)),\n",
    "        df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 17. ë¯¸ì„¸ì£¼ì…_ì„±ê³µë¥ \n",
    "    df['ë¯¸ì„¸ì£¼ì…_ì„±ê³µë¥ '] = safe_div(\n",
    "        df['ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜'].fillna(0),\n",
    "        df['ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 18-20. 3-way êµí˜¸ì‘ìš©\n",
    "    df['ë‚˜ì´Ã—ë°°ì•„ìˆ˜Ã—Day5'] = (\n",
    "        df['ë‚˜ì´_3êµ¬ê°„'].astype(str) + '_' +\n",
    "        df['ì´ì‹ë°°ì•„_êµ¬ê°„'].astype(str) + '_' +\n",
    "        df['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    )\n",
    "    \n",
    "    df['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´Ã—ë¶ˆì„'] = (\n",
    "        df['ì´ì‹œìˆ _bin3'].astype(str) + '_' +\n",
    "        df['ë‚˜ì´_3êµ¬ê°„'].astype(str) + '_' +\n",
    "        df['ë¶ˆì„ì›ì¸_ë³µì¡ë„'].astype(str)\n",
    "    )\n",
    "    \n",
    "    df['ê³ ë ¹Ã—ICSIÃ—ë‹¤ë°°ì•„'] = (\n",
    "        df['ê³ ë ¹_ì—¬ë¶€'].astype(str) + '_' +\n",
    "        df['ICSI_í¬í•¨'].astype(str) + '_' +\n",
    "        (df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].fillna(0) >= 3).astype(int).astype(str)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"\\nì „ì²˜ë¦¬ ì¤‘...\")\n",
    "train_df = preprocess(train)\n",
    "test_df = preprocess(test)\n",
    "\n",
    "print(f\"âœ… Train shape: {train_df.shape}\")\n",
    "print(f\"âœ… Test shape: {test_df.shape}\")\n",
    "\n",
    "# ID ì œê±°\n",
    "train_data = train_df.drop(columns=[ID_COL, 'ë°°ì•„_stage_missing_count'])\n",
    "test_data = test_df.drop(columns=[ID_COL, 'ë°°ì•„_stage_missing_count'])\n",
    "\n",
    "print(f\"\\nìµœì¢… Feature ê°œìˆ˜: {len(train_data.columns) - 1}ê°œ\")\n",
    "\n",
    "# ============================================================\n",
    "# 2) AutoGluon í•™ìŠµ (ì£¼ë§ ìŠ¤í˜ì…œ - ì¥ì‹œê°„)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AutoGluon Training - Weekend Special\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 5~8ì‹œê°„\")\n",
    "print(\"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 8-16GB ì˜ˆìƒ\")\n",
    "print(\"\\ní•™ìŠµ ì‹œì‘...\\n\")\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=TARGET_COL,\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='../outputs/autogluon_weekend_special'\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=28800,        # 8ì‹œê°„ (ì£¼ë§ì´ë‹ˆê¹Œ!)\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=10,        # 5â†’10 (ë” ì•ˆì •ì )\n",
    "    num_bag_sets=2,          # 1â†’2 (ë” ë‹¤ì–‘)\n",
    "    num_stack_levels=2,      # 1â†’2 (ë” ê¹Šì€ ìŠ¤íƒœí‚¹)\n",
    "    hyperparameters='multimodal',  # ë” ë‹¤ì–‘í•œ ëª¨ë¸\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3) ê²°ê³¼ í™•ì¸\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AutoGluon Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "leaderboard = predictor.leaderboard(train_data, silent=True)\n",
    "print(\"\\n=== Model Leaderboard (Top 20) ===\")\n",
    "print(leaderboard.head(20).to_string())\n",
    "\n",
    "best_model = leaderboard.iloc[0]['model']\n",
    "best_score = leaderboard.iloc[0]['score_val']\n",
    "print(f\"\\nğŸ† Best Model: {best_model}\")\n",
    "print(f\"ğŸ¯ Best CV AUC: {best_score:.6f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Previous Best (03ë²ˆ): 0.7407\")\n",
    "print(f\"ğŸš€ Improvement: +{best_score - 0.7407:.6f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4) ì˜ˆì¸¡ ë° Submission\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Generating Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_predictions = predictor.predict_proba(test_data)\n",
    "\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    test_proba = test_predictions[1].values\n",
    "else:\n",
    "    test_proba = test_predictions\n",
    "\n",
    "# ğŸ†• Post-processing: í™•ì • ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ê°•ì œ 0\n",
    "mask = test_df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] == 1\n",
    "if mask.sum() > 0:\n",
    "    print(f\"\\nâš ï¸  í™•ì • ì‹¤íŒ¨ ì¼€ì´ìŠ¤ {mask.sum()}ê°œ â†’ ê°•ì œë¡œ 0.0 ì„¤ì •\")\n",
    "    test_proba[mask] = 0.0\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ê°’ í†µê³„:\")\n",
    "print(f\"Min:  {test_proba.min():.6f}\")\n",
    "print(f\"Max:  {test_proba.max():.6f}\")\n",
    "print(f\"Mean: {test_proba.mean():.6f}\")\n",
    "print(f\"Std:  {test_proba.std():.6f}\")\n",
    "\n",
    "# Submission\n",
    "sub['probability'] = test_proba\n",
    "sub.to_csv(\"../outputs/07_submission_autogluon_weekend(0206).csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Submission saved!\")\n",
    "print(f\"   File: ../outputs/07_submission_autogluon_weekend(0206).csv\")\n",
    "\n",
    "# ìƒì„¸ ì •ë³´ ì €ì¥\n",
    "leaderboard.to_csv(\"../outputs/07_autogluon_weekend_leaderboard.csv\", index=False)\n",
    "print(\"âœ… Leaderboard saved: ../07_outputs/autogluon_weekend_leaderboard.csv\")\n",
    "\n",
    "try:\n",
    "    importance = predictor.feature_importance(train_data)\n",
    "    importance.to_csv(\"../outputs/07_autogluon_weekend_feature_importance.csv\")\n",
    "    print(\"âœ… Feature importance saved\")\n",
    "    print(\"\\n=== Top 30 Features ===\")\n",
    "    print(importance.head(30).to_string())\n",
    "except:\n",
    "    print(\"Feature importance not available\")\n",
    "\n",
    "# ìš”ì•½\n",
    "summary = f\"\"\"\n",
    "=== AutoGluon Weekend Special Summary ===\n",
    "\n",
    "Total Features: {len(train_data.columns) - 1}\n",
    "  - ì›ë³¸: 64ê°œ (ê³ ê²°ì¸¡ 5ê°œ ì œê±°)\n",
    "  - íŒŒìƒ: {len(train_data.columns) - 1 - 64}ê°œ\n",
    "\n",
    "Best Model: {best_model}\n",
    "CV AUC: {best_score:.6f}\n",
    "\n",
    "Training Time: 8ì‹œê°„\n",
    "Models Trained: {len(leaderboard)}\n",
    "\n",
    "Top 5 Models:\n",
    "\"\"\"\n",
    "\n",
    "for i in range(min(5, len(leaderboard))):\n",
    "    summary += f\"  {i+1}. {leaderboard.iloc[i]['model']}: {leaderboard.iloc[i]['score_val']:.6f}\\n\"\n",
    "\n",
    "summary += f\"\\nImprovement from 03ë²ˆ: +{best_score - 0.7407:.6f}\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(summary)\n",
    "print(\"=\"*80)\n",
    "\n",
    "with open(\"../outputs/07_autogluon_weekend_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\nâœ… Summary saved: ../outputs/07_autogluon_weekend_summary.txt\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WEEKEND SPECIAL COMPLETE! ğŸ‰\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fertility_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
