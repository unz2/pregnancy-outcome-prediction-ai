{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a287f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì „ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../outputs/autogluon_08_final_strike\"\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=10, num_bag_sets=2\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 14400 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: ../outputs/autogluon_08_final_strike/ds_sub_fit/sub_fit_ho.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (256351, 86)\n",
      "âœ… Test shape: (90067, 85)\n",
      "\n",
      "ğŸ¯ ìµœì¢… Feature ê°œìˆ˜: 83ê°œ\n",
      "   - 03ë²ˆ ê²€ì¦: 15ê°œ\n",
      "   - 07ë²ˆ ì¶”ê°€: 5ê°œ\n",
      "   - ì´: 20ê°œ (ìµœì í™”!)\n",
      "\n",
      "================================================================================\n",
      "ğŸ† AutoGluon Training - 1ë“± íƒˆí™˜ ëª¨ë“œ! ğŸ†\n",
      "================================================================================\n",
      "\n",
      "â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 4ì‹œê°„\n",
      "ğŸ¯ ëª©í‘œ CV AUC: 0.7425+\n",
      "ğŸ† ëª©í‘œ LB: 0.7430+ (í˜„ì¬ 1ë“±: 0.74209)\n",
      "\n",
      "í•™ìŠµ ì‹œì‘...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 17:20:03,442\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 3621 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 10779 seconds.\n",
      "Starting full fit now with num_stack_levels 2.\n",
      "Beginning AutoGluon training ... Time limit = 10779s\n",
      "AutoGluon will save models to \"../outputs/autogluon_08_final_strike\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       7.19 GB / 16.00 GB (44.9%)\n",
      "Disk Space Avail:   207.29 GB / 460.43 GB (45.0%)\n",
      "===================================================\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 83\n",
      "Label Column:       ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7460.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 814.60 MB (10.9% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 10.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 24 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 29 | ['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])    : 18 | ['ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t\t('object', []) : 30 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ì‹œìˆ  ìœ í˜•', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 29 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', 'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ', ...]\n",
      "\t\t('float', [])     : 28 | ['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])       :  1 | ['ë¶ˆì„_ì›ì¸_ê°œìˆ˜']\n",
      "\t\t('int', ['bool']) : 19 | ['ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t2.7s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 68.47 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'AG_AUTOMM': {},\n",
      "\t'VW': {},\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 8 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4788.11s of the 10775.93s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.81%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t10.67s\t = Training   runtime\n",
      "\t3.36s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4775.12s of the 10762.95s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.61%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t10.49s\t = Training   runtime\n",
      "\t3.97s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4762.27s of the 10750.1s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.49%)\n",
      "\t0.7403\t = Validation score   (roc_auc)\n",
      "\t3811.03s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 949.35s of the 6937.18s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.08% memory usage per fold, 44.31%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.08%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t401.12s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 545.84s of the 6533.67s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.26%)\n",
      "\t0.7372\t = Validation score   (roc_auc)\n",
      "\t136.92s\t = Training   runtime\n",
      "\t2.9s\t = Validation runtime\n",
      "Fitting model: VowpalWabbit_BAG_L1 ... Training model for up to 406.3s of the 6394.13s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.06%)\n",
      "\tWarning: Exception caused VowpalWabbit_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=37444, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=37444, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 403.73s of the 6391.56s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.55%)\n",
      "2026-02-07 19:33:37,629\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=37440, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=37440, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "2026-02-07 19:33:37,651\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 19:33:37,659\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 19:33:37,692\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 19:33:37,713\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 19:33:37,734\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 19:33:37,743\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 19:33:37,745\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 19:33:37,747\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=37441, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=37441, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t12.99s\t = Training   runtime\n",
      "\t5.74s\t = Validation runtime\n",
      "Fitting model: MultiModalPredictor_BAG_L1 ... Training model for up to 388.31s of the 6376.14s of remaining time.\n",
      "\tWarning: Exception caused MultiModalPredictor_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe total system num_gpus=0 is less than minimum num_gpus=1 to fit StackerEnsembleModel. Consider using a machine with more GPUs.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 847, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 528, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 759, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 704, in _calculate_total_resources\n",
      "    system_num_gpus >= minimum_model_num_gpus\n",
      "AssertionError: The total system num_gpus=0 is less than minimum num_gpus=1 to fit StackerEnsembleModel. Consider using a machine with more GPUs.\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 478.81s of the 6373.79s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.529, 'LightGBMXT_BAG_L1': 0.118, 'XGBoost_BAG_L1': 0.118, 'NeuralNetTorch_BAG_L1': 0.118, 'LightGBM_BAG_L1': 0.059, 'LightGBMLarge_BAG_L1': 0.059}\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t6.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting 6 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 4244.05s of the 6367.66s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.37%)\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t6.83s\t = Training   runtime\n",
      "\t1.67s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4235.23s of the 6358.83s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.86%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t7.32s\t = Training   runtime\n",
      "\t1.92s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4225.75s of the 6349.35s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.10%)\n",
      "\t0.74\t = Validation score   (roc_auc)\n",
      "\t703.28s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 3520.61s of the 5644.21s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.93% memory usage per fold, 79.42%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.93%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t171.38s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3346.66s of the 5470.26s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.93%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t108.47s\t = Training   runtime\n",
      "\t2.19s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 3235.6s of the 5359.2s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.55%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t10.26s\t = Training   runtime\n",
      "\t3.52s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/2\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3222.46s of the 5346.06s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.83%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t13.09s\t = Training   runtime\n",
      "\t3.19s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3214.27s of the 5337.87s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.62%)\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t14.14s\t = Training   runtime\n",
      "\t3.95s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 3205.41s of the 5329.01s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.58%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t1592.84s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 2314.02s of the 4437.62s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.45% memory usage per fold, 41.81%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.45%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t393.42s\t = Training   runtime\n",
      "\t2.73s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 2089.71s of the 4213.31s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.51%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t226.06s\t = Training   runtime\n",
      "\t4.23s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1969.57s of the 4093.17s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.86%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t21.45s\t = Training   runtime\n",
      "\t7.04s\t = Validation runtime\n",
      "Completed 2/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 424.41s of the 4079.21s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.5, 'LightGBM_BAG_L2': 0.2, 'XGBoost_BAG_L2': 0.2, 'NeuralNetTorch_BAG_L2': 0.1}\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t6.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting 6 L3 models ...\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 4073.0s of the 4072.97s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.06%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t6.82s\t = Training   runtime\n",
      "\t1.53s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 4064.25s of the 4064.22s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.08%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t7.47s\t = Training   runtime\n",
      "\t1.88s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 4054.64s of the 4054.61s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.85%)\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t959.29s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 3093.5s of the 3093.47s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.17% memory usage per fold, 48.66%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.17%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t213.32s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 2877.8s of the 2877.77s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.06%)\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t107.66s\t = Training   runtime\n",
      "\t2.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 2767.77s of the 2767.74s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.13%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t10.55s\t = Training   runtime\n",
      "\t3.61s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/2\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 2754.54s of the 2754.51s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.06%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t13.08s\t = Training   runtime\n",
      "\t3.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 2746.31s of the 2746.28s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.51%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t13.96s\t = Training   runtime\n",
      "\t3.71s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 2737.77s of the 2737.74s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.33%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t2026.23s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 1668.97s of the 1668.93s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.42% memory usage per fold, 41.68%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.42%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t435.35s\t = Training   runtime\n",
      "\t2.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 1444.68s of the 1444.65s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.43%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t229.06s\t = Training   runtime\n",
      "\t4.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 1321.03s of the 1320.99s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.59%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t20.5s\t = Training   runtime\n",
      "\t6.97s\t = Validation runtime\n",
      "Completed 2/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 407.3s of the 1308.2s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.542, 'LightGBMXT_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.125, 'NeuralNetTorch_BAG_L1': 0.125, 'CatBoost_BAG_L2': 0.042}\n",
      "\t0.7406\t = Validation score   (roc_auc)\n",
      "\t14.14s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9485.02s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../outputs/autogluon_08_final_strike\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š AutoGluon Results\n",
      "================================================================================\n",
      "\n",
      "=== Model Leaderboard (Top 20) ===\n",
      "                    model  score_test  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    LightGBMLarge_BAG_L1    0.774141   0.738185     roc_auc        7.245909       5.740938    12.988045                 7.245909                5.740938          12.988045            1       True          6\n",
      "1    LightGBMLarge_BAG_L2    0.760447   0.739224     roc_auc       60.654647      25.169178  4404.662633                 9.467964                7.036826          21.447542            2       True         13\n",
      "2    LightGBMLarge_BAG_L3    0.760427   0.739197     roc_auc      142.934995      46.904182  6664.697865                 9.285333                6.968925          20.498347            3       True         20\n",
      "3       LightGBMXT_BAG_L3    0.757112   0.739111     roc_auc      139.452085      43.644873  6658.161908                 5.802423                3.709615          13.962390            3       True         16\n",
      "4       LightGBMXT_BAG_L2    0.756611   0.739623     roc_auc       57.266391      22.085761  4397.351876                 6.079708                3.953409          14.136785            2       True          9\n",
      "5         LightGBM_BAG_L3    0.755929   0.739425     roc_auc      138.519430      42.998737  6657.282190                 4.869768                3.063480          13.082672            3       True         15\n",
      "6         CatBoost_BAG_L3    0.755584   0.739651     roc_auc      135.796379      40.605204  8670.429789                 2.146717                0.669946        2026.230271            3       True         17\n",
      "7          XGBoost_BAG_L3    0.755529   0.739531     roc_auc      156.579377      42.320542  7079.549477                22.929715                2.385285         435.349959            3       True         18\n",
      "8         CatBoost_BAG_L2    0.755066   0.740091     roc_auc       53.250598      18.794740  5976.051100                 2.063916                0.662388        1592.836010            2       True         10\n",
      "9     WeightedEnsemble_L3    0.754667   0.740183     roc_auc      118.105365      28.984617  6614.774271                 0.003375                0.039595           6.159080            3       True         14\n",
      "10        LightGBM_BAG_L1    0.754665   0.739160     roc_auc        4.926647       3.355309    10.666659                 4.926647                3.355309          10.666659            1       True          1\n",
      "11        LightGBM_BAG_L2    0.754369   0.739849     roc_auc       56.286350      21.319998  4396.301599                 5.099668                3.187646          13.086508            2       True          8\n",
      "12         XGBoost_BAG_L2    0.753836   0.739830     roc_auc       74.286097      20.864823  4776.634935                23.099414                2.732471         393.419845            2       True         11\n",
      "13  NeuralNetTorch_BAG_L2    0.753560   0.739165     roc_auc       87.838993      22.362518  4609.272828                36.652310                4.230165         226.057737            2       True         12\n",
      "14         XGBoost_BAG_L1    0.753283   0.739084     roc_auc       12.099421       1.538189   401.118524                12.099421                1.538189         401.118524            1       True          4\n",
      "15  NeuralNetTorch_BAG_L3    0.753039   0.739106     roc_auc      170.403051      44.026497  6873.260578                36.753389                4.091239         229.061061            3       True         19\n",
      "16    WeightedEnsemble_L2    0.752258   0.740587     roc_auc       51.191881      18.171217  4389.278594                 0.005198                0.038865           6.063503            2       True          7\n",
      "17      LightGBMXT_BAG_L1    0.751872   0.739522     roc_auc        5.356709       3.968127    10.491406                 5.356709                3.968127          10.491406            1       True          2\n",
      "18    WeightedEnsemble_L4    0.750732   0.740568     roc_auc       53.254866      18.834504  5990.190726                 0.004268                0.039764          14.139625            4       True         21\n",
      "19        CatBoost_BAG_L1    0.749545   0.740280     roc_auc        3.057241       0.627994  3811.030520                 3.057241                0.627994        3811.030520            1       True          3\n",
      "\n",
      "ğŸ† Best Model: LightGBMLarge_BAG_L1\n",
      "ğŸ¯ Best CV AUC: 0.738185\n",
      "\n",
      "ğŸ“Š ì„±ì í‘œ:\n",
      "   03ë²ˆ (ê¸°ë³¸):     0.7407\n",
      "   07ë²ˆ (35ê°œ):     0.7386\n",
      "   08ë²ˆ (20ê°œ):     0.738185\n",
      "   Improvement:    +-0.002515\n",
      "\n",
      "ğŸ¤” 03ë²ˆë³´ë‹¤ ë†’ìœ¼ë©´ ì œì¶œ ê³ ë ¤\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ Generating Predictions\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  í™•ì • ì‹¤íŒ¨ ì¼€ì´ìŠ¤ 4205ê°œ â†’ ê°•ì œë¡œ 0.0 ì„¤ì •\n",
      "\n",
      "ì˜ˆì¸¡ê°’ í†µê³„:\n",
      "Min:  0.000000\n",
      "Max:  0.755408\n",
      "Mean: 0.258951\n",
      "Std:  0.159878\n",
      "\n",
      "âœ… Submission saved!\n",
      "   File: ../outputs/08_submission_final_strike_CV0.738185.csv\n",
      "âœ… Leaderboard saved: ../outputs/08_leaderboard.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 77 features using 5000 rows with 5 shuffle sets...\n",
      "\t599.62s\t= Expected runtime (119.92s per shuffle set)\n",
      "\t390.53s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature importance saved\n",
      "\n",
      "=== Top 20 Features ===\n",
      "               importance    stddev   p_value  n  p99_high   p99_low\n",
      "ì´ì‹ëœ ë°°ì•„ ìˆ˜         0.020642  0.004170  0.000189  5  0.029228  0.012056\n",
      "ì´ì‹ë°°ì•„_êµ¬ê°„          0.014499  0.003663  0.000450  5  0.022041  0.006957\n",
      "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´         0.010428  0.003617  0.001490  5  0.017876  0.002980\n",
      "ì €ì¥ëœ ë°°ì•„ ìˆ˜         0.005230  0.003422  0.013420  5  0.012276 -0.001816\n",
      "ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼        0.004973  0.001811  0.001783  5  0.008701  0.001245\n",
      "ë‚˜ì´Ã—ë°°ì•„ìˆ˜Ã—Day5      0.004520  0.002539  0.008201  5  0.009749 -0.000709\n",
      "ì‹œìˆ  ì‹œê¸° ì½”ë“œ         0.003609  0.000621  0.000101  5  0.004887  0.002330\n",
      "ë‚˜ì´_3êµ¬ê°„           0.003155  0.002089  0.013936  5  0.007456 -0.001147\n",
      "ë°°ì•„_ì§„í–‰_ë‹¨ê³„         0.003114  0.001639  0.006584  5  0.006487 -0.000260\n",
      "ë°°ì•„_ìƒì„±_íš¨ìœ¨         0.002937  0.000625  0.000232  5  0.004224  0.001650\n",
      "ë‚˜ì´Ã—Day5          0.002922  0.001354  0.004244  5  0.005709  0.000134\n",
      "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜      0.002558  0.000840  0.001215  5  0.004287  0.000828\n",
      "ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´Ã—ë¶ˆì„       0.002544  0.000197  0.000004  5  0.002949  0.002138\n",
      "ë‚œì ì¶œì²˜            0.002492  0.000769  0.000963  5  0.004075  0.000908\n",
      "ë°°ì•„_ì €ì¥_ë¹„ìœ¨         0.002161  0.001533  0.017229  5  0.005319 -0.000996\n",
      "ì´ ìƒì„± ë°°ì•„ ìˆ˜        0.001877  0.001945  0.048565  5  0.005882 -0.002128\n",
      "IVF_ê³¼ê±°_ì„±ê³µë¥        0.001629  0.001163  0.017560  5  0.004025 -0.000766\n",
      "ë‚œì ê¸°ì¦ì ë‚˜ì´        0.001589  0.000810  0.005892  5  0.003256 -0.000078\n",
      "ë°°ë€ ìœ ë„ ìœ í˜•         0.001532  0.000513  0.001309  5  0.002589  0.000475\n",
      "í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜    0.001482  0.000769  0.006286  5  0.003066 -0.000102\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ† 08ë²ˆ - 1ë“± íƒˆí™˜ ì‘ì „ ê²°ê³¼ ğŸ†\n",
      "================================================================================\n",
      "\n",
      "Feature ì „ëµ: ê²€ì¦ëœ 20ê°œë§Œ!\n",
      "  - 03ë²ˆ ê²€ì¦ Feature: 15ê°œ\n",
      "  - 07ë²ˆ íš¨ê³¼ í™•ì¸: 5ê°œ\n",
      "  - ì´ Feature: 83ê°œ\n",
      "\n",
      "Best Model: LightGBMLarge_BAG_L1\n",
      "CV AUC: 0.738185\n",
      "\n",
      "ì„±ì  ë¹„êµ:\n",
      "  03ë²ˆ (ê¸°ë³¸):     0.7407 (LB: 0.742)\n",
      "  07ë²ˆ (35ê°œ):     0.7386\n",
      "  08ë²ˆ (20ê°œ):     0.738185\n",
      "\n",
      "Improvement from 03ë²ˆ: +-0.002515\n",
      "\n",
      "================================================================================\n",
      "í˜„ì¬ ìˆœìœ„:\n",
      "  1ë“±: 0.74209\n",
      "  ë‚˜:  0.74200 (5ë“±)\n",
      "\n",
      "08ë²ˆ ì˜ˆìƒ LB: 0.739485\n",
      "(03ë²ˆì€ CV 0.7407 â†’ LB 0.742ë¡œ +0.0013 ìƒìŠ¹)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤” 03ë²ˆ ìœ ì§€ ê²€í† ...\n",
      "================================================================================\n",
      "\n",
      "âœ… Summary saved: ../outputs/08_summary.txt\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¥ 08ë²ˆ COMPLETE! ğŸ”¥\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# 0) Load\n",
    "# ============================================================\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "TEST_PATH  = \"../data/test.csv\"\n",
    "SUB_PATH   = \"../data/sample_submission.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "sub   = pd.read_csv(SUB_PATH)\n",
    "\n",
    "TARGET_COL = \"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"\n",
    "ID_COL = \"ID\"\n",
    "\n",
    "# ============================================================\n",
    "# 1) Feature Engineering (ê²€ì¦ëœ 20ê°œë§Œ!)\n",
    "# ============================================================\n",
    "\n",
    "# ê³ ê²°ì¸¡ ë³€ìˆ˜ ì œê±°\n",
    "HIGH_MISSING_COLS = [\n",
    "    'ë‚œì í•´ë™ ê²½ê³¼ì¼',           # 99.4%\n",
    "    'PGS ì‹œìˆ  ì—¬ë¶€',             # 99.2%\n",
    "    'PGD ì‹œìˆ  ì—¬ë¶€',             # 99.1%\n",
    "    'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', # 98.9%\n",
    "    'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜',  # 96.3%\n",
    "]\n",
    "\n",
    "EMBRYO_STAGE_COLS = [\n",
    "    \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\",\"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\",\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "    \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\",\"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ ë‚œì ìˆ˜\",\n",
    "    \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "]\n",
    "\n",
    "INFERTILITY_COLS = [\n",
    "    \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\",\"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\",\"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\",\"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\",\"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\",\"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"\n",
    "]\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return np.where(b == 0, 0.0, a / b)\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ê³ ê²°ì¸¡ ì œê±°\n",
    "    df = df.drop(columns=HIGH_MISSING_COLS, errors='ignore')\n",
    "    \n",
    "    # ===== 03ë²ˆ ê²€ì¦ëœ Feature (15ê°œ) =====\n",
    "    \n",
    "    # 1. ì‹œìˆ _ëŒ€ë¶„ë¥˜\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        x = str(x)\n",
    "        if \"IUI\" in x: return \"IUI\"\n",
    "        if \"ICSI\" in x: return \"ICSI\"\n",
    "        if \"IVF\" in x: return \"IVF\"\n",
    "        if \"DI\" in x: return \"DI\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df[\"ì‹œìˆ _ëŒ€ë¶„ë¥˜\"] = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(major_procedure)\n",
    "    \n",
    "    # 2. BLASTOCYST_í¬í•¨\n",
    "    s = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].astype(\"object\").fillna(\"Unknown\").astype(str)\n",
    "    df[\"BLASTOCYST_í¬í•¨\"] = s.str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    \n",
    "    # 3. ë°°ì•„_ì´ì‹_ì—¬ë¶€\n",
    "    df[\"ë°°ì•„_stage_missing_count\"] = df[EMBRYO_STAGE_COLS].isna().sum(axis=1)\n",
    "    df[\"ë°°ì•„_ì´ì‹_ì—¬ë¶€\"] = (df[\"ë°°ì•„_stage_missing_count\"] < len(EMBRYO_STAGE_COLS)).astype(int)\n",
    "    \n",
    "    # 4. ë°°ì•„_ì§„í–‰_ë‹¨ê³„\n",
    "    def embryo_stage(row):\n",
    "        if row['ë°°ì•„_ì´ì‹_ì—¬ë¶€'] == 0:\n",
    "            return 'ë°°ì•„ë‹¨ê³„_ë¯¸ë„ë‹¬'\n",
    "        total = pd.to_numeric(row.get('ì´ ìƒì„± ë°°ì•„ ìˆ˜'), errors='coerce')\n",
    "        implanted = pd.to_numeric(row.get('ì´ì‹ëœ ë°°ì•„ ìˆ˜'), errors='coerce')\n",
    "        if pd.isna(total) or total == 0:\n",
    "            return 'ë°°ì•„ìƒì„±_ì‹¤íŒ¨'\n",
    "        elif pd.isna(implanted) or implanted == 0:\n",
    "            return 'ì´ì‹_ë¯¸ì‹¤ì‹œ'\n",
    "        else:\n",
    "            return 'ì´ì‹_ì™„ë£Œ'\n",
    "    \n",
    "    df['ë°°ì•„_ì§„í–‰_ë‹¨ê³„'] = df.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    # 5. ì´ì‹œìˆ _bin3\n",
    "    def collapse_trials(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        if x == \"0íšŒ\": return \"0íšŒ\"\n",
    "        if x in [\"1íšŒ\", \"2íšŒ\"]: return \"1-2íšŒ\"\n",
    "        return \"3íšŒ ì´ìƒ\"\n",
    "    \n",
    "    df[\"ì´ì‹œìˆ _bin3\"] = df[\"ì´ ì‹œìˆ  íšŸìˆ˜\"].apply(collapse_trials)\n",
    "    \n",
    "    # 6. ë‚˜ì´_3êµ¬ê°„\n",
    "    def age_group_simple(age):\n",
    "        if pd.isna(age) or age == \"ì•Œ ìˆ˜ ì—†ìŒ\": return \"Unknown\"\n",
    "        if age == \"ë§Œ18-34ì„¸\": return \"34ì„¸ ì´í•˜\"\n",
    "        if age in [\"ë§Œ35-37ì„¸\", \"ë§Œ38-39ì„¸\"]: return \"35-39ì„¸\"\n",
    "        return \"40ì„¸ ì´ìƒ\"\n",
    "    \n",
    "    df[\"ë‚˜ì´_3êµ¬ê°„\"] = df[\"ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´\"].apply(age_group_simple)\n",
    "    \n",
    "    # 7. ì´ì‹ë°°ì•„_êµ¬ê°„\n",
    "    def embryo_count_bin(count):\n",
    "        count = pd.to_numeric(count, errors='coerce')\n",
    "        if pd.isna(count) or count == 0: return \"0ê°œ\"\n",
    "        elif count <= 2: return \"1-2ê°œ\"\n",
    "        else: return \"3ê°œ ì´ìƒ\"\n",
    "    \n",
    "    df['ì´ì‹ë°°ì•„_êµ¬ê°„'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].apply(embryo_count_bin)\n",
    "    \n",
    "    # 8. Day5_ì´ì‹_ì—¬ë¶€\n",
    "    d = pd.to_numeric(df[\"ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼\"], errors=\"coerce\")\n",
    "    df[\"Day5_ì´ì‹_ì—¬ë¶€\"] = (d == 5).astype(int)\n",
    "    \n",
    "    # 9. ë¶ˆì„ì›ì¸_ë³µì¡ë„\n",
    "    tmp = df[INFERTILITY_COLS].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    df[\"ë¶ˆì„_ì›ì¸_ê°œìˆ˜\"] = tmp.sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df['ë¶ˆì„ì›ì¸_ë³µì¡ë„'] = df['ë¶ˆì„_ì›ì¸_ê°œìˆ˜'].apply(infertility_complexity)\n",
    "    \n",
    "    # 10. ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€\n",
    "    df['ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€'] = df['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].notna().astype(int)\n",
    "    \n",
    "    # ìˆ«ìí˜• ì•ˆì „ ë³€í™˜\n",
    "    num_cols = [\n",
    "        \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\", \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\", \"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼\", \"ë‚œì ì±„ì·¨ ê²½ê³¼ì¼\", \"ë‚œì í˜¼í•© ê²½ê³¼ì¼\"\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    \n",
    "    # 11-13. ë¹„ìœ¨ ë³€ìˆ˜ (03ë²ˆ ê²€ì¦ë¨)\n",
    "    df[\"ë°°ì•„_ìƒì„±_íš¨ìœ¨\"] = safe_div(\n",
    "        df[\"ì´ ìƒì„± ë°°ì•„ ìˆ˜\"].fillna(0),\n",
    "        df[\"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\"].fillna(0)\n",
    "    )\n",
    "    \n",
    "    df[\"ë°°ì•„_ì´ì‹_ë¹„ìœ¨\"] = safe_div(\n",
    "        df[\"ì´ì‹ëœ ë°°ì•„ ìˆ˜\"].fillna(0),\n",
    "        df[\"ì´ ìƒì„± ë°°ì•„ ìˆ˜\"].fillna(0)\n",
    "    )\n",
    "    \n",
    "    df[\"ë°°ì•„_ì €ì¥_ë¹„ìœ¨\"] = safe_div(\n",
    "        df[\"ì €ì¥ëœ ë°°ì•„ ìˆ˜\"].fillna(0),\n",
    "        df[\"ì´ ìƒì„± ë°°ì•„ ìˆ˜\"].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 14-15. êµí˜¸ì‘ìš© (03ë²ˆ ê²€ì¦ë¨)\n",
    "    df['ë‚˜ì´Ã—Day5'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].astype(str) + '_' + df['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    df['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´'] = df['ì´ì‹œìˆ _bin3'].astype(str) + '_' + df['ë‚˜ì´_3êµ¬ê°„'].astype(str)\n",
    "    \n",
    "    # ===== ğŸ†• 07ë²ˆì—ì„œ íš¨ê³¼ í™•ì¸ëœ Feature (5ê°œë§Œ!) =====\n",
    "    \n",
    "    # 16. ë‚˜ì´Ã—ë°°ì•„ìˆ˜Ã—Day5 (3-way, ì¤‘ìš”ë„ 0.0027)\n",
    "    df['ë‚˜ì´Ã—ë°°ì•„ìˆ˜Ã—Day5'] = (\n",
    "        df['ë‚˜ì´_3êµ¬ê°„'].astype(str) + '_' +\n",
    "        df['ì´ì‹ë°°ì•„_êµ¬ê°„'].astype(str) + '_' +\n",
    "        df['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # 17. ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´Ã—ë¶ˆì„ (3-way, ì¤‘ìš”ë„ 0.0021)\n",
    "    df['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´Ã—ë¶ˆì„'] = (\n",
    "        df['ì´ì‹œìˆ _bin3'].astype(str) + '_' +\n",
    "        df['ë‚˜ì´_3êµ¬ê°„'].astype(str) + '_' +\n",
    "        df['ë¶ˆì„ì›ì¸_ë³µì¡ë„'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # 18. í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤ (Post-processingìš©)\n",
    "    storage_keywords = ['ë‚œì ì €ì¥ìš©', 'ê¸°ì¦ìš©', 'ë°°ì•„ ì €ì¥ìš©', 'ì—°êµ¬ìš©']\n",
    "    df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] = 0\n",
    "    if 'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ' in df.columns:\n",
    "        df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] = df['ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ '].isin(storage_keywords).astype(int)\n",
    "    if 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´' in df.columns:\n",
    "        df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] = df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] | (df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'] == 'ì•Œ ìˆ˜ ì—†ìŒ').astype(int)\n",
    "    \n",
    "    # 19. ë°°ì•„_í™œìš©ë¥  (ì¤‘ìš”ë„ 0.0008)\n",
    "    df['ë°°ì•„_í™œìš©ë¥ '] = safe_div(\n",
    "        (df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].fillna(0) + df['ì €ì¥ëœ ë°°ì•„ ìˆ˜'].fillna(0)),\n",
    "        df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 20. IVF_ê³¼ê±°_ì„±ê³µë¥  (ì¤‘ìš”ë„ 0.0008)\n",
    "    trials_map = {'0íšŒ': 0, '1íšŒ': 1, '2íšŒ': 2, '3íšŒ': 3, '4íšŒ': 4, '5íšŒ': 5, '6íšŒ ì´ìƒ': 7}\n",
    "    ivf_trials = df['IVF ì‹œìˆ  íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    ivf_preg = df['IVF ì„ì‹  íšŸìˆ˜'].map(trials_map).fillna(0)\n",
    "    df['IVF_ê³¼ê±°_ì„±ê³µë¥ '] = safe_div(ivf_preg, ivf_trials)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"\\nì „ì²˜ë¦¬ ì¤‘...\")\n",
    "train_df = preprocess(train)\n",
    "test_df = preprocess(test)\n",
    "\n",
    "print(f\"âœ… Train shape: {train_df.shape}\")\n",
    "print(f\"âœ… Test shape: {test_df.shape}\")\n",
    "\n",
    "# ID ì œê±°\n",
    "train_data = train_df.drop(columns=[ID_COL, 'ë°°ì•„_stage_missing_count'])\n",
    "test_data = test_df.drop(columns=[ID_COL, 'ë°°ì•„_stage_missing_count'])\n",
    "\n",
    "print(f\"\\nğŸ¯ ìµœì¢… Feature ê°œìˆ˜: {len(train_data.columns) - 1}ê°œ\")\n",
    "print(f\"   - 03ë²ˆ ê²€ì¦: 15ê°œ\")\n",
    "print(f\"   - 07ë²ˆ ì¶”ê°€: 5ê°œ\")\n",
    "print(f\"   - ì´: 20ê°œ (ìµœì í™”!)\")\n",
    "\n",
    "# ============================================================\n",
    "# 2) AutoGluon í•™ìŠµ (ìµœì í™” ì„¤ì •)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ† AutoGluon Training - 1ë“± íƒˆí™˜ ëª¨ë“œ! ğŸ†\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 4ì‹œê°„\")\n",
    "print(\"ğŸ¯ ëª©í‘œ CV AUC: 0.7425+\")\n",
    "print(\"ğŸ† ëª©í‘œ LB: 0.7430+ (í˜„ì¬ 1ë“±: 0.74209)\")\n",
    "print(\"\\ní•™ìŠµ ì‹œì‘...\\n\")\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=TARGET_COL,\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='../outputs/autogluon_08_final_strike'\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=14400,        # 4ì‹œê°„\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=10,        # ì•ˆì •ì„±\n",
    "    num_bag_sets=2,          # ë‹¤ì–‘ì„±\n",
    "    num_stack_levels=2,      # ê¹Šì€ ìŠ¤íƒœí‚¹\n",
    "    hyperparameters='multimodal',  # ë‹¤ì–‘í•œ ëª¨ë¸\n",
    "    auto_stack=True,         # ìë™ ìŠ¤íƒœí‚¹ ìµœì í™”\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3) ê²°ê³¼ í™•ì¸\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š AutoGluon Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "leaderboard = predictor.leaderboard(train_data, silent=True)\n",
    "print(\"\\n=== Model Leaderboard (Top 20) ===\")\n",
    "print(leaderboard.head(20).to_string())\n",
    "\n",
    "best_model = leaderboard.iloc[0]['model']\n",
    "best_score = leaderboard.iloc[0]['score_val']\n",
    "\n",
    "print(f\"\\nğŸ† Best Model: {best_model}\")\n",
    "print(f\"ğŸ¯ Best CV AUC: {best_score:.6f}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì„±ì í‘œ:\")\n",
    "print(f\"   03ë²ˆ (ê¸°ë³¸):     0.7407\")\n",
    "print(f\"   07ë²ˆ (35ê°œ):     0.7386\")\n",
    "print(f\"   08ë²ˆ (20ê°œ):     {best_score:.6f}\")\n",
    "print(f\"   Improvement:    +{best_score - 0.7407:.6f}\")\n",
    "\n",
    "if best_score >= 0.7425:\n",
    "    print(\"\\nğŸ‰ğŸ‰ğŸ‰ ëª©í‘œ ë‹¬ì„±! 1ë“± ê°€ëŠ¥ì„± ë†’ìŒ! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "elif best_score >= 0.7415:\n",
    "    print(\"\\nğŸ˜Š ì¢‹ì€ ì„±ì ! ìƒìœ„ê¶Œ í™•ì •!\")\n",
    "else:\n",
    "    print(\"\\nğŸ¤” 03ë²ˆë³´ë‹¤ ë†’ìœ¼ë©´ ì œì¶œ ê³ ë ¤\")\n",
    "\n",
    "# ============================================================\n",
    "# 4) ì˜ˆì¸¡ ë° Submission\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ Generating Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_predictions = predictor.predict_proba(test_data)\n",
    "\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    test_proba = test_predictions[1].values\n",
    "else:\n",
    "    test_proba = test_predictions\n",
    "\n",
    "# ğŸ”¥ Post-processing: í™•ì • ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ê°•ì œ 0\n",
    "mask = test_df['í™•ì •_ì‹¤íŒ¨_ì¼€ì´ìŠ¤'] == 1\n",
    "if mask.sum() > 0:\n",
    "    print(f\"\\nâš ï¸  í™•ì • ì‹¤íŒ¨ ì¼€ì´ìŠ¤ {mask.sum()}ê°œ â†’ ê°•ì œë¡œ 0.0 ì„¤ì •\")\n",
    "    test_proba[mask] = 0.0\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ê°’ í†µê³„:\")\n",
    "print(f\"Min:  {test_proba.min():.6f}\")\n",
    "print(f\"Max:  {test_proba.max():.6f}\")\n",
    "print(f\"Mean: {test_proba.mean():.6f}\")\n",
    "print(f\"Std:  {test_proba.std():.6f}\")\n",
    "\n",
    "# Submission\n",
    "sub['probability'] = test_proba\n",
    "output_file = f\"../outputs/08_submission_final_strike_CV{best_score:.6f}.csv\"\n",
    "sub.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Submission saved!\")\n",
    "print(f\"   File: {output_file}\")\n",
    "\n",
    "# ìƒì„¸ ì •ë³´ ì €ì¥\n",
    "leaderboard.to_csv(\"../outputs/08_leaderboard.csv\", index=False)\n",
    "print(\"âœ… Leaderboard saved: ../outputs/08_leaderboard.csv\")\n",
    "\n",
    "try:\n",
    "    importance = predictor.feature_importance(train_data)\n",
    "    importance.to_csv(\"../outputs/08_feature_importance.csv\")\n",
    "    print(\"âœ… Feature importance saved\")\n",
    "    print(\"\\n=== Top 20 Features ===\")\n",
    "    print(importance.head(20).to_string())\n",
    "except:\n",
    "    print(\"âš ï¸ Feature importance not available\")\n",
    "\n",
    "# ìš”ì•½\n",
    "summary = f\"\"\"\n",
    "{'='*80}\n",
    "ğŸ† 08ë²ˆ - 1ë“± íƒˆí™˜ ì‘ì „ ê²°ê³¼ ğŸ†\n",
    "{'='*80}\n",
    "\n",
    "Feature ì „ëµ: ê²€ì¦ëœ 20ê°œë§Œ!\n",
    "  - 03ë²ˆ ê²€ì¦ Feature: 15ê°œ\n",
    "  - 07ë²ˆ íš¨ê³¼ í™•ì¸: 5ê°œ\n",
    "  - ì´ Feature: {len(train_data.columns) - 1}ê°œ\n",
    "\n",
    "Best Model: {best_model}\n",
    "CV AUC: {best_score:.6f}\n",
    "\n",
    "ì„±ì  ë¹„êµ:\n",
    "  03ë²ˆ (ê¸°ë³¸):     0.7407 (LB: 0.742)\n",
    "  07ë²ˆ (35ê°œ):     0.7386\n",
    "  08ë²ˆ (20ê°œ):     {best_score:.6f}\n",
    "  \n",
    "Improvement from 03ë²ˆ: +{best_score - 0.7407:.6f}\n",
    "\n",
    "{'='*80}\n",
    "í˜„ì¬ ìˆœìœ„:\n",
    "  1ë“±: 0.74209\n",
    "  ë‚˜:  0.74200 (5ë“±)\n",
    "  \n",
    "08ë²ˆ ì˜ˆìƒ LB: {best_score + 0.0013:.6f}\n",
    "(03ë²ˆì€ CV 0.7407 â†’ LB 0.742ë¡œ +0.0013 ìƒìŠ¹)\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "if best_score >= 0.7425:\n",
    "    summary += \"\\nğŸ‰ğŸ‰ğŸ‰ 1ë“± íƒˆí™˜ ê°€ëŠ¥ì„± ë†’ìŒ! ë°”ë¡œ ì œì¶œ! ğŸ‰ğŸ‰ğŸ‰\\n\"\n",
    "elif best_score >= 0.7415:\n",
    "    summary += \"\\nğŸ˜Š ìƒìœ„ê¶Œ í™•ì •! ì œì¶œ ì¶”ì²œ!\\n\"\n",
    "elif best_score > 0.7407:\n",
    "    summary += \"\\nâœ… 03ë²ˆë³´ë‹¤ ë†’ìŒ! ì œì¶œ ê³ ë ¤!\\n\"\n",
    "else:\n",
    "    summary += \"\\nğŸ¤” 03ë²ˆ ìœ ì§€ ê²€í† ...\\n\"\n",
    "\n",
    "summary += \"=\"*80\n",
    "\n",
    "print(\"\\n\" + summary)\n",
    "\n",
    "with open(\"../outputs/08_summary.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\nâœ… Summary saved: ../outputs/08_summary.txt\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ”¥ 08ë²ˆ COMPLETE! ğŸ”¥\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f5372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fertility_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
