{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ce2240",
   "metadata": {},
   "source": [
    "02 íŒŒì¼ê³¼ feature ë™ì¼, autogluon ì‚¬ìš©\n",
    "\n",
    "**AutoGluon TabularPredictor**\n",
    "- `time_limit`: 7200ì´ˆ (2ì‹œê°„)\n",
    "- `presets`: 'best_quality'\n",
    "- `num_bag_folds`: 5-Fold CV\n",
    "- `num_stack_levels`: 1 (Multi-layer Stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a61910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AutoGluon Experiment\n",
      "============================================================\n",
      "\n",
      "Train shape: (256351, 69)\n",
      "Test shape: (90067, 68)\n",
      "\n",
      "ì „ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 7200 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: ../outputs/autogluon_models/ds_sub_fit/sub_fit_ho.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ í›„ Train shape: (256351, 86)\n",
      "ì „ì²˜ë¦¬ í›„ Test shape: (90067, 85)\n",
      "\n",
      "Final Train shape: (256351, 84)\n",
      "Target distribution:\n",
      "ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "0    0.741651\n",
      "1    0.258349\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "Starting AutoGluon Training\n",
      "============================================================\n",
      "\n",
      "â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2ì‹œê°„\n",
      "ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 4-8GB ì˜ˆìƒ\n",
      "\n",
      "í•™ìŠµ ì‹œì‘...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 11:20:02,405\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 1849 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 5351 seconds.\n",
      "Starting full fit now with num_stack_levels 0.\n",
      "Beginning AutoGluon training ... Time limit = 5351s\n",
      "AutoGluon will save models to \"../outputs/autogluon_models\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       4.73 GB / 16.00 GB (29.6%)\n",
      "Disk Space Avail:   227.67 GB / 460.43 GB (49.4%)\n",
      "===================================================\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 83\n",
      "Label Column:       ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5310.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 752.89 MB (14.2% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 14.2% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 26 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 32 | ['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])    : 17 | ['ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t\t('object', []) : 28 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ì‹œìˆ  ìœ í˜•', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 27 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', 'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ', ...]\n",
      "\t\t('float', [])     : 28 | ['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', ...]\n",
      "\t\t('int', [])       :  1 | ['ë¶ˆì„_ì›ì¸_ê°œìˆ˜']\n",
      "\t\t('int', ['bool']) : 21 | ['ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìê·¹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t2.8s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 68.46 MB (1.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5347.78s of the 5347.78s of remaining time.\n",
      "\t0.6413\t = Validation score   (roc_auc)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t27.54s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 5319.6s of the 5319.59s of remaining time.\n",
      "\t0.6262\t = Validation score   (roc_auc)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t27.38s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5291.79s of the 5291.78s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.84%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t6.88s\t = Training   runtime\n",
      "\t2.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 5282.05s of the 5282.04s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.80%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t5.67s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 5274.26s of the 5274.25s of remaining time.\n",
      "\t0.73\t = Validation score   (roc_auc)\n",
      "\t13.53s\t = Training   runtime\n",
      "\t7.91s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 5252.34s of the 5252.33s of remaining time.\n",
      "\t0.7311\t = Validation score   (roc_auc)\n",
      "\t13.98s\t = Training   runtime\n",
      "\t8.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 5229.74s of the 5229.74s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.12%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t1036.01s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 4191.83s of the 4191.83s of remaining time.\n",
      "\t0.7325\t = Validation score   (roc_auc)\n",
      "\t10.95s\t = Training   runtime\n",
      "\t7.94s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4172.14s of the 4172.14s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 295 due to low memory. Expected memory usage reduced from 15.23% -> 15.0% of available memory...\n",
      "\t0.7326\t = Validation score   (roc_auc)\n",
      "\t11.34s\t = Training   runtime\n",
      "\t7.92s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4152.11s of the 4152.1s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.01% memory usage per fold, 68.06%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=17.01%)\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t122.79s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4026.62s of the 4026.61s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.47%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t576.92s\t = Training   runtime\n",
      "\t1.68s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3447.02s of the 3447.02s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.48%)\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t127.64s\t = Training   runtime\n",
      "\t2.35s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3316.67s of the 3316.67s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.83%)\n",
      "\t0.7383\t = Validation score   (roc_auc)\n",
      "\t10.04s\t = Training   runtime\n",
      "\t2.84s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 3303.66s of the 3303.65s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.15%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t158.44s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 3143.21s of the 3143.2s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.28%)\n",
      "\t0.7378\t = Validation score   (roc_auc)\n",
      "\t161.15s\t = Training   runtime\n",
      "\t2.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2979.2s of the 2979.2s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.54%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t20.52s\t = Training   runtime\n",
      "\t7.99s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2955.08s of the 2955.08s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.61%)\n",
      "\t0.7355\t = Validation score   (roc_auc)\n",
      "\t393.83s\t = Training   runtime\n",
      "\t3.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2558.9s of the 2558.9s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.91%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t145.13s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 2411.37s of the 2411.36s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.51%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t41.21s\t = Training   runtime\n",
      "\t10.5s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 2365.91s of the 2365.9s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.91%)\n",
      "\t0.737\t = Validation score   (roc_auc)\n",
      "\t243.38s\t = Training   runtime\n",
      "\t2.79s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 2120.3s of the 2120.29s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.53%)\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t1579.86s\t = Training   runtime\n",
      "\t5.99s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 537.03s of the 537.03s of remaining time.\n",
      "\t0.7223\t = Validation score   (roc_auc)\n",
      "\t59.29s\t = Training   runtime\n",
      "\t8.56s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 468.51s of the 468.51s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.38%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t374.68s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 91.33s of the 91.33s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.39% memory usage per fold, 73.54%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=18.39%)\n",
      "\t0.7365\t = Validation score   (roc_auc)\n",
      "\t73.99s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 14.51s of the 14.51s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.29%)\n",
      "\t0.7306\t = Validation score   (roc_auc)\n",
      "\t11.3s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 534.78s of the 0.82s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.286, 'LightGBMXT_BAG_L1': 0.143, 'NeuralNetTorch_r79_BAG_L1': 0.143, 'RandomForestEntr_BAG_L1': 0.048, 'NeuralNetFastAI_BAG_L1': 0.048, 'XGBoost_BAG_L1': 0.048, 'NeuralNetTorch_BAG_L1': 0.048, 'CatBoost_r177_BAG_L1': 0.048, 'CatBoost_r9_BAG_L1': 0.048, 'LightGBM_r96_BAG_L1': 0.048, 'NeuralNetTorch_r22_BAG_L1': 0.048, 'NeuralNetFastAI_r102_BAG_L1': 0.048}\n",
      "\t0.7407\t = Validation score   (roc_auc)\n",
      "\t26.42s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5376.72s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../outputs/autogluon_models\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "AutoGluon Results\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "Computing feature importance via permutation shuffling for 77 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Leaderboard (Top 15) ===\n",
      "                      model  score_test  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     ExtraTrees_r42_BAG_L1    0.958349   0.722289     roc_auc        2.102997       8.557869    59.288020                 2.102997                8.557869          59.288020            1       True         22\n",
      "1   RandomForestEntr_BAG_L1    0.930159   0.731145     roc_auc        2.477784       8.096630    13.980618                 2.477784                8.096630          13.980618            1       True          6\n",
      "2   RandomForestGini_BAG_L1    0.928349   0.730036     roc_auc        2.458589       7.909825    13.528742                 2.458589                7.909825          13.528742            1       True          5\n",
      "3     ExtraTreesEntr_BAG_L1    0.903508   0.732631     roc_auc        2.593283       7.924929    11.344786                 2.593283                7.924929          11.344786            1       True          9\n",
      "4     ExtraTreesGini_BAG_L1    0.903415   0.732512     roc_auc        2.429996       7.937687    10.945295                 2.429996                7.937687          10.945295            1       True          8\n",
      "5     KNeighborsDist_BAG_L1    0.856610   0.626226     roc_auc       28.504939      27.376671     0.222155                28.504939               27.376671           0.222155            1       True          2\n",
      "6        XGBoost_r33_BAG_L1    0.785411   0.737103     roc_auc       10.508105       5.989705  1579.862987                10.508105                5.989705        1579.862987            1       True         21\n",
      "7      LightGBMLarge_BAG_L1    0.772624   0.738310     roc_auc        3.591562       2.838064    10.037551                 3.591562                2.838064          10.037551            1       True         13\n",
      "8       WeightedEnsemble_L2    0.762040   0.740718     roc_auc       80.843845      33.472807  2733.930788                 0.008223                0.042145          26.416104            2       True         26\n",
      "9      LightGBM_r131_BAG_L1    0.757204   0.739494     roc_auc        9.532425       7.988672    20.518509                 9.532425                7.988672          20.518509            1       True         16\n",
      "10    KNeighborsUnif_BAG_L1    0.757089   0.641296     roc_auc       27.043551      27.538082     0.205819                27.043551               27.538082           0.205819            1       True          1\n",
      "11     CatBoost_r177_BAG_L1    0.753377   0.739703     roc_auc        0.309654       0.159159   158.435280                 0.309654                0.159159         158.435280            1       True         14\n",
      "12           XGBoost_BAG_L1    0.752175   0.738928     roc_auc        6.081774       1.677300   576.922451                 6.081774                1.677300         576.922451            1       True         11\n",
      "13       CatBoost_r9_BAG_L1    0.752098   0.739761     roc_auc        1.207913       0.368347   145.127934                 1.207913                0.368347         145.127934            1       True         18\n",
      "14          LightGBM_BAG_L1    0.751874   0.739370     roc_auc        2.728702       1.651214     5.666959                 2.728702                1.651214           5.666959            1       True          4\n",
      "\n",
      "ğŸ† Best Model: ExtraTrees_r42_BAG_L1\n",
      "ğŸ¯ Best CV AUC: 0.722289\n",
      "\n",
      "============================================================\n",
      "Feature Importance\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t853.67s\t= Expected runtime (170.73s per shuffle set)\n",
      "\t544.7s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 20 Features ===\n",
      "                  importance    stddev       p_value  n  p99_high   p99_low\n",
      "ì´ì‹ëœ ë°°ì•„ ìˆ˜            0.019851  0.004014  1.901256e-04  5  0.028117  0.011586\n",
      "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´            0.011297  0.003085  6.059486e-04  5  0.017649  0.004945\n",
      "ë‚˜ì´_3êµ¬ê°„              0.010647  0.003570  1.313894e-03  5  0.017998  0.003296\n",
      "ë°°ì•„_ì´ì‹_ë¹„ìœ¨            0.009838  0.002147  2.555314e-04  5  0.014258  0.005418\n",
      "ì´ì‹ë°°ì•„_êµ¬ê°„             0.009680  0.003194  1.237507e-03  5  0.016256  0.003103\n",
      "ë‚˜ì´Ã—Day5             0.008002  0.002413  8.827383e-04  5  0.012971  0.003033\n",
      "ë°°ì•„_ì €ì¥_ë¹„ìœ¨            0.007536  0.002599  1.459067e-03  5  0.012888  0.002184\n",
      "ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼           0.007275  0.001796  4.120106e-04  5  0.010974  0.003576\n",
      "ì´ ìƒì„± ë°°ì•„ ìˆ˜           0.006966  0.002667  2.142094e-03  5  0.012457  0.001475\n",
      "ë°°ì•„_ìƒì„±_íš¨ìœ¨            0.006736  0.001112  8.599298e-05  5  0.009026  0.004446\n",
      "ì‹œìˆ  ì‹œê¸° ì½”ë“œ            0.006650  0.000500  3.817704e-06  5  0.007680  0.005620\n",
      "ë°°ì•„_ì§„í–‰_ë‹¨ê³„            0.004722  0.001765  1.961776e-03  5  0.008356  0.001088\n",
      "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜         0.004713  0.000602  3.123764e-05  5  0.005952  0.003474\n",
      "Day5_ì´ì‹_ì—¬ë¶€          0.004192  0.001213  7.552108e-04  5  0.006690  0.001694\n",
      "í˜¼í•©ëœ ë‚œì ìˆ˜            0.004077  0.000189  5.583645e-07  5  0.004467  0.003687\n",
      "íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜    0.003796  0.000092  4.130747e-08  5  0.003985  0.003606\n",
      "ì €ì¥ëœ ë°°ì•„ ìˆ˜            0.003644  0.002004  7.634307e-03  5  0.007770 -0.000482\n",
      "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜          0.003293  0.000436  3.596853e-05  5  0.004190  0.002396\n",
      "í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜       0.003212  0.000892  6.454917e-04  5  0.005048  0.001375\n",
      "ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´             0.003111  0.000940  8.886648e-04  5  0.005046  0.001176\n",
      "\n",
      "============================================================\n",
      "Generating Predictions\n",
      "============================================================\n",
      "\n",
      "ì˜ˆì¸¡ê°’ í†µê³„:\n",
      "Min:  0.000212\n",
      "Max:  0.716650\n",
      "Mean: 0.258268\n",
      "Std:  0.159832\n",
      "\n",
      "âœ… AutoGluon Submission saved!\n",
      "   File: ../outputs/submission_autogluon(0206).csv\n",
      "\n",
      "============================================================\n",
      "Saving Details\n",
      "============================================================\n",
      "âœ… Leaderboard saved: ../outputs/autogluon_leaderboard.csv\n",
      "âœ… Feature importance saved: ../outputs/autogluon_feature_importance.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "Best Model: ExtraTrees_r42_BAG_L1\n",
      "CV AUC: 0.722289\n",
      "\n",
      "Total Models Trained: 26\n",
      "Ensemble Type: WeightedEnsemble_L2\n",
      "\n",
      "Top 3 Models:\n",
      "  1. ExtraTrees_r42_BAG_L1: 0.722289\n",
      "  2. RandomForestEntr_BAG_L1: 0.731145\n",
      "  3. RandomForestGini_BAG_L1: 0.730036\n",
      "\n",
      "\n",
      "âœ… Summary saved: ../outputs/autogluon_summary.txt\n",
      "\n",
      "============================================================\n",
      "AutoGluon Experiment Complete! ğŸ‰\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AutoGluon Experiment\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# 2. ì „ì²˜ë¦¬ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "def preprocess(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # ì‹œìˆ _ëŒ€ë¶„ë¥˜\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x):\n",
    "            return \"Unknown\"\n",
    "        if \"IUI\" in x:\n",
    "            return \"IUI\"\n",
    "        if \"DI\" in x:\n",
    "            return \"Other\"\n",
    "        if \"ICSI\" in x:\n",
    "            return \"ICSI\"\n",
    "        if \"IVF\" in x:\n",
    "            return \"IVF\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df_copy[\"ì‹œìˆ _ëŒ€ë¶„ë¥˜\"] = df_copy[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(major_procedure)\n",
    "    \n",
    "    # BLASTOCYST í¬í•¨ ì—¬ë¶€\n",
    "    df_copy[\"BLASTOCYST_í¬í•¨\"] = df_copy[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    \n",
    "    # ë°°ì•„ ì´ì‹ ì—¬ë¶€\n",
    "    embryo_stage_cols = [\n",
    "        \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\", \"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\", \"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "        \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\", \"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\", \"í•´ë™ëœ ë°°ì•„ ìˆ˜\", \"í•´ë™ ë‚œì ìˆ˜\",\n",
    "        \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\", \"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "    ]\n",
    "    \n",
    "    df_copy[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"] = df_copy[embryo_stage_cols].isna().all(axis=1).astype(int)\n",
    "    df_copy[\"ë°°ì•„_ì´ì‹_ì—¬ë¶€\"] = 1 - df_copy[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"]\n",
    "    \n",
    "    # ë°°ì•„ ì§„í–‰ ë‹¨ê³„\n",
    "    def embryo_stage(row):\n",
    "        if row['ë°°ì•„_ì´ì‹_ì—¬ë¶€'] == 0:\n",
    "            return 'ë°°ì•„ë‹¨ê³„_ë¯¸ë„ë‹¬'\n",
    "        elif pd.isna(row['ì´ ìƒì„± ë°°ì•„ ìˆ˜']) or row['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] == 0:\n",
    "            return 'ë°°ì•„ìƒì„±_ì‹¤íŒ¨'\n",
    "        elif pd.isna(row['ì´ì‹ëœ ë°°ì•„ ìˆ˜']) or row['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] == 0:\n",
    "            return 'ì´ì‹_ë¯¸ì‹¤ì‹œ'\n",
    "        else:\n",
    "            return 'ì´ì‹_ì™„ë£Œ'\n",
    "    \n",
    "    df_copy['ë°°ì•„_ì§„í–‰_ë‹¨ê³„'] = df_copy.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    # ì´ì‹œìˆ _bin3\n",
    "    def collapse_trials(x):\n",
    "        if x == '0íšŒ':\n",
    "            return '0íšŒ'\n",
    "        elif x in ['1íšŒ', '2íšŒ']:\n",
    "            return '1â€“2íšŒ'\n",
    "        else:\n",
    "            return '3íšŒ ì´ìƒ'\n",
    "    \n",
    "    df_copy[\"ì´ì‹œìˆ _bin3\"] = df_copy[\"ì´ ì‹œìˆ  íšŸìˆ˜\"].apply(collapse_trials)\n",
    "    \n",
    "    # ë‚˜ì´_3êµ¬ê°„\n",
    "    def age_group_simple(age):\n",
    "        if age == 'ì•Œ ìˆ˜ ì—†ìŒ':\n",
    "            return 'Unknown'\n",
    "        elif age == 'ë§Œ18-34ì„¸':\n",
    "            return '34ì„¸ ì´í•˜'\n",
    "        elif age in ['ë§Œ35-37ì„¸', 'ë§Œ38-39ì„¸']:\n",
    "            return '35-39ì„¸'\n",
    "        else:\n",
    "            return '40ì„¸ ì´ìƒ'\n",
    "    \n",
    "    df_copy['ë‚˜ì´_3êµ¬ê°„'] = df_copy['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].apply(age_group_simple)\n",
    "    \n",
    "    # ì´ì‹ë°°ì•„_êµ¬ê°„\n",
    "    def embryo_count_bin(count):\n",
    "        if pd.isna(count) or count == 0:\n",
    "            return '0ê°œ'\n",
    "        elif count <= 2:\n",
    "            return '1-2ê°œ'\n",
    "        else:\n",
    "            return '3ê°œ ì´ìƒ'\n",
    "    \n",
    "    df_copy['ì´ì‹ë°°ì•„_êµ¬ê°„'] = df_copy['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].apply(embryo_count_bin)\n",
    "    \n",
    "    # Day5_ì´ì‹_ì—¬ë¶€\n",
    "    df_copy['Day5_ì´ì‹_ì—¬ë¶€'] = (df_copy['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'] == 5.0).astype(int)\n",
    "    \n",
    "    # ë¶ˆì„ì›ì¸_ë³µì¡ë„\n",
    "    infertility_cols = [\n",
    "        \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\", \"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\", \"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\", \"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "        \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\", \"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\", \"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\", \"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\", \"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\", \"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"\n",
    "    ]\n",
    "    \n",
    "    df_copy[\"ë¶ˆì„_ì›ì¸_ê°œìˆ˜\"] = df_copy[infertility_cols].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0:\n",
    "            return 'None'\n",
    "        elif count == 1:\n",
    "            return 'Single'\n",
    "        elif count == 2:\n",
    "            return 'Double'\n",
    "        else:\n",
    "            return 'Multiple'\n",
    "    \n",
    "    df_copy['ë¶ˆì„ì›ì¸_ë³µì¡ë„'] = df_copy['ë¶ˆì„_ì›ì¸_ê°œìˆ˜'].apply(infertility_complexity)\n",
    "    \n",
    "    # ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€\n",
    "    df_copy['ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€'] = df_copy['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].notna().astype(int)\n",
    "    \n",
    "    # ë°°ì•„ íš¨ìœ¨ ë¹„ìœ¨ ë³€ìˆ˜ë“¤\n",
    "    df_copy['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df_copy['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)\n",
    "    df_copy['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df_copy['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    df_copy['ë°°ì•„_ì €ì¥_ë¹„ìœ¨'] = df_copy['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    \n",
    "    # êµí˜¸ì‘ìš© ë³€ìˆ˜ë“¤\n",
    "    df_copy['ë‚˜ì´Ã—Day5'] = df_copy['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].astype(str) + '_' + df_copy['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    df_copy['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´'] = df_copy['ì´ì‹œìˆ _bin3'] + '_' + df_copy['ë‚˜ì´_3êµ¬ê°„']\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬ ì ìš©\n",
    "print(\"\\nì „ì²˜ë¦¬ ì¤‘...\")\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ Train shape: {train_df.shape}\")\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ Test shape: {test_df.shape}\")\n",
    "\n",
    "# 4. ID ì œê±° (AutoGluonì€ ìë™ìœ¼ë¡œ íƒ€ê²Ÿ ì°¾ìŒ)\n",
    "train_data = train_df.drop(columns=['ID', 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "test_data = test_df.drop(columns=['ID', 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "\n",
    "print(f\"\\nFinal Train shape: {train_data.shape}\")\n",
    "print(f\"Target distribution:\\n{train_data['ì„ì‹  ì„±ê³µ ì—¬ë¶€'].value_counts(normalize=True)}\")\n",
    "\n",
    "# ============================\n",
    "# 5. AutoGluon í•™ìŠµ\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting AutoGluon Training\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2ì‹œê°„\")\n",
    "print(\"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 4-8GB ì˜ˆìƒ\")\n",
    "print(\"\\ní•™ìŠµ ì‹œì‘...\\n\")\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label='ì„ì‹  ì„±ê³µ ì—¬ë¶€',\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='../outputs/autogluon_models'\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=7200,  # 2ì‹œê°„\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=5,\n",
    "    num_bag_sets=1,\n",
    "    num_stack_levels=1,\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 6. ê²°ê³¼ í™•ì¸\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AutoGluon Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Leaderboard\n",
    "leaderboard = predictor.leaderboard(train_data, silent=True)\n",
    "print(\"\\n=== Model Leaderboard (Top 15) ===\")\n",
    "print(leaderboard.head(15).to_string())\n",
    "\n",
    "# Best model\n",
    "best_model = leaderboard.iloc[0]['model']\n",
    "best_score = leaderboard.iloc[0]['score_val']\n",
    "print(f\"\\nğŸ† Best Model: {best_model}\")\n",
    "print(f\"ğŸ¯ Best CV AUC: {best_score:.6f}\")\n",
    "\n",
    "# ============================\n",
    "# 7. Feature Importance\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Feature Importance\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    importance = predictor.feature_importance(train_data)\n",
    "    print(\"\\n=== Top 20 Features ===\")\n",
    "    print(importance.head(20).to_string())\n",
    "except:\n",
    "    print(\"Feature importance not available for ensemble model\")\n",
    "\n",
    "# ============================\n",
    "# 8. ì˜ˆì¸¡ ë° Submission\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Predictions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test ì˜ˆì¸¡\n",
    "test_predictions = predictor.predict_proba(test_data)\n",
    "\n",
    "# í™•ë¥ ê°’ ì¶”ì¶œ (í´ë˜ìŠ¤ 1ì˜ í™•ë¥ )\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    test_proba = test_predictions[1].values\n",
    "else:\n",
    "    test_proba = test_predictions\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ê°’ í†µê³„:\")\n",
    "print(f\"Min:  {test_proba.min():.6f}\")\n",
    "print(f\"Max:  {test_proba.max():.6f}\")\n",
    "print(f\"Mean: {test_proba.mean():.6f}\")\n",
    "print(f\"Std:  {test_proba.std():.6f}\")\n",
    "\n",
    "# Submission ìƒì„±\n",
    "submission['probability'] = test_proba\n",
    "submission.to_csv(\"../outputs/submission_autogluon(0206).csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… AutoGluon Submission saved!\")\n",
    "print(f\"   File: ../outputs/submission_autogluon(0206).csv\")\n",
    "\n",
    "# ============================\n",
    "# 9. ìƒì„¸ ì •ë³´ ì €ì¥\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Saving Details\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Leaderboard ì „ì²´ ì €ì¥\n",
    "leaderboard.to_csv(\"../outputs/autogluon_leaderboard.csv\", index=False)\n",
    "print(\"âœ… Leaderboard saved: ../outputs/autogluon_leaderboard.csv\")\n",
    "\n",
    "# Feature importance ì €ì¥\n",
    "try:\n",
    "    importance.to_csv(\"../outputs/autogluon_feature_importance.csv\")\n",
    "    print(\"âœ… Feature importance saved: ../outputs/autogluon_feature_importance.csv\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ============================\n",
    "# 10. ìš”ì•½\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Best Model: {best_model}\n",
    "CV AUC: {best_score:.6f}\n",
    "\n",
    "Total Models Trained: {len(leaderboard)}\n",
    "Ensemble Type: {predictor.model_best}\n",
    "\n",
    "Top 3 Models:\n",
    "\"\"\"\n",
    "\n",
    "for i in range(min(3, len(leaderboard))):\n",
    "    summary += f\"  {i+1}. {leaderboard.iloc[i]['model']}: {leaderboard.iloc[i]['score_val']:.6f}\\n\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# ìš”ì•½ íŒŒì¼ ì €ì¥\n",
    "with open(\"../outputs/autogluon_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\nâœ… Summary saved: ../outputs/autogluon_summary.txt\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AutoGluon Experiment Complete! ğŸ‰\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdbda9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission model: WeightedEnsemble_L2\n"
     ]
    }
   ],
   "source": [
    "print(\"Submission model:\", predictor.model_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de560e",
   "metadata": {},
   "source": [
    "AUC ê¸°ì¤€ WeightedEnsemble_L2 1ë“± 0.740718\n",
    "\n",
    "------------\n",
    "\n",
    "<ê³„ì†í•´ì„œ ìƒìœ„ê¶Œì— ìˆëŠ” ì›ë³¸ ë³€ìˆ˜>\n",
    "\n",
    "ì´ì‹ëœ ë°°ì•„ ìˆ˜ (0.0199) \n",
    "\n",
    "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´ (0.0113)\n",
    "\n",
    "ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼ (0.0073)\n",
    "\n",
    "ì´ ìƒì„± ë°°ì•„ ìˆ˜ (0.0067)\n",
    "\n",
    "ì €ì¥ëœ ë°°ì•„ ìˆ˜\n",
    "\n",
    "-------------\n",
    "\n",
    "<íŒŒìƒ ë³€ìˆ˜>\n",
    "ë°°ì•„_ì´ì‹_ë¹„ìœ¨ \n",
    "\n",
    "ë‚˜ì´Ã—Day5\n",
    "\n",
    "ë°°ì•„_ì €ì¥_ë¹„ìœ¨\n",
    "\n",
    "ë°°ì•„_ìƒì„±_íš¨ìœ¨\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553e01d",
   "metadata": {},
   "source": [
    "## 03.1 feature top 20ë§Œ ê°€ì§€ê³  í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35bbb36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "03.1 - Top 20 Feature Selection + AutoGluon\n",
      "================================================================================\n",
      "\n",
      "ì „ëµ: 03ë²ˆ Feature Importance Top 20ë§Œ ì‚¬ìš©\n",
      "================================================================================\n",
      "\n",
      "Train shape: (256351, 69)\n",
      "Test shape: (90067, 68)\n",
      "\n",
      "ì „ì²˜ë¦¬ ì¤‘...\n",
      "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "   Train: (256351, 82)\n",
      "   Test: (90067, 81)\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ Top 20 Feature Selection (03ë²ˆ Feature Importance ê¸°ë°˜)\n",
      "================================================================================\n",
      "\n",
      "ì„ íƒëœ Feature: 20ê°œ\n",
      "   1. ì´ì‹ëœ ë°°ì•„ ìˆ˜\n",
      "   2. ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´\n",
      "   3. ë‚˜ì´_3êµ¬ê°„\n",
      "   4. ë°°ì•„_ì €ì¥_ë¹„ìœ¨\n",
      "   5. ì´ì‹ë°°ì•„_êµ¬ê°„\n",
      "   6. ë‚˜ì´Ã—Day5\n",
      "   7. Day5_ì´ì‹_ì—¬ë¶€\n",
      "   8. ë°°ì•„_ìƒì„±_íš¨ìœ¨\n",
      "   9. ì‹œìˆ  ì‹œê¸° ì½”ë“œ\n",
      "  10. ì €ì¥ëœ ë°°ì•„ ìˆ˜\n",
      "  11. ë°°ì•„_ì´ì‹_ë¹„ìœ¨\n",
      "  12. ì‹œìˆ _ëŒ€ë¶„ë¥˜\n",
      "  13. ë°°ì•„_ì§„í–‰_ë‹¨ê³„\n",
      "  14. ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\n",
      "  15. ì´ì‹œìˆ _bin3\n",
      "  16. BLASTOCYST_í¬í•¨\n",
      "  17. ë°°ë€ ìœ ë„ ìœ í˜•\n",
      "  18. ë¶ˆì„_ì›ì¸_ê°œìˆ˜\n",
      "  19. ì´ ìƒì„± ë°°ì•„ ìˆ˜\n",
      "  20. ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´\n",
      "\n",
      " ì‹¤ì œ ì‚¬ìš© Feature: 20ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=10, num_bag_sets=2\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 10800 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: ../outputs/autogluon_03.1_top20/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ìµœì¢… ë°ì´í„°:\n",
      "   Train: (256351, 21)\n",
      "   Test: (90067, 20)\n",
      "\n",
      "Target ë¶„í¬:\n",
      "ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "0    0.741651\n",
      "1    0.258349\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ AutoGluon Training - Top 20 Features Only!\n",
      "================================================================================\n",
      "\n",
      "â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 3ì‹œê°„\n",
      "ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 4-8GB\n",
      "\n",
      "í•™ìŠµ ì‹œì‘...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 2542 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 8258 seconds.\n",
      "Starting full fit now with num_stack_levels 0.\n",
      "Beginning AutoGluon training ... Time limit = 8258s\n",
      "AutoGluon will save models to \"../outputs/autogluon_03.1_top20\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       6.08 GB / 16.00 GB (38.0%)\n",
      "Disk Space Avail:   206.83 GB / 460.43 GB (44.9%)\n",
      "===================================================\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 20\n",
      "Label Column:       ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6322.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 263.74 MB (4.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  7 | ['ì´ì‹ëœ ë°°ì•„ ìˆ˜', 'ë°°ì•„_ì €ì¥_ë¹„ìœ¨', 'ë°°ì•„_ìƒì„±_íš¨ìœ¨', 'ì €ì¥ëœ ë°°ì•„ ìˆ˜', 'ë°°ì•„_ì´ì‹_ë¹„ìœ¨', ...]\n",
      "\t\t('int', [])    :  3 | ['Day5_ì´ì‹_ì—¬ë¶€', 'BLASTOCYST_í¬í•¨', 'ë¶ˆì„_ì›ì¸_ê°œìˆ˜']\n",
      "\t\t('object', []) : 10 | ['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ë‚˜ì´_3êµ¬ê°„', 'ì´ì‹ë°°ì•„_êµ¬ê°„', 'ë‚˜ì´Ã—Day5', 'ì‹œìˆ  ì‹œê¸° ì½”ë“œ', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ë‚˜ì´_3êµ¬ê°„', 'ì´ì‹ë°°ì•„_êµ¬ê°„', 'ë‚˜ì´Ã—Day5', 'ì‹œìˆ  ì‹œê¸° ì½”ë“œ', ...]\n",
      "\t\t('float', [])     :  7 | ['ì´ì‹ëœ ë°°ì•„ ìˆ˜', 'ë°°ì•„_ì €ì¥_ë¹„ìœ¨', 'ë°°ì•„_ìƒì„±_íš¨ìœ¨', 'ì €ì¥ëœ ë°°ì•„ ìˆ˜', 'ë°°ì•„_ì´ì‹_ë¹„ìœ¨', ...]\n",
      "\t\t('int', [])       :  1 | ['ë¶ˆì„_ì›ì¸_ê°œìˆ˜']\n",
      "\t\t('int', ['bool']) :  2 | ['Day5_ì´ì‹_ì—¬ë¶€', 'BLASTOCYST_í¬í•¨']\n",
      "\t0.9s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 18.58 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'AG_AUTOMM': {},\n",
      "\t'VW': {},\n",
      "}\n",
      "Fitting 8 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 8256.99s of the 8256.99s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.93%)\n",
      "\t0.7339\t = Validation score   (roc_auc)\n",
      "\t5.22s\t = Training   runtime\n",
      "\t2.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 8249.6s of the 8249.6s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.94%)\n",
      "\t0.7344\t = Validation score   (roc_auc)\n",
      "\t6.2s\t = Training   runtime\n",
      "\t2.95s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 8241.24s of the 8241.24s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.99%)\n",
      "\t0.7345\t = Validation score   (roc_auc)\n",
      "\t1110.3s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 7129.11s of the 7129.11s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.90%)\n",
      "\t0.7339\t = Validation score   (roc_auc)\n",
      "\t102.75s\t = Training   runtime\n",
      "\t1.67s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 7023.93s of the 7023.93s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.79%)\n",
      "\t0.7335\t = Validation score   (roc_auc)\n",
      "\t101.95s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: VowpalWabbit_BAG_L1 ... Training model for up to 6919.87s of the 6919.87s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.38%)\n",
      "\tWarning: Exception caused VowpalWabbit_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=42755, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=42755, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 6917.63s of the 6917.62s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.57%)\n",
      "2026-02-07 23:59:47,446\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=42754, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=42754, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "2026-02-07 23:59:47,451\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=42758, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=42758, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "2026-02-07 23:59:47,452\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 23:59:47,454\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=42752, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=42752, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "2026-02-07 23:59:47,457\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=42750, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=42750, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "2026-02-07 23:59:47,459\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2026-02-07 23:59:47,461\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.733\t = Validation score   (roc_auc)\n",
      "\t7.8s\t = Training   runtime\n",
      "\t4.71s\t = Validation runtime\n",
      "Fitting model: MultiModalPredictor_BAG_L1 ... Training model for up to 6907.48s of the 6907.48s of remaining time.\n",
      "\tWarning: Exception caused MultiModalPredictor_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe total system num_gpus=0 is less than minimum num_gpus=1 to fit StackerEnsembleModel. Consider using a machine with more GPUs.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 847, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 528, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 759, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 704, in _calculate_total_resources\n",
      "    system_num_gpus >= minimum_model_num_gpus\n",
      "AssertionError: The total system num_gpus=0 is less than minimum num_gpus=1 to fit StackerEnsembleModel. Consider using a machine with more GPUs.\n",
      "Repeating k-fold bagging: 2/2\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 6905.59s of the 6905.59s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.96%)\n",
      "\t0.7341\t = Validation score   (roc_auc)\n",
      "\t10.87s\t = Training   runtime\n",
      "\t4.8s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 6897.9s of the 6897.9s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.02%)\n",
      "\t0.7345\t = Validation score   (roc_auc)\n",
      "\t15.09s\t = Training   runtime\n",
      "\t6.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 6886.96s of the 6886.96s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.08%)\n",
      "\t0.7346\t = Validation score   (roc_auc)\n",
      "\t1849.9s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 6145.56s of the 6145.56s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=3.37%)\n",
      "\t0.7341\t = Validation score   (roc_auc)\n",
      "\t194.0s\t = Training   runtime\n",
      "\t3.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 6051.83s of the 6051.83s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.74%)\n",
      "\t0.734\t = Validation score   (roc_auc)\n",
      "\t204.93s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 5946.57s of the 5946.57s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=2.28%)\n",
      "\t0.7334\t = Validation score   (roc_auc)\n",
      "\t16.91s\t = Training   runtime\n",
      "\t9.52s\t = Validation runtime\n",
      "Completed 2/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 825.7s of the 5934.76s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.421, 'NeuralNetTorch_BAG_L1': 0.316, 'LightGBMXT_BAG_L1': 0.105, 'XGBoost_BAG_L1': 0.105, 'LightGBMLarge_BAG_L1': 0.053}\n",
      "\t0.735\t = Validation score   (roc_auc)\n",
      "\t6.19s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2329.5s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../outputs/autogluon_03.1_top20\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š Results\n",
      "================================================================================\n",
      "\n",
      "=== Model Leaderboard (Top 20) ===\n",
      "                   model  score_test  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   LightGBMLarge_BAG_L1    0.758143   0.733417     roc_auc       11.113005       9.522752    16.913163                11.113005                9.522752          16.913163            1       True          6\n",
      "1        LightGBM_BAG_L1    0.741519   0.734102     roc_auc        6.065471       4.795352    10.874730                 6.065471                4.795352          10.874730            1       True          1\n",
      "2    WeightedEnsemble_L2    0.740812   0.734957     roc_auc       51.447638      21.243602  2287.031656                 0.004058                0.039310           6.194374            2       True          7\n",
      "3         XGBoost_BAG_L1    0.740777   0.734054     roc_auc       11.947266       3.164918   194.004320                11.947266                3.164918         194.004320            1       True          4\n",
      "4      LightGBMXT_BAG_L1    0.740327   0.734505     roc_auc        7.805345       6.158440    15.088012                 7.805345                6.158440          15.088012            1       True          2\n",
      "5  NeuralNetTorch_BAG_L1    0.739170   0.734031     roc_auc       18.126491       1.825867   204.929139                18.126491                1.825867         204.929139            1       True          5\n",
      "6        CatBoost_BAG_L1    0.738684   0.734590     roc_auc        2.451473       0.532315  1849.902647                 2.451473                0.532315        1849.902647            1       True          3\n",
      "\n",
      " Best Model: LightGBMLarge_BAG_L1\n",
      "ğŸ¯ Best CV AUC: 0.733417\n",
      "\n",
      "ğŸ“Š ì„±ì í‘œ:\n",
      "   03ë²ˆ (85ê°œ Feature): 0.7407\n",
      "   03.1ë²ˆ (20ê°œ Feature): 0.733417\n",
      "   Improvement:        +-0.007283\n",
      "\n",
      "03ë²ˆì´ ë” ë‚˜ìŒ... Feature Selection íš¨ê³¼ ì—†ìŒ\n",
      "\n",
      "================================================================================\n",
      "Predictions\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 20 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì˜ˆì¸¡ê°’ í†µê³„:\n",
      "Min:  0.000273\n",
      "Max:  0.635399\n",
      "Mean: 0.259804\n",
      "Std:  0.156654\n",
      "\n",
      "Submission saved!\n",
      "   File: ../outputs/03.1_submission_top20_CV0.733417.csv\n",
      "Leaderboard saved: ../outputs/03.1_leaderboard.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t164.05s\t= Expected runtime (32.81s per shuffle set)\n",
      "\t112.74s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance saved\n",
      "\n",
      "=== Top 20 Feature Importance (ì¬í™•ì¸) ===\n",
      "               importance    stddev   p_value  n  p99_high   p99_low\n",
      "ì´ì‹ëœ ë°°ì•„ ìˆ˜         0.017270  0.004218  0.000395  5  0.025955  0.008586\n",
      "ë°°ì•„_ì´ì‹_ë¹„ìœ¨         0.015024  0.003372  0.000285  5  0.021966  0.008082\n",
      "ë‚˜ì´_3êµ¬ê°„           0.011237  0.004490  0.002502  5  0.020482  0.001992\n",
      "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´         0.007882  0.003204  0.002662  5  0.014479  0.001285\n",
      "ë°°ì•„_ìƒì„±_íš¨ìœ¨         0.007523  0.001626  0.000246  5  0.010870  0.004175\n",
      "ì´ ìƒì„± ë°°ì•„ ìˆ˜        0.006957  0.003600  0.006219  5  0.014369 -0.000456\n",
      "ë°°ì•„_ì§„í–‰_ë‹¨ê³„         0.006806  0.002230  0.001206  5  0.011398  0.002214\n",
      "ë‚˜ì´Ã—Day5          0.006779  0.002646  0.002299  5  0.012228  0.001331\n",
      "ë°°ë€ ìœ ë„ ìœ í˜•         0.006646  0.001128  0.000096  5  0.008969  0.004322\n",
      "ë°°ì•„_ì €ì¥_ë¹„ìœ¨         0.005882  0.002896  0.005240  5  0.011844 -0.000080\n",
      "ì´ì‹ë°°ì•„_êµ¬ê°„          0.005660  0.002296  0.002643  5  0.010388  0.000932\n",
      "Day5_ì´ì‹_ì—¬ë¶€       0.005457  0.001879  0.001450  5  0.009326  0.001588\n",
      "ì‹œìˆ  ì‹œê¸° ì½”ë“œ         0.005007  0.000574  0.000020  5  0.006188  0.003825\n",
      "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜      0.004159  0.000862  0.000210  5  0.005934  0.002383\n",
      "ì €ì¥ëœ ë°°ì•„ ìˆ˜         0.002671  0.002445  0.035512  5  0.007705 -0.002364\n",
      "ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´          0.001932  0.001249  0.012929  5  0.004504 -0.000640\n",
      "ì‹œìˆ _ëŒ€ë¶„ë¥˜           0.001889  0.000709  0.001991  5  0.003348  0.000429\n",
      "ë¶ˆì„_ì›ì¸_ê°œìˆ˜         0.001290  0.000288  0.000281  5  0.001884  0.000696\n",
      "ì´ì‹œìˆ _bin3         0.000696  0.000366  0.006544  5  0.001449 -0.000057\n",
      "BLASTOCYST_í¬í•¨    0.000095  0.000038  0.002559  5  0.000173  0.000016\n",
      "\n",
      "\n",
      "================================================================================\n",
      "03.1ë²ˆ - Top 20 Feature Selection ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ì „ëµ: 03ë²ˆ Feature Importance Top 20ë§Œ ì„ íƒ\n",
      "  - 85ê°œ Feature â†’ 20ê°œ Feature (65ê°œ ì œê±°!)\n",
      "  - ë…¸ì´ì¦ˆ ì œê±° + í•µì‹¬ Feature ì§‘ì¤‘\n",
      "\n",
      "Best Model: LightGBMLarge_BAG_L1\n",
      "CV AUC: 0.733417\n",
      "\n",
      "ì„±ì  ë¹„êµ:\n",
      "  03ë²ˆ (85ê°œ):     0.7407 (LB: 0.742)\n",
      "  03.1ë²ˆ (20ê°œ):     0.733417\n",
      "\n",
      "Improvement: +-0.007283\n",
      "\n",
      "ì˜ˆìƒ LB (03ë²ˆ ê¸°ì¤€ +0.0013):\n",
      "  03.1ë²ˆ: 0.734717\n",
      "\n",
      "================================================================================\n",
      "í˜„ì¬ ìˆœìœ„:\n",
      "  1ë“±: 0.74209\n",
      "  ë‚˜:  0.74200 (5ë“±)\n",
      "\n",
      "03.1ë²ˆ ì˜ˆìƒ ìˆœìœ„:\n",
      "  ìƒìœ„ê¶Œ (ì˜ˆìƒ LB: 0.73472)\n",
      "================================================================================\n",
      "\n",
      "Summary saved: ../outputs/03.1_summary.txt\n",
      "\n",
      "================================================================================\n",
      "03.1ë²ˆ COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"03.1 - Top 20 Feature Selection + AutoGluon\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nì „ëµ: 03ë²ˆ Feature Importance Top 20ë§Œ ì‚¬ìš©\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 0) Load\n",
    "# ============================================================\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "TEST_PATH  = \"../data/test.csv\"\n",
    "SUB_PATH   = \"../data/sample_submission.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "sub   = pd.read_csv(SUB_PATH)\n",
    "\n",
    "TARGET_COL = \"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"\n",
    "ID_COL = \"ID\"\n",
    "\n",
    "print(f\"\\nTrain shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 1) Feature Engineering (03ë²ˆê³¼ ë™ì¼)\n",
    "# ============================================================\n",
    "\n",
    "# ê³ ê²°ì¸¡ ë³€ìˆ˜ ì œê±°\n",
    "HIGH_MISSING_COLS = [\n",
    "    'ë‚œì í•´ë™ ê²½ê³¼ì¼',           # 99.4%\n",
    "    'PGS ì‹œìˆ  ì—¬ë¶€',             # 99.2%\n",
    "    'PGD ì‹œìˆ  ì—¬ë¶€',             # 99.1%\n",
    "    'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', # 98.9%\n",
    "    'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜',  # 96.3%\n",
    "]\n",
    "\n",
    "EMBRYO_STAGE_COLS = [\n",
    "    \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\",\"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\",\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "    \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\",\"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ ë‚œì ìˆ˜\",\n",
    "    \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "]\n",
    "\n",
    "INFERTILITY_COLS = [\n",
    "    \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\",\"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\",\"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\",\"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\",\"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\",\"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"\n",
    "]\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ê³ ê²°ì¸¡ ì œê±°\n",
    "    df = df.drop(columns=HIGH_MISSING_COLS, errors='ignore')\n",
    "    \n",
    "    # ì‹œìˆ _ëŒ€ë¶„ë¥˜\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        x = str(x)\n",
    "        if \"IUI\" in x: return \"IUI\"\n",
    "        if \"ICSI\" in x: return \"ICSI\"\n",
    "        if \"IVF\" in x: return \"IVF\"\n",
    "        if \"DI\" in x: return \"DI\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df[\"ì‹œìˆ _ëŒ€ë¶„ë¥˜\"] = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(major_procedure)\n",
    "    \n",
    "    # BLASTOCYST_í¬í•¨\n",
    "    s = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].astype(\"object\").fillna(\"Unknown\").astype(str)\n",
    "    df[\"BLASTOCYST_í¬í•¨\"] = s.str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    \n",
    "    # ë°°ì•„_ì´ì‹_ì—¬ë¶€\n",
    "    df[\"ë°°ì•„_stage_missing_count\"] = df[EMBRYO_STAGE_COLS].isna().sum(axis=1)\n",
    "    df[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"] = (df[\"ë°°ì•„_stage_missing_count\"] == len(EMBRYO_STAGE_COLS)).astype(int)\n",
    "    df[\"ë°°ì•„_ì´ì‹_ì—¬ë¶€\"] = 1 - df[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"]\n",
    "    \n",
    "    # ë°°ì•„_ì§„í–‰_ë‹¨ê³„\n",
    "    def embryo_stage(row):\n",
    "        if row['ë°°ì•„_ì´ì‹_ì—¬ë¶€'] == 0:\n",
    "            return 'ë°°ì•„ë‹¨ê³„_ë¯¸ë„ë‹¬'\n",
    "        total = pd.to_numeric(row.get('ì´ ìƒì„± ë°°ì•„ ìˆ˜'), errors='coerce')\n",
    "        implanted = pd.to_numeric(row.get('ì´ì‹ëœ ë°°ì•„ ìˆ˜'), errors='coerce')\n",
    "        if pd.isna(total) or total == 0:\n",
    "            return 'ë°°ì•„ìƒì„±_ì‹¤íŒ¨'\n",
    "        elif pd.isna(implanted) or implanted == 0:\n",
    "            return 'ì´ì‹_ë¯¸ì‹¤ì‹œ'\n",
    "        else:\n",
    "            return 'ì´ì‹_ì™„ë£Œ'\n",
    "    \n",
    "    df['ë°°ì•„_ì§„í–‰_ë‹¨ê³„'] = df.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    # ì´ì‹œìˆ _bin3\n",
    "    def collapse_trials(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        if x == \"0íšŒ\": return \"0íšŒ\"\n",
    "        if x in [\"1íšŒ\", \"2íšŒ\"]: return \"1-2íšŒ\"\n",
    "        return \"3íšŒ ì´ìƒ\"\n",
    "    \n",
    "    df[\"ì´ì‹œìˆ _bin3\"] = df[\"ì´ ì‹œìˆ  íšŸìˆ˜\"].apply(collapse_trials)\n",
    "    \n",
    "    # ë‚˜ì´_3êµ¬ê°„\n",
    "    def age_group_simple(age):\n",
    "        if pd.isna(age) or age == \"ì•Œ ìˆ˜ ì—†ìŒ\": return \"Unknown\"\n",
    "        if age == \"ë§Œ18-34ì„¸\": return \"34ì„¸ ì´í•˜\"\n",
    "        if age in [\"ë§Œ35-37ì„¸\", \"ë§Œ38-39ì„¸\"]: return \"35-39ì„¸\"\n",
    "        return \"40ì„¸ ì´ìƒ\"\n",
    "    \n",
    "    df[\"ë‚˜ì´_3êµ¬ê°„\"] = df[\"ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´\"].apply(age_group_simple)\n",
    "    \n",
    "    # ì´ì‹ë°°ì•„_êµ¬ê°„\n",
    "    def embryo_count_bin(count):\n",
    "        count = pd.to_numeric(count, errors='coerce')\n",
    "        if pd.isna(count) or count == 0: return \"0ê°œ\"\n",
    "        elif count <= 2: return \"1-2ê°œ\"\n",
    "        else: return \"3ê°œ ì´ìƒ\"\n",
    "    \n",
    "    df['ì´ì‹ë°°ì•„_êµ¬ê°„'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].apply(embryo_count_bin)\n",
    "    \n",
    "    # Day5_ì´ì‹_ì—¬ë¶€\n",
    "    d = pd.to_numeric(df[\"ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼\"], errors=\"coerce\")\n",
    "    df[\"Day5_ì´ì‹_ì—¬ë¶€\"] = (d == 5).astype(int)\n",
    "    \n",
    "    # ë¶ˆì„ì›ì¸_ë³µì¡ë„\n",
    "    tmp = df[INFERTILITY_COLS].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    df[\"ë¶ˆì„_ì›ì¸_ê°œìˆ˜\"] = tmp.sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df['ë¶ˆì„ì›ì¸_ë³µì¡ë„'] = df['ë¶ˆì„_ì›ì¸_ê°œìˆ˜'].apply(infertility_complexity)\n",
    "    \n",
    "    # ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€\n",
    "    df['ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€'] = df['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].notna().astype(int)\n",
    "    \n",
    "    # ìˆ«ìí˜• ì•ˆì „ ë³€í™˜\n",
    "    num_cols = [\n",
    "        \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\", \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\", \"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\"\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    \n",
    "    # ë¹„ìœ¨ ë³€ìˆ˜\n",
    "    df['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)\n",
    "    df['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    df['ë°°ì•„_ì €ì¥_ë¹„ìœ¨'] = df['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    \n",
    "    # êµí˜¸ì‘ìš©\n",
    "    df['ë‚˜ì´Ã—Day5'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].astype(str) + '_' + df['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    df['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´'] = df['ì´ì‹œìˆ _bin3'].astype(str) + '_' + df['ë‚˜ì´_3êµ¬ê°„'].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"\\nì „ì²˜ë¦¬ ì¤‘...\")\n",
    "train_df = preprocess(train)\n",
    "test_df = preprocess(test)\n",
    "\n",
    "print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "print(f\"   Train: {train_df.shape}\")\n",
    "print(f\"   Test: {test_df.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# ğŸ¯ 2) Top 20 Feature ì„ íƒ (í•µì‹¬!)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ Top 20 Feature Selection (03ë²ˆ Feature Importance ê¸°ë°˜)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 03ë²ˆ Feature Importance Top 20\n",
    "TOP_20_FEATURES = [\n",
    "    # Top 10 (ì›ë³¸)\n",
    "    'ì´ì‹ëœ ë°°ì•„ ìˆ˜',           # 1ìœ„ (0.0300)\n",
    "    'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´',           # 2ìœ„ (0.0112)\n",
    "    'ë‚˜ì´_3êµ¬ê°„',              # 3ìœ„ (0.0106)\n",
    "    'ë°°ì•„_ì €ì¥_ë¹„ìœ¨',           # 4ìœ„ (0.0097)\n",
    "    'ì´ì‹ë°°ì•„_êµ¬ê°„',           # 5ìœ„ (0.0097)\n",
    "    'ë‚˜ì´Ã—Day5',             # 7ìœ„ (0.0090)\n",
    "    'Day5_ì´ì‹_ì—¬ë¶€',         # 8ìœ„ (0.0067)\n",
    "    'ë°°ì•„_ìƒì„±_íš¨ìœ¨',          # 9ìœ„ (0.0067)\n",
    "    'ì‹œìˆ  ì‹œê¸° ì½”ë“œ',          # 10ìœ„ (0.0065)\n",
    "    'ì €ì¥ëœ ë°°ì•„ ìˆ˜',          # 11ìœ„ (0.0064)\n",
    "    \n",
    "    # Top 11-20\n",
    "    'ë°°ì•„_ì´ì‹_ë¹„ìœ¨',          # 12ìœ„\n",
    "    'ì‹œìˆ _ëŒ€ë¶„ë¥˜',            # 13ìœ„\n",
    "    'ë°°ì•„_ì§„í–‰_ë‹¨ê³„',          # 14ìœ„\n",
    "    'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜',      # 15ìœ„\n",
    "    'ì´ì‹œìˆ _bin3',           # 16ìœ„\n",
    "    'BLASTOCYST_í¬í•¨',       # 17ìœ„\n",
    "    'ë°°ë€ ìœ ë„ ìœ í˜•',          # 18ìœ„\n",
    "    'ë¶ˆì„_ì›ì¸_ê°œìˆ˜',          # 19ìœ„\n",
    "    'ì´ ìƒì„± ë°°ì•„ ìˆ˜',         # 20ìœ„\n",
    "    'ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´',          # íŒŒìƒ (êµí˜¸ì‘ìš©)\n",
    "]\n",
    "\n",
    "print(f\"\\nì„ íƒëœ Feature: {len(TOP_20_FEATURES)}ê°œ\")\n",
    "for i, feat in enumerate(TOP_20_FEATURES, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "\n",
    "# Feature ì¡´ì¬ í™•ì¸\n",
    "available_features = []\n",
    "for feat in TOP_20_FEATURES:\n",
    "    if feat in train_df.columns:\n",
    "        available_features.append(feat)\n",
    "    else:\n",
    "        print(f\"âš ï¸  '{feat}' not found in data\")\n",
    "\n",
    "print(f\"\\n ì‹¤ì œ ì‚¬ìš© Feature: {len(available_features)}ê°œ\")\n",
    "\n",
    "# ============================================================\n",
    "# 3) ë°ì´í„° ì¤€ë¹„ (Top 20ë§Œ!)\n",
    "# ============================================================\n",
    "train_data = train_df[available_features + [TARGET_COL]].copy()\n",
    "test_data = test_df[available_features].copy()\n",
    "\n",
    "print(f\"\\nìµœì¢… ë°ì´í„°:\")\n",
    "print(f\"   Train: {train_data.shape}\")\n",
    "print(f\"   Test: {test_data.shape}\")\n",
    "print(f\"\\nTarget ë¶„í¬:\")\n",
    "print(train_data[TARGET_COL].value_counts(normalize=True))\n",
    "\n",
    "# ============================================================\n",
    "# 4) AutoGluon í•™ìŠµ\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ AutoGluon Training - Top 20 Features Only!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 3ì‹œê°„\")\n",
    "print(\"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 4-8GB\")\n",
    "print(\"\\ní•™ìŠµ ì‹œì‘...\\n\")\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=TARGET_COL,\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='../outputs/autogluon_03.1_top20'\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=10800,        # 3ì‹œê°„\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=10,        # ì•ˆì •ì„±\n",
    "    num_bag_sets=2,          # ë‹¤ì–‘ì„±\n",
    "    num_stack_levels=2,      # ê¹Šì€ ìŠ¤íƒœí‚¹\n",
    "    hyperparameters='multimodal',\n",
    "    auto_stack=True,\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5) ê²°ê³¼ í™•ì¸\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "leaderboard = predictor.leaderboard(train_data, silent=True)\n",
    "print(\"\\n=== Model Leaderboard (Top 20) ===\")\n",
    "print(leaderboard.head(20).to_string())\n",
    "\n",
    "best_model = leaderboard.iloc[0]['model']\n",
    "best_score = leaderboard.iloc[0]['score_val']\n",
    "\n",
    "print(f\"\\n Best Model: {best_model}\")\n",
    "print(f\"ğŸ¯ Best CV AUC: {best_score:.6f}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì„±ì í‘œ:\")\n",
    "print(f\"   03ë²ˆ (85ê°œ Feature): 0.7407\")\n",
    "print(f\"   03.1ë²ˆ (20ê°œ Feature): {best_score:.6f}\")\n",
    "print(f\"   Improvement:        +{best_score - 0.7407:.6f}\")\n",
    "\n",
    "if best_score >= 0.7450:\n",
    "    print(\"\\nëª©í‘œ ë‹¬ì„±! 1ë“± ê°€ëŠ¥ì„± ë§¤ìš° ë†’ìŒ! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "elif best_score >= 0.7425:\n",
    "    print(\"\\nëŒ€ì„±ê³µ! ìƒìœ„ê¶Œ í™•ì •!\")\n",
    "elif best_score >= 0.7415:\n",
    "    print(\"\\nì¢‹ì€ ì„±ì ! ì œì¶œ ì¶”ì²œ!\")\n",
    "elif best_score > 0.7407:\n",
    "    print(\"\\n03ë²ˆë³´ë‹¤ ë†’ìŒ! ì œì¶œ ê³ ë ¤!\")\n",
    "else:\n",
    "    print(\"\\n03ë²ˆì´ ë” ë‚˜ìŒ... Feature Selection íš¨ê³¼ ì—†ìŒ\")\n",
    "\n",
    "# ============================================================\n",
    "# 6) ì˜ˆì¸¡ ë° Submission\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_predictions = predictor.predict_proba(test_data)\n",
    "\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    test_proba = test_predictions[1].values\n",
    "else:\n",
    "    test_proba = test_predictions\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ê°’ í†µê³„:\")\n",
    "print(f\"Min:  {test_proba.min():.6f}\")\n",
    "print(f\"Max:  {test_proba.max():.6f}\")\n",
    "print(f\"Mean: {test_proba.mean():.6f}\")\n",
    "print(f\"Std:  {test_proba.std():.6f}\")\n",
    "\n",
    "# Submission\n",
    "sub['probability'] = test_proba\n",
    "output_file = f\"../outputs/03.1_submission_top20_CV{best_score:.6f}.csv\"\n",
    "sub.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved!\")\n",
    "print(f\"   File: {output_file}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) ìƒì„¸ ì •ë³´ ì €ì¥\n",
    "# ============================================================\n",
    "leaderboard.to_csv(\"../outputs/03.1_leaderboard.csv\", index=False)\n",
    "print(\"Leaderboard saved: ../outputs/03.1_leaderboard.csv\")\n",
    "\n",
    "try:\n",
    "    importance = predictor.feature_importance(train_data)\n",
    "    importance.to_csv(\"../outputs/03.1_feature_importance.csv\")\n",
    "    print(\"Feature importance saved\")\n",
    "    print(\"\\n=== Top 20 Feature Importance (ì¬í™•ì¸) ===\")\n",
    "    print(importance.head(20).to_string())\n",
    "except:\n",
    "    print(\"Feature importance not available\")\n",
    "\n",
    "# ============================================================\n",
    "# 8) ìš”ì•½\n",
    "# ============================================================\n",
    "summary = f\"\"\"\n",
    "{'='*80}\n",
    "03.1ë²ˆ - Top 20 Feature Selection ê²°ê³¼\n",
    "{'='*80}\n",
    "\n",
    "ì „ëµ: 03ë²ˆ Feature Importance Top 20ë§Œ ì„ íƒ\n",
    "  - 85ê°œ Feature â†’ 20ê°œ Feature (65ê°œ ì œê±°!)\n",
    "  - ë…¸ì´ì¦ˆ ì œê±° + í•µì‹¬ Feature ì§‘ì¤‘\n",
    "\n",
    "Best Model: {best_model}\n",
    "CV AUC: {best_score:.6f}\n",
    "\n",
    "ì„±ì  ë¹„êµ:\n",
    "  03ë²ˆ (85ê°œ):     0.7407 (LB: 0.742)\n",
    "  03.1ë²ˆ (20ê°œ):     {best_score:.6f}\n",
    "  \n",
    "Improvement: +{best_score - 0.7407:.6f}\n",
    "\n",
    "ì˜ˆìƒ LB (03ë²ˆ ê¸°ì¤€ +0.0013):\n",
    "  03.1ë²ˆ: {best_score + 0.0013:.6f}\n",
    "\n",
    "{'='*80}\n",
    "í˜„ì¬ ìˆœìœ„:\n",
    "  1ë“±: 0.74209\n",
    "  ë‚˜:  0.74200 (5ë“±)\n",
    "  \n",
    "03.1ë²ˆ ì˜ˆìƒ ìˆœìœ„:\n",
    "\"\"\"\n",
    "\n",
    "if best_score + 0.0013 >= 0.74209:\n",
    "    summary += \"  (ì˜ˆìƒ LB: {:.5f})\\n\".format(best_score + 0.0013)\n",
    "else:\n",
    "    summary += \"  ìƒìœ„ê¶Œ (ì˜ˆìƒ LB: {:.5f})\\n\".format(best_score + 0.0013)\n",
    "\n",
    "summary += \"=\"*80\n",
    "\n",
    "print(\"\\n\" + summary)\n",
    "\n",
    "with open(\"../outputs/03.1_summary.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\nSummary saved: ../outputs/03.1_summary.txt\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"03.1ë²ˆ COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127f389",
   "metadata": {},
   "source": [
    "### 03.2 í•˜ì´í¼íŒŒë¼ë¯¸í„°íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134ced78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train shape: (256351, 69)\n",
      "Test shape: (90067, 68)\n",
      "\n",
      "ì „ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=10, num_bag_sets=3\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 21600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: ../outputs/autogluon_10_hypermax/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ (03ë²ˆê³¼ ë™ì¼)\n",
      "   Train: (256351, 81)\n",
      "   Test: (90067, 80)\n",
      "\n",
      "ìµœì¢… Feature ê°œìˆ˜: 78ê°œ\n",
      "\n",
      "Target ë¶„í¬:\n",
      "ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "0    0.741651\n",
      "1    0.258349\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ AutoGluon MAX POWER Training!\n",
      "================================================================================\n",
      "\n",
      "â° ì†Œìš” ì‹œê°„: 6ì‹œê°„ (03ë²ˆì˜ 3ë°°!)\n",
      "ğŸ’¾ ë©”ëª¨ë¦¬: 8-16GB\n",
      "ğŸ¯ ëª©í‘œ CV: 0.745+\n",
      "\n",
      "ê°•í™” í¬ì¸íŠ¸:\n",
      "  1. ì‹œê°„: 2ì‹œê°„ â†’ 6ì‹œê°„ (3ë°°)\n",
      "  2. Bagging: folds 5â†’10, sets 1â†’3\n",
      "  3. Stacking: levels 1â†’3 (ê¹Šì€ ì•™ìƒë¸”)\n",
      "  4. í•˜ì´í¼íŒŒë¼ë¯¸í„°: ê° ëª¨ë¸ ìµœëŒ€ ê°•í™”\n",
      "\n",
      "í•™ìŠµ ì‹œì‘...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 5453 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 16147 seconds.\n",
      "Starting full fit now with num_stack_levels 0.\n",
      "Beginning AutoGluon training ... Time limit = 16147s\n",
      "AutoGluon will save models to \"../outputs/autogluon_10_hypermax\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       6.18 GB / 16.00 GB (38.6%)\n",
      "Disk Space Avail:   210.92 GB / 460.43 GB (45.8%)\n",
      "===================================================\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 78\n",
      "Label Column:       ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7072.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 742.74 MB (10.5% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 10.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 23 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 27 | ['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])    : 17 | ['ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t\t('object', []) : 28 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ì‹œìˆ  ìœ í˜•', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 27 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', 'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ', ...]\n",
      "\t\t('float', [])     : 26 | ['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])       :  1 | ['ë¶ˆì„_ì›ì¸_ê°œìˆ˜']\n",
      "\t\t('int', ['bool']) : 18 | ['ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t2.5s = Fit runtime\n",
      "\t72 features in original data used to generate 72 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 63.82 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.9s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'NN_TORCH': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}],\n",
      "}\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 16144.1s of the 16144.1s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.24%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t11.82s\t = Training   runtime\n",
      "\t4.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 16129.34s of the 16129.34s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.41%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t9.44s\t = Training   runtime\n",
      "\t3.45s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 16117.52s of the 16117.52s of remaining time.\n",
      "\t0.7298\t = Validation score   (roc_auc)\n",
      "\t11.2s\t = Training   runtime\n",
      "\t7.27s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 16098.61s of the 16098.61s of remaining time.\n",
      "\t0.7306\t = Validation score   (roc_auc)\n",
      "\t11.86s\t = Training   runtime\n",
      "\t7.44s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 16078.86s of the 16078.86s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=7.21%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t2854.61s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 13222.39s of the 13222.39s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.67% memory usage per fold, 50.66%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=12.67%)\n",
      "\t0.7376\t = Validation score   (roc_auc)\n",
      "\t257.63s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 12962.35s of the 12962.35s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.86% memory usage per fold, 70.84%/80.00% total).\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.86%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t233.22s\t = Training   runtime\n",
      "\t2.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 12726.51s of the 12726.51s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.78%)\n",
      "\t0.7372\t = Validation score   (roc_auc)\n",
      "\t144.13s\t = Training   runtime\n",
      "\t2.92s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 12579.8s of the 12579.8s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.81%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t12.65s\t = Training   runtime\n",
      "\t6.26s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/3\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 12564.09s of the 12564.09s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.15%)\n",
      "\t0.74\t = Validation score   (roc_auc)\n",
      "\t23.12s\t = Training   runtime\n",
      "\t8.75s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 12550.17s of the 12550.17s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.52%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t18.25s\t = Training   runtime\n",
      "\t6.66s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 12539.28s of the 12539.28s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.65%)\n",
      "\t0.7403\t = Validation score   (roc_auc)\n",
      "\t6157.83s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 9234.23s of the 9234.23s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.78% memory usage per fold, 47.13%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.78%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t512.39s\t = Training   runtime\n",
      "\t2.9s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 8977.18s of the 8977.18s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 8.92% memory usage per fold, 71.34%/80.00% total).\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=8.92%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t511.16s\t = Training   runtime\n",
      "\t4.4s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 8696.83s of the 8696.83s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.02%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t280.69s\t = Training   runtime\n",
      "\t5.96s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 8557.78s of the 8557.78s of remaining time.\n",
      "\tFitting 10 child models (S2F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.84%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t25.37s\t = Training   runtime\n",
      "\t12.32s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/3\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 8542.07s of the 8542.06s of remaining time.\n",
      "\tFitting 10 child models (S3F1 - S3F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.37%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t33.18s\t = Training   runtime\n",
      "\t12.9s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 8529.43s of the 8529.43s of remaining time.\n",
      "\tFitting 10 child models (S3F1 - S3F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.65%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t27.27s\t = Training   runtime\n",
      "\t10.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 8518.07s of the 8518.07s of remaining time.\n",
      "\tFitting 10 child models (S3F1 - S3F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.33%)\n",
      "\t0.7404\t = Validation score   (roc_auc)\n",
      "\t9442.45s\t = Training   runtime\n",
      "\t1.55s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5231.63s of the 5231.62s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.74% memory usage per fold, 54.98%/80.00% total).\n",
      "\tFitting 10 child models (S3F1 - S3F10) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=13.74%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t768.24s\t = Training   runtime\n",
      "\t4.34s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4973.48s of the 4973.47s of remaining time.\n",
      "\tMemory not enough to fit 10 folds in parallel. Will train 8 folds in parallel instead (Estimated 9.03% memory usage per fold, 72.25%/80.00% total).\n",
      "\tFitting 10 child models (S3F1 - S3F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=9.03%)\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t763.81s\t = Training   runtime\n",
      "\t6.57s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4718.32s of the 4718.32s of remaining time.\n",
      "\tFitting 10 child models (S3F1 - S3F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=5.63%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t415.84s\t = Training   runtime\n",
      "\t8.91s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4580.64s of the 4580.64s of remaining time.\n",
      "\tFitting 10 child models (S3F1 - S3F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=6.97%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t38.41s\t = Training   runtime\n",
      "\t18.86s\t = Validation runtime\n",
      "Completed 3/3 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1614.41s of the 4564.49s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.36, 'NeuralNetFastAI_BAG_L1': 0.28, 'XGBoost_BAG_L1': 0.12, 'LightGBM_BAG_L1': 0.08, 'NeuralNetTorch_BAG_L1': 0.08, 'LightGBMXT_BAG_L1': 0.04, 'RandomForestEntr_BAG_L1': 0.04}\n",
      "\t0.7408\t = Validation score   (roc_auc)\n",
      "\t9.22s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11591.8s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../outputs/autogluon_10_hypermax\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š Results\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "Computing feature importance via permutation shuffling for 72 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Leaderboard (Top 30) ===\n",
      "                     model  score_test  score_val eval_metric  pred_time_test  pred_time_val      fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  RandomForestEntr_BAG_L1    0.931375   0.730583     roc_auc        1.791452       7.444626     11.861585                 1.791452                7.444626          11.861585            1       True          4\n",
      "1  RandomForestGini_BAG_L1    0.929479   0.729776     roc_auc        1.701691       7.265590     11.198239                 1.701691                7.265590          11.198239            1       True          3\n",
      "2     LightGBMLarge_BAG_L1    0.772744   0.739109     roc_auc       22.403445      18.864785     38.406015                22.403445               18.864785          38.406015            1       True          9\n",
      "3      WeightedEnsemble_L2    0.760503   0.740810     roc_auc      168.033392      51.802508  11471.865762                 0.006359                0.039037           9.215970            2       True         10\n",
      "4           XGBoost_BAG_L1    0.752801   0.739630     roc_auc       34.755658       6.572139    763.809591                34.755658                6.572139         763.809591            1       True          7\n",
      "5          LightGBM_BAG_L1    0.751770   0.739933     roc_auc       13.799993      10.046374     27.267228                13.799993               10.046374          27.267228            1       True          2\n",
      "6        LightGBMXT_BAG_L1    0.751597   0.740120     roc_auc       17.379151      12.898184     33.184407                17.379151               12.898184          33.184407            1       True          1\n",
      "7          CatBoost_BAG_L1    0.749038   0.740375     roc_auc        7.225188       1.554889   9442.448996                 7.225188                1.554889        9442.448996            1       True          5\n",
      "8   NeuralNetFastAI_BAG_L1    0.745892   0.739541     roc_auc       39.651538       4.337462    768.238619                39.651538                4.337462         768.238619            1       True          6\n",
      "9    NeuralNetTorch_BAG_L1    0.745269   0.738706     roc_auc       53.424053       8.909796    415.839366                53.424053                8.909796         415.839366            1       True          8\n",
      "\n",
      "ğŸ† Best Model: RandomForestEntr_BAG_L1\n",
      "ğŸ¯ Best CV AUC: 0.730583\n",
      "\n",
      "ğŸ“Š ì„±ì í‘œ:\n",
      "   03ë²ˆ (2ì‹œê°„):  0.7407 (LB: 0.742)\n",
      "   10ë²ˆ (6ì‹œê°„):  0.730583\n",
      "   Improvement:  +-0.010117\n",
      "\n",
      "ğŸ¯ ì˜ˆìƒ Public LB: 0.731883\n",
      "   (03ë²ˆì€ CV+0.0013 ìƒìŠ¹)\n",
      "\n",
      "ğŸ¤” 03ë²ˆê³¼ ë¹„ìŠ·... ê·¸ë˜ë„ ì œì¶œ ê°€ì¹˜ ìˆìŒ\n",
      "\n",
      "================================================================================\n",
      "Feature Importance\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t2043.38s\t= Expected runtime (408.68s per shuffle set)\n",
      "\t1196.76s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature importance saved\n",
      "\n",
      "=== Top 30 Features ===\n",
      "                  importance    stddev       p_value  n  p99_high   p99_low\n",
      "ì´ì‹ëœ ë°°ì•„ ìˆ˜            0.023687  0.004292  1.238673e-04  5  0.032523  0.014850\n",
      "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´            0.011249  0.003121  6.432862e-04  5  0.017674  0.004824\n",
      "ë‚˜ì´_3êµ¬ê°„              0.009877  0.003298  1.293740e-03  5  0.016668  0.003086\n",
      "ë°°ì•„_ì´ì‹_ë¹„ìœ¨            0.009632  0.002278  3.487698e-04  5  0.014322  0.004943\n",
      "ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼           0.008219  0.002099  4.688847e-04  5  0.012540  0.003897\n",
      "ë°°ì•„_ì €ì¥_ë¹„ìœ¨            0.007001  0.002539  1.755241e-03  5  0.012228  0.001774\n",
      "ì´ ìƒì„± ë°°ì•„ ìˆ˜           0.006774  0.002622  2.229175e-03  5  0.012173  0.001376\n",
      "ë‚˜ì´Ã—Day5             0.006565  0.001717  5.136822e-04  5  0.010100  0.003030\n",
      "ì‹œìˆ  ì‹œê¸° ì½”ë“œ            0.006348  0.000434  2.602829e-06  5  0.007241  0.005454\n",
      "ë°°ì•„_ìƒì„±_íš¨ìœ¨            0.006009  0.000752  2.879392e-05  5  0.007556  0.004461\n",
      "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜         0.005068  0.000696  4.154320e-05  5  0.006500  0.003635\n",
      "Day5_ì´ì‹_ì—¬ë¶€          0.003882  0.001186  9.270881e-04  5  0.006324  0.001440\n",
      "í˜¼í•©ëœ ë‚œì ìˆ˜            0.003738  0.000183  6.928378e-07  5  0.004115  0.003360\n",
      "ì €ì¥ëœ ë°°ì•„ ìˆ˜            0.003676  0.002234  1.060857e-02  5  0.008277 -0.000924\n",
      "íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜    0.003439  0.000075  2.730268e-08  5  0.003594  0.003285\n",
      "ì´ì‹ë°°ì•„_êµ¬ê°„             0.003412  0.001944  8.584453e-03  5  0.007414 -0.000590\n",
      "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜          0.003213  0.000468  5.249344e-05  5  0.004177  0.002250\n",
      "í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜       0.003100  0.000841  5.907323e-04  5  0.004832  0.001369\n",
      "IVF ì‹œìˆ  íšŸìˆ˜           0.002984  0.000732  4.018542e-04  5  0.004492  0.001477\n",
      "ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´             0.002844  0.001018  1.671748e-03  5  0.004939  0.000749\n",
      "ë°°ì•„_ì§„í–‰_ë‹¨ê³„            0.002566  0.001238  4.893227e-03  5  0.005115  0.000016\n",
      "ë‚œì ì¶œì²˜               0.002255  0.000676  8.623675e-04  5  0.003646  0.000863\n",
      "ì´ ì„ì‹  íšŸìˆ˜             0.002215  0.000755  1.398264e-03  5  0.003770  0.000660\n",
      "ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜     0.002185  0.000407  1.377018e-04  5  0.003023  0.001348\n",
      "ì´ ì‹œìˆ  íšŸìˆ˜             0.001889  0.000201  1.504150e-05  5  0.002302  0.001476\n",
      "ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€         0.001867  0.000563  8.823964e-04  5  0.003026  0.000708\n",
      "ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸       0.001859  0.000680  1.812001e-03  5  0.003259  0.000459\n",
      "íŠ¹ì • ì‹œìˆ  ìœ í˜•            0.001791  0.000327  1.278892e-04  5  0.002465  0.001118\n",
      "ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜       0.001531  0.000368  3.718181e-04  5  0.002289  0.000773\n",
      "ì´ ì¶œì‚° íšŸìˆ˜             0.001508  0.000441  7.833992e-04  5  0.002416  0.000601\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ Predictions\n",
      "================================================================================\n",
      "\n",
      "ì˜ˆì¸¡ê°’ í†µê³„:\n",
      "Min:  0.000210\n",
      "Max:  0.731375\n",
      "Mean: 0.258415\n",
      "Std:  0.158444\n",
      "\n",
      "âœ… Submission saved!\n",
      "   File: ../outputs/03.2_submission_hypermax_CV0.730583.csv\n",
      "âœ… Leaderboard saved: ../outputs/0.32_leaderboard.csv\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¥ 03.2ë²ˆ - í•˜ì´í¼íŒŒë¼ë¯¸í„° MAX íŠœë‹ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ì „ëµ: 03ë²ˆ Feature (ê²€ì¦ë¨) + ì‹œê°„ 3ë°° + ì„¤ì • ìµœëŒ€ ê°•í™”\n",
      "\n",
      "í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°•í™”:\n",
      "  - ì‹œê°„: 2ì‹œê°„ â†’ 6ì‹œê°„ (3ë°°)\n",
      "  - Bagging: folds 5â†’10, sets 1â†’3\n",
      "  - Stacking: levels 1â†’3\n",
      "  - ëª¨ë¸: GBM, CAT, XGB, NN, RF ì „ë¶€ ê°•í™”\n",
      "\n",
      "Best Model: RandomForestEntr_BAG_L1\n",
      "CV AUC: 0.730583\n",
      "\n",
      "ì„±ì  ë¹„êµ:\n",
      "  03ë²ˆ (2ì‹œê°„):    0.7407 (LB: 0.7420)\n",
      "  10ë²ˆ (6ì‹œê°„):    0.730583\n",
      "\n",
      "Improvement: +-0.010117\n",
      "\n",
      "ì˜ˆìƒ Public LB: 0.731883\n",
      "  (03ë²ˆ ê¸°ì¤€ CV + 0.0013)\n",
      "\n",
      "================================================================================\n",
      "í˜„ì¬ ìˆœìœ„:\n",
      "  1ë“±: 0.74209\n",
      "  ë‚˜:  0.74200 (5ë“±)\n",
      "\n",
      "10ë²ˆ ì˜ˆìƒ:\n",
      "  ìƒìœ„ê¶Œ ìœ ì§€ (LB 0.73188)\n",
      "\n",
      "================================================================================\n",
      "ì´ ëª¨ë¸ ìˆ˜: 10\n",
      "\n",
      "Top 5 Models:\n",
      "  1. RandomForestEntr_BAG_L1: 0.730583\n",
      "  2. RandomForestGini_BAG_L1: 0.729776\n",
      "  3. LightGBMLarge_BAG_L1: 0.739109\n",
      "  4. WeightedEnsemble_L2: 0.740810\n",
      "  5. XGBoost_BAG_L1: 0.739630\n",
      "================================================================================\n",
      "\n",
      "âœ… Summary saved: ../outputs/10_summary.txt\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ 10ë²ˆ COMPLETE! ğŸ”¥ğŸ”¥ğŸ”¥\n",
      "================================================================================\n",
      "\n",
      "ìµœì¢… ì²´í¬:\n",
      "  âœ… CV AUC: 0.730583\n",
      "  âœ… ì˜ˆìƒ LB: 0.731883\n",
      "  âœ… Submission: ../outputs/03.2_submission_hypermax_CV0.730583.csv\n",
      "\n",
      "â†’ ë°”ë¡œ ì œì¶œí•˜ì„¸ìš”! 1ë“± ê°€ëŠ¥ì„± ë†’ìŒ! ğŸ†\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# 0) Load\n",
    "# ============================================================\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "TEST_PATH  = \"../data/test.csv\"\n",
    "SUB_PATH   = \"../data/sample_submission.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "sub   = pd.read_csv(SUB_PATH)\n",
    "\n",
    "TARGET_COL = \"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"\n",
    "ID_COL = \"ID\"\n",
    "\n",
    "print(f\"\\nTrain shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 1) Feature Engineering (03ë²ˆê³¼ ì™„ì „ ë™ì¼!)\n",
    "# ============================================================\n",
    "\n",
    "# ê³ ê²°ì¸¡ ë³€ìˆ˜ ì œê±°\n",
    "HIGH_MISSING_COLS = [\n",
    "    'ë‚œì í•´ë™ ê²½ê³¼ì¼',           # 99.4%\n",
    "    'PGS ì‹œìˆ  ì—¬ë¶€',             # 99.2%\n",
    "    'PGD ì‹œìˆ  ì—¬ë¶€',             # 99.1%\n",
    "    'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', # 98.9%\n",
    "    'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜',  # 96.3%\n",
    "]\n",
    "\n",
    "EMBRYO_STAGE_COLS = [\n",
    "    \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\",\"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\",\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "    \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\",\"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ ë‚œì ìˆ˜\",\n",
    "    \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "]\n",
    "\n",
    "INFERTILITY_COLS = [\n",
    "    \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\",\"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\",\"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\",\"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\",\"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\",\"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"\n",
    "]\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ê³ ê²°ì¸¡ ì œê±°\n",
    "    df = df.drop(columns=HIGH_MISSING_COLS, errors='ignore')\n",
    "    \n",
    "    # ì‹œìˆ _ëŒ€ë¶„ë¥˜\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        x = str(x)\n",
    "        if \"IUI\" in x: return \"IUI\"\n",
    "        if \"ICSI\" in x: return \"ICSI\"\n",
    "        if \"IVF\" in x: return \"IVF\"\n",
    "        if \"DI\" in x: return \"DI\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df[\"ì‹œìˆ _ëŒ€ë¶„ë¥˜\"] = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(major_procedure)\n",
    "    \n",
    "    # BLASTOCYST_í¬í•¨\n",
    "    s = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].astype(\"object\").fillna(\"Unknown\").astype(str)\n",
    "    df[\"BLASTOCYST_í¬í•¨\"] = s.str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    \n",
    "    # ë°°ì•„_ì´ì‹_ì—¬ë¶€\n",
    "    df[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"] = df[EMBRYO_STAGE_COLS].isna().all(axis=1).astype(int)\n",
    "    df[\"ë°°ì•„_ì´ì‹_ì—¬ë¶€\"] = 1 - df[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"]\n",
    "    \n",
    "    # ë°°ì•„_ì§„í–‰_ë‹¨ê³„\n",
    "    def embryo_stage(row):\n",
    "        if row['ë°°ì•„_ì´ì‹_ì—¬ë¶€'] == 0:\n",
    "            return 'ë°°ì•„ë‹¨ê³„_ë¯¸ë„ë‹¬'\n",
    "        elif pd.isna(row['ì´ ìƒì„± ë°°ì•„ ìˆ˜']) or row['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] == 0:\n",
    "            return 'ë°°ì•„ìƒì„±_ì‹¤íŒ¨'\n",
    "        elif pd.isna(row['ì´ì‹ëœ ë°°ì•„ ìˆ˜']) or row['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] == 0:\n",
    "            return 'ì´ì‹_ë¯¸ì‹¤ì‹œ'\n",
    "        else:\n",
    "            return 'ì´ì‹_ì™„ë£Œ'\n",
    "    \n",
    "    df['ë°°ì•„_ì§„í–‰_ë‹¨ê³„'] = df.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    # ì´ì‹œìˆ _bin3\n",
    "    def collapse_trials(x):\n",
    "        if x == '0íšŒ': return '0íšŒ'\n",
    "        elif x in ['1íšŒ', '2íšŒ']: return '1-2íšŒ'\n",
    "        else: return '3íšŒ ì´ìƒ'\n",
    "    \n",
    "    df[\"ì´ì‹œìˆ _bin3\"] = df[\"ì´ ì‹œìˆ  íšŸìˆ˜\"].apply(collapse_trials)\n",
    "    \n",
    "    # ë‚˜ì´_3êµ¬ê°„\n",
    "    def age_group_simple(age):\n",
    "        if age == 'ì•Œ ìˆ˜ ì—†ìŒ': return 'Unknown'\n",
    "        elif age == 'ë§Œ18-34ì„¸': return '34ì„¸ ì´í•˜'\n",
    "        elif age in ['ë§Œ35-37ì„¸', 'ë§Œ38-39ì„¸']: return '35-39ì„¸'\n",
    "        else: return '40ì„¸ ì´ìƒ'\n",
    "    \n",
    "    df['ë‚˜ì´_3êµ¬ê°„'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].apply(age_group_simple)\n",
    "    \n",
    "    # ì´ì‹ë°°ì•„_êµ¬ê°„\n",
    "    def embryo_count_bin(count):\n",
    "        if pd.isna(count) or count == 0: return '0ê°œ'\n",
    "        elif count <= 2: return '1-2ê°œ'\n",
    "        else: return '3ê°œ ì´ìƒ'\n",
    "    \n",
    "    df['ì´ì‹ë°°ì•„_êµ¬ê°„'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].apply(embryo_count_bin)\n",
    "    \n",
    "    # Day5_ì´ì‹_ì—¬ë¶€\n",
    "    df['Day5_ì´ì‹_ì—¬ë¶€'] = (df['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'] == 5.0).astype(int)\n",
    "    \n",
    "    # ë¶ˆì„ì›ì¸_ë³µì¡ë„\n",
    "    df[\"ë¶ˆì„_ì›ì¸_ê°œìˆ˜\"] = df[INFERTILITY_COLS].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df['ë¶ˆì„ì›ì¸_ë³µì¡ë„'] = df['ë¶ˆì„_ì›ì¸_ê°œìˆ˜'].apply(infertility_complexity)\n",
    "    \n",
    "    # ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€\n",
    "    df['ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€'] = df['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].notna().astype(int)\n",
    "    \n",
    "    # ë¹„ìœ¨ ë³€ìˆ˜\n",
    "    df['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)\n",
    "    df['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    df['ë°°ì•„_ì €ì¥_ë¹„ìœ¨'] = df['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    \n",
    "    # êµí˜¸ì‘ìš©\n",
    "    df['ë‚˜ì´Ã—Day5'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].astype(str) + '_' + df['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    df['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´'] = df['ì´ì‹œìˆ _bin3'] + '_' + df['ë‚˜ì´_3êµ¬ê°„']\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"\\nì „ì²˜ë¦¬ ì¤‘...\")\n",
    "train_df = preprocess(train)\n",
    "test_df = preprocess(test)\n",
    "\n",
    "print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ (03ë²ˆê³¼ ë™ì¼)\")\n",
    "print(f\"   Train: {train_df.shape}\")\n",
    "print(f\"   Test: {test_df.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2) ë°ì´í„° ì¤€ë¹„\n",
    "# ============================================================\n",
    "train_data = train_df.drop(columns=[ID_COL, 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "test_data = test_df.drop(columns=[ID_COL, 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "\n",
    "print(f\"\\nìµœì¢… Feature ê°œìˆ˜: {len(train_data.columns) - 1}ê°œ\")\n",
    "print(f\"\\nTarget ë¶„í¬:\")\n",
    "print(train_data[TARGET_COL].value_counts(normalize=True))\n",
    "\n",
    "# ============================================================\n",
    "# ğŸ”¥ 3) AutoGluon ìµœëŒ€ ê°•í™”! ğŸ”¥\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ AutoGluon MAX POWER Training!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâ° ì†Œìš” ì‹œê°„: 6ì‹œê°„ (03ë²ˆì˜ 3ë°°!)\")\n",
    "print(\"ğŸ’¾ ë©”ëª¨ë¦¬: 8-16GB\")\n",
    "print(\"ğŸ¯ ëª©í‘œ CV: 0.745+\")\n",
    "print(\"\\nê°•í™” í¬ì¸íŠ¸:\")\n",
    "print(\"  1. ì‹œê°„: 2ì‹œê°„ â†’ 6ì‹œê°„ (3ë°°)\")\n",
    "print(\"  2. Bagging: folds 5â†’10, sets 1â†’3\")\n",
    "print(\"  3. Stacking: levels 1â†’3 (ê¹Šì€ ì•™ìƒë¸”)\")\n",
    "print(\"  4. í•˜ì´í¼íŒŒë¼ë¯¸í„°: ê° ëª¨ë¸ ìµœëŒ€ ê°•í™”\")\n",
    "print(\"\\ní•™ìŠµ ì‹œì‘...\\n\")\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=TARGET_COL,\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='../outputs/autogluon_10_hypermax'\n",
    ")\n",
    "\n",
    "# ğŸ”¥ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœëŒ€ ê°•í™”\n",
    "hyperparameters = {\n",
    "    'GBM': [\n",
    "        {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
    "        {},\n",
    "        'GBMLarge',\n",
    "    ],\n",
    "    'CAT': {},\n",
    "    'XGB': {},\n",
    "    'FASTAI': {},\n",
    "    'NN_TORCH': {},\n",
    "    'RF': [\n",
    "        {'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}},\n",
    "        {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}},\n",
    "    ],\n",
    "}\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=21600,        # ğŸ”¥ 6ì‹œê°„! (ê¸°ì¡´ 2ì‹œê°„)\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=10,        # ğŸ”¥ 5â†’10 (ë” ì•ˆì •ì )\n",
    "    num_bag_sets=3,          # ğŸ”¥ 1â†’3 (ë” ë‹¤ì–‘)\n",
    "    num_stack_levels=3,      # ğŸ”¥ 1â†’3 (ë” ê¹Šì€ ìŠ¤íƒœí‚¹)\n",
    "    hyperparameters=hyperparameters,\n",
    "    auto_stack=True,\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4) ê²°ê³¼ í™•ì¸\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "leaderboard = predictor.leaderboard(train_data, silent=True)\n",
    "print(\"\\n=== Model Leaderboard (Top 30) ===\")\n",
    "print(leaderboard.head(30).to_string())\n",
    "\n",
    "best_model = leaderboard.iloc[0]['model']\n",
    "best_score = leaderboard.iloc[0]['score_val']\n",
    "\n",
    "print(f\"\\nğŸ† Best Model: {best_model}\")\n",
    "print(f\"ğŸ¯ Best CV AUC: {best_score:.6f}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì„±ì í‘œ:\")\n",
    "print(f\"   03ë²ˆ (2ì‹œê°„):  0.7407 (LB: 0.742)\")\n",
    "print(f\"   10ë²ˆ (6ì‹œê°„):  {best_score:.6f}\")\n",
    "print(f\"   Improvement:  +{best_score - 0.7407:.6f}\")\n",
    "\n",
    "# ì˜ˆìƒ LB\n",
    "expected_lb = best_score + 0.0013  # 03ë²ˆ ê¸°ì¤€\n",
    "print(f\"\\nğŸ¯ ì˜ˆìƒ Public LB: {expected_lb:.6f}\")\n",
    "print(f\"   (03ë²ˆì€ CV+0.0013 ìƒìŠ¹)\")\n",
    "\n",
    "if best_score >= 0.7450:\n",
    "    print(\"\\nğŸ‰ğŸ‰ğŸ‰ ëŒ€ë°•! 1ë“± ê±°ì˜ í™•ì •! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "    print(f\"   ì˜ˆìƒ LB {expected_lb:.5f} > í˜„ì¬ 1ë“± 0.74209\")\n",
    "elif best_score >= 0.7425:\n",
    "    print(\"\\nğŸ˜ŠğŸ˜Š ëŒ€ì„±ê³µ! ìƒìœ„ê¶Œ í™•ì •!\")\n",
    "elif best_score >= 0.7415:\n",
    "    print(\"\\nâœ… ì¢‹ì€ ì„±ì ! ì œì¶œ ê°•ë ¥ ì¶”ì²œ!\")\n",
    "elif best_score > 0.7407:\n",
    "    print(\"\\nğŸ‘ 03ë²ˆë³´ë‹¤ ë†’ìŒ! ì œì¶œ ê³ ë ¤!\")\n",
    "else:\n",
    "    print(\"\\nğŸ¤” 03ë²ˆê³¼ ë¹„ìŠ·... ê·¸ë˜ë„ ì œì¶œ ê°€ì¹˜ ìˆìŒ\")\n",
    "\n",
    "# ============================================================\n",
    "# 5) Feature Importance\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Feature Importance\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    importance = predictor.feature_importance(train_data)\n",
    "    importance.to_csv(\"../outputs/03.2_feature_importance.csv\")\n",
    "    print(\"âœ… Feature importance saved\")\n",
    "    print(\"\\n=== Top 30 Features ===\")\n",
    "    print(importance.head(30).to_string())\n",
    "except:\n",
    "    print(\"âš ï¸ Feature importance not available\")\n",
    "\n",
    "# ============================================================\n",
    "# 6) ì˜ˆì¸¡ ë° Submission\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_predictions = predictor.predict_proba(test_data)\n",
    "\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    test_proba = test_predictions[1].values\n",
    "else:\n",
    "    test_proba = test_predictions\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ê°’ í†µê³„:\")\n",
    "print(f\"Min:  {test_proba.min():.6f}\")\n",
    "print(f\"Max:  {test_proba.max():.6f}\")\n",
    "print(f\"Mean: {test_proba.mean():.6f}\")\n",
    "print(f\"Std:  {test_proba.std():.6f}\")\n",
    "\n",
    "# Submission\n",
    "sub['probability'] = test_proba\n",
    "output_file = f\"../outputs/03.2_submission_hypermax_CV{best_score:.6f}.csv\"\n",
    "sub.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Submission saved!\")\n",
    "print(f\"   File: {output_file}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) ìƒì„¸ ì •ë³´ ì €ì¥\n",
    "# ============================================================\n",
    "leaderboard.to_csv(\"../outputs/03.2_leaderboard.csv\", index=False)\n",
    "print(\"âœ… Leaderboard saved: ../outputs/0.32_leaderboard.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# 8) ìµœì¢… ìš”ì•½\n",
    "# ============================================================\n",
    "summary = f\"\"\"\n",
    "{'='*80}\n",
    "ğŸ”¥ 03.2ë²ˆ - í•˜ì´í¼íŒŒë¼ë¯¸í„° MAX íŠœë‹ ê²°ê³¼\n",
    "{'='*80}\n",
    "\n",
    "ì „ëµ: 03ë²ˆ Feature (ê²€ì¦ë¨) + ì‹œê°„ 3ë°° + ì„¤ì • ìµœëŒ€ ê°•í™”\n",
    "\n",
    "í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°•í™”:\n",
    "  - ì‹œê°„: 2ì‹œê°„ â†’ 6ì‹œê°„ (3ë°°)\n",
    "  - Bagging: folds 5â†’10, sets 1â†’3\n",
    "  - Stacking: levels 1â†’3\n",
    "  - ëª¨ë¸: GBM, CAT, XGB, NN, RF ì „ë¶€ ê°•í™”\n",
    "\n",
    "Best Model: {best_model}\n",
    "CV AUC: {best_score:.6f}\n",
    "\n",
    "ì„±ì  ë¹„êµ:\n",
    "  03ë²ˆ (2ì‹œê°„):    0.7407 (LB: 0.7420)\n",
    "  10ë²ˆ (6ì‹œê°„):    {best_score:.6f}\n",
    "  \n",
    "Improvement: +{best_score - 0.7407:.6f}\n",
    "\n",
    "ì˜ˆìƒ Public LB: {expected_lb:.6f}\n",
    "  (03ë²ˆ ê¸°ì¤€ CV + 0.0013)\n",
    "\n",
    "{'='*80}\n",
    "í˜„ì¬ ìˆœìœ„:\n",
    "  1ë“±: 0.74209\n",
    "  ë‚˜:  0.74200 (5ë“±)\n",
    "  \n",
    "10ë²ˆ ì˜ˆìƒ:\n",
    "\"\"\"\n",
    "\n",
    "if expected_lb >= 0.74209:\n",
    "    summary += f\"  ğŸ† 1ë“± ì˜ˆìƒ! (LB {expected_lb:.5f})\\n\"\n",
    "elif expected_lb >= 0.74150:\n",
    "    summary += f\"  ğŸ¥ˆ ìƒìœ„ê¶Œ ì˜ˆìƒ (LB {expected_lb:.5f})\\n\"\n",
    "else:\n",
    "    summary += f\"  ìƒìœ„ê¶Œ ìœ ì§€ (LB {expected_lb:.5f})\\n\"\n",
    "\n",
    "summary += f\"\"\"\n",
    "{'='*80}\n",
    "ì´ ëª¨ë¸ ìˆ˜: {len(leaderboard)}\n",
    "\n",
    "Top 5 Models:\n",
    "\"\"\"\n",
    "\n",
    "for i in range(min(5, len(leaderboard))):\n",
    "    summary += f\"  {i+1}. {leaderboard.iloc[i]['model']}: {leaderboard.iloc[i]['score_val']:.6f}\\n\"\n",
    "\n",
    "summary += \"=\"*80\n",
    "\n",
    "print(\"\\n\" + summary)\n",
    "\n",
    "with open(\"../outputs/03.2_summary.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\nâœ… Summary saved: ../outputs/10_summary.txt\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ”¥ğŸ”¥ğŸ”¥ 10ë²ˆ COMPLETE! ğŸ”¥ğŸ”¥ğŸ”¥\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nìµœì¢… ì²´í¬:\")\n",
    "print(f\"  âœ… CV AUC: {best_score:.6f}\")\n",
    "print(f\"  âœ… ì˜ˆìƒ LB: {expected_lb:.6f}\")\n",
    "print(f\"  âœ… Submission: {output_file}\")\n",
    "print(\"\\nâ†’ ë°”ë¡œ ì œì¶œí•˜ì„¸ìš”! 1ë“± ê°€ëŠ¥ì„± ë†’ìŒ! ğŸ†\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b081f425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "03.2ë²ˆ ìˆ˜ì • - WeightedEnsemble_L2ë¡œ ì¬ì œì¶œ\n",
      "================================================================================\n",
      "\n",
      "=== Leaderboard ì»¬ëŸ¼ í™•ì¸ ===\n",
      "['model', 'score_val', 'eval_metric', 'pred_time_val', 'fit_time', 'pred_time_val_marginal', 'fit_time_marginal', 'stack_level', 'can_infer', 'fit_order']\n",
      "\n",
      "=== Top 10 Models (score_val ê¸°ì¤€) ===\n",
      "                     model  score_val\n",
      "0      WeightedEnsemble_L2   0.740810\n",
      "1          CatBoost_BAG_L1   0.740375\n",
      "2        LightGBMXT_BAG_L1   0.740120\n",
      "3          LightGBM_BAG_L1   0.739933\n",
      "4           XGBoost_BAG_L1   0.739630\n",
      "5   NeuralNetFastAI_BAG_L1   0.739541\n",
      "6     LightGBMLarge_BAG_L1   0.739109\n",
      "7    NeuralNetTorch_BAG_L1   0.738706\n",
      "8  RandomForestEntr_BAG_L1   0.730583\n",
      "9  RandomForestGini_BAG_L1   0.729776\n",
      "\n",
      "ì§„ì§œ Best Model: WeightedEnsemble_L2\n",
      "ì§„ì§œ CV AUC: 0.740810\n",
      "\n",
      "ì„±ì í‘œ:\n",
      "   03ë²ˆ: 0.7407\n",
      "   10ë²ˆ: 0.740810\n",
      "   Improvement: +0.000110\n",
      "\n",
      "ì˜ˆì¸¡ ì¤‘...\n",
      "\n",
      "ì˜ˆì¸¡ê°’ í†µê³„:\n",
      "Min:  0.000210\n",
      "Max:  0.731375\n",
      "Mean: 0.258415\n",
      "\n",
      "âœ… ìˆ˜ì •ëœ Submission ì €ì¥!\n",
      "   Model: WeightedEnsemble_L2\n",
      "   CV: 0.740810\n",
      "   File: ../outputs/10_FIXED_submission_CV0.740810.csv\n",
      "\n",
      "ğŸ¯ ì˜ˆìƒ LB: 0.742110\n",
      "   í˜„ì¬ 1ë“±: 0.74209\n",
      "\n",
      "ğŸ† 1ë“± ê°€ëŠ¥!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 03.2ë²ˆ ê²°ê³¼ ìˆ˜ì • - WeightedEnsemble_L2ë¡œ ì¬ì œì¶œ\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"03.2ë²ˆ ìˆ˜ì • - WeightedEnsemble_L2ë¡œ ì¬ì œì¶œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. ì €ì¥ëœ predictor ë¡œë“œ\n",
    "predictor = TabularPredictor.load('../outputs/autogluon_10_hypermax/')\n",
    "\n",
    "# 2. Leaderboard score_valë¡œ ì •ë ¬\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "\n",
    "print(\"\\n=== Leaderboard ì»¬ëŸ¼ í™•ì¸ ===\")\n",
    "print(leaderboard.columns.tolist())\n",
    "\n",
    "# score_valë¡œ ì •ë ¬\n",
    "leaderboard_sorted = leaderboard.sort_values('score_val', ascending=False)\n",
    "\n",
    "print(\"\\n=== Top 10 Models (score_val ê¸°ì¤€) ===\")\n",
    "print(leaderboard_sorted.head(10)[['model', 'score_val']])\n",
    "\n",
    "# 3. ì§„ì§œ Best Model\n",
    "best_model = leaderboard_sorted.iloc[0]['model']\n",
    "best_score = leaderboard_sorted.iloc[0]['score_val']\n",
    "\n",
    "print(f\"\\nì§„ì§œ Best Model: {best_model}\")\n",
    "print(f\"ì§„ì§œ CV AUC: {best_score:.6f}\")\n",
    "print(f\"\\nì„±ì í‘œ:\")\n",
    "print(f\"   03ë²ˆ: 0.7407\")\n",
    "print(f\"   10ë²ˆ: {best_score:.6f}\")\n",
    "print(f\"   Improvement: +{best_score - 0.7407:.6f}\")\n",
    "\n",
    "# 4. Test ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# ì „ì²˜ë¦¬ (03ë²ˆê³¼ ë™ì¼)\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ê³ ê²°ì¸¡ ì œê±°\n",
    "    HIGH_MISSING_COLS = [\n",
    "        'ë‚œì í•´ë™ ê²½ê³¼ì¼', 'PGS ì‹œìˆ  ì—¬ë¶€', 'PGD ì‹œìˆ  ì—¬ë¶€',\n",
    "        'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜'\n",
    "    ]\n",
    "    df = df.drop(columns=HIGH_MISSING_COLS, errors='ignore')\n",
    "    \n",
    "    EMBRYO_STAGE_COLS = [\n",
    "        \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\",\"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\",\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "        \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\",\"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\",\"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\",\"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ëœ ë°°ì•„ ìˆ˜\",\"í•´ë™ ë‚œì ìˆ˜\",\n",
    "        \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\",\"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "    ]\n",
    "    \n",
    "    INFERTILITY_COLS = [\n",
    "        \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "        \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\",\"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\",\"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\",\"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\",\"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\",\"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\",\"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"\n",
    "    ]\n",
    "    \n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        x = str(x)\n",
    "        if \"IUI\" in x: return \"IUI\"\n",
    "        if \"ICSI\" in x: return \"ICSI\"\n",
    "        if \"IVF\" in x: return \"IVF\"\n",
    "        if \"DI\" in x: return \"DI\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df[\"ì‹œìˆ _ëŒ€ë¶„ë¥˜\"] = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(major_procedure)\n",
    "    \n",
    "    s = df[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].astype(\"object\").fillna(\"Unknown\").astype(str)\n",
    "    df[\"BLASTOCYST_í¬í•¨\"] = s.str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    \n",
    "    df[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"] = df[EMBRYO_STAGE_COLS].isna().all(axis=1).astype(int)\n",
    "    df[\"ë°°ì•„_ì´ì‹_ì—¬ë¶€\"] = 1 - df[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"]\n",
    "    \n",
    "    def embryo_stage(row):\n",
    "        if row['ë°°ì•„_ì´ì‹_ì—¬ë¶€'] == 0:\n",
    "            return 'ë°°ì•„ë‹¨ê³„_ë¯¸ë„ë‹¬'\n",
    "        elif pd.isna(row.get('ì´ ìƒì„± ë°°ì•„ ìˆ˜')) or row.get('ì´ ìƒì„± ë°°ì•„ ìˆ˜') == 0:\n",
    "            return 'ë°°ì•„ìƒì„±_ì‹¤íŒ¨'\n",
    "        elif pd.isna(row.get('ì´ì‹ëœ ë°°ì•„ ìˆ˜')) or row.get('ì´ì‹ëœ ë°°ì•„ ìˆ˜') == 0:\n",
    "            return 'ì´ì‹_ë¯¸ì‹¤ì‹œ'\n",
    "        else:\n",
    "            return 'ì´ì‹_ì™„ë£Œ'\n",
    "    \n",
    "    df['ë°°ì•„_ì§„í–‰_ë‹¨ê³„'] = df.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    def collapse_trials(x):\n",
    "        if x == '0íšŒ': return '0íšŒ'\n",
    "        elif x in ['1íšŒ', '2íšŒ']: return '1-2íšŒ'\n",
    "        else: return '3íšŒ ì´ìƒ'\n",
    "    \n",
    "    df[\"ì´ì‹œìˆ _bin3\"] = df[\"ì´ ì‹œìˆ  íšŸìˆ˜\"].apply(collapse_trials)\n",
    "    \n",
    "    def age_group_simple(age):\n",
    "        if age == 'ì•Œ ìˆ˜ ì—†ìŒ': return 'Unknown'\n",
    "        elif age == 'ë§Œ18-34ì„¸': return '34ì„¸ ì´í•˜'\n",
    "        elif age in ['ë§Œ35-37ì„¸', 'ë§Œ38-39ì„¸']: return '35-39ì„¸'\n",
    "        else: return '40ì„¸ ì´ìƒ'\n",
    "    \n",
    "    df['ë‚˜ì´_3êµ¬ê°„'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].apply(age_group_simple)\n",
    "    \n",
    "    def embryo_count_bin(count):\n",
    "        if pd.isna(count) or count == 0: return '0ê°œ'\n",
    "        elif count <= 2: return '1-2ê°œ'\n",
    "        else: return '3ê°œ ì´ìƒ'\n",
    "    \n",
    "    df['ì´ì‹ë°°ì•„_êµ¬ê°„'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].apply(embryo_count_bin)\n",
    "    df['Day5_ì´ì‹_ì—¬ë¶€'] = (df['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'] == 5.0).astype(int)\n",
    "    df[\"ë¶ˆì„_ì›ì¸_ê°œìˆ˜\"] = df[INFERTILITY_COLS].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0: return 'None'\n",
    "        elif count == 1: return 'Single'\n",
    "        elif count == 2: return 'Double'\n",
    "        else: return 'Multiple'\n",
    "    \n",
    "    df['ë¶ˆì„ì›ì¸_ë³µì¡ë„'] = df['ë¶ˆì„_ì›ì¸_ê°œìˆ˜'].apply(infertility_complexity)\n",
    "    df['ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€'] = df['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].notna().astype(int)\n",
    "    df['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)\n",
    "    df['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    df['ë°°ì•„_ì €ì¥_ë¹„ìœ¨'] = df['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    df['ë‚˜ì´Ã—Day5'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].astype(str) + '_' + df['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    df['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´'] = df['ì´ì‹œìˆ _bin3'] + '_' + df['ë‚˜ì´_3êµ¬ê°„']\n",
    "    \n",
    "    return df\n",
    "\n",
    "test_df = preprocess(test_df)\n",
    "test_data = test_df.drop(columns=['ID', 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "\n",
    "# 5. ì˜ˆì¸¡\n",
    "print(\"\\nì˜ˆì¸¡ ì¤‘...\")\n",
    "test_predictions = predictor.predict_proba(test_data, model=best_model)\n",
    "\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    test_proba = test_predictions[1].values\n",
    "else:\n",
    "    test_proba = test_predictions\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ê°’ í†µê³„:\")\n",
    "print(f\"Min:  {test_proba.min():.6f}\")\n",
    "print(f\"Max:  {test_proba.max():.6f}\")\n",
    "print(f\"Mean: {test_proba.mean():.6f}\")\n",
    "\n",
    "# 6. Submission\n",
    "sub = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "sub['probability'] = test_proba\n",
    "\n",
    "output_file = f\"../outputs/10_FIXED_submission_CV{best_score:.6f}.csv\"\n",
    "sub.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… ìˆ˜ì •ëœ Submission ì €ì¥!\")\n",
    "print(f\"   Model: {best_model}\")\n",
    "print(f\"   CV: {best_score:.6f}\")\n",
    "print(f\"   File: {output_file}\")\n",
    "\n",
    "expected_lb = best_score + 0.0013\n",
    "print(f\"\\nğŸ¯ ì˜ˆìƒ LB: {expected_lb:.6f}\")\n",
    "print(f\"   í˜„ì¬ 1ë“±: 0.74209\")\n",
    "\n",
    "if expected_lb >= 0.74209:\n",
    "    print(\"\\nğŸ† 1ë“± ê°€ëŠ¥!\")\n",
    "else:\n",
    "    print(\"\\nğŸ˜Š ìƒìœ„ê¶Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500006e6",
   "metadata": {},
   "source": [
    "### 03.3 Seed 123ìœ¼ë¡œ ë°”ê¿”ì„œ test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81950df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "03.3ë²ˆ - Random Seed 123 ë²„ì „\n",
      "================================================================================\n",
      "ì „ëµ: 03ë²ˆ ì™„ì „ ë™ì¼ + Seedë§Œ 123ìœ¼ë¡œ ë³€ê²½\n",
      "================================================================================\n",
      "\n",
      "Train shape: (256351, 69)\n",
      "Test shape: (90067, 68)\n",
      "\n",
      "ì „ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../outputs/autogluon_seed123_v2\"\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 7200 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: ../outputs/autogluon_seed123_v2/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ í›„ Train shape: (256351, 86)\n",
      "ì „ì²˜ë¦¬ í›„ Test shape: (90067, 85)\n",
      "\n",
      "Final Train shape: (256351, 84)\n",
      "Target distribution:\n",
      "ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "0    0.741651\n",
      "1    0.258349\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "AutoGluon Training - Random Seed 123\n",
      "================================================================================\n",
      "\n",
      "ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2ì‹œê°„\n",
      "Random Seed: 123 (03ë²ˆì€ 42)\n",
      "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 4-8GB\n",
      "\n",
      "í•™ìŠµ ì‹œì‘...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 47 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 7153 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 7153s\n",
      "AutoGluon will save models to \"../outputs/autogluon_seed123_v2\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       3.46 GB / 16.00 GB (21.6%)\n",
      "Disk Space Avail:   202.38 GB / 460.43 GB (44.0%)\n",
      "===================================================\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 83\n",
      "Label Column:       ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4043.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 752.52 MB (18.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 18.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 26 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 32 | ['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])    : 17 | ['ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t\t('object', []) : 28 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ì‹œìˆ  ìœ í˜•', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 27 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', 'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ', ...]\n",
      "\t\t('float', [])     : 28 | ['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', ...]\n",
      "\t\t('int', [])       :  1 | ['ë¶ˆì„_ì›ì¸_ê°œìˆ˜']\n",
      "\t\t('int', ['bool']) : 21 | ['ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìê·¹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t2.7s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 68.46 MB (1.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': {'seed': 123},\n",
      "\t'CAT': {'random_seed': 123},\n",
      "\t'XGB': {'seed': 123},\n",
      "\t'NN_TORCH': {'seed': 123},\n",
      "\t'FASTAI': {'seed': 123},\n",
      "\t'RF': {'random_state': 123},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4765.4s of the 7149.89s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 4764.93s of the 7149.42s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 223 due to low memory. Expected memory usage reduced from 20.13% -> 15.0% of available memory...\n",
      "\t0.73\t = Validation score   (roc_auc)\n",
      "\t11.95s\t = Training   runtime\n",
      "\t6.0s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4746.55s of the 7131.04s of remaining time.\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4746.17s of the 7130.66s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.23% memory usage per fold, 42.46%/80.00% total).\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4745.78s of the 7130.27s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.24% memory usage per fold, 68.96%/80.00% total).\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4745.38s of the 7129.87s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 476.54s of the 7129.48s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForest_BAG_L1': 1.0}\n",
      "\t0.73\t = Validation score   (roc_auc)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting 6 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 7129.37s of the 7129.36s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 7128.95s of the 7128.94s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 249 due to low memory. Expected memory usage reduced from 18.05% -> 15.0% of available memory...\n",
      "\t0.7435\t = Validation score   (roc_auc)\n",
      "\t12.92s\t = Training   runtime\n",
      "\t6.74s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 7108.79s of the 7108.78s of remaining time.\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 7108.24s of the 7108.23s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.48% memory usage per fold, 42.96%/80.00% total).\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 7107.85s of the 7107.84s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.54% memory usage per fold, 70.17%/80.00% total).\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 7107.45s of the 7107.44s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 693, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 483, in __init__\n",
      "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 778, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/fertility_ai/lib/python3.11/site-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 712.94s of the 7107.02s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForest_BAG_L2': 1.0}\n",
      "\t0.7435\t = Validation score   (roc_auc)\n",
      "\t2.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 48.23s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../outputs/autogluon_seed123_v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Results\n",
      "================================================================================\n",
      "\n",
      "=== Model Leaderboard (Top 15, score_val ê¸°ì¤€) ===\n",
      "                 model  score_val\n",
      "2  RandomForest_BAG_L2   0.743485\n",
      "3  WeightedEnsemble_L3   0.743485\n",
      "0  RandomForest_BAG_L1   0.729995\n",
      "1  WeightedEnsemble_L2   0.729995\n",
      "\n",
      "ğŸ† Best Model: RandomForest_BAG_L2\n",
      "ğŸ¯ Best CV AUC: 0.743485\n",
      "\n",
      "================================================================================\n",
      "Predictions\n",
      "================================================================================\n",
      "\n",
      "ì˜ˆì¸¡ê°’ í†µê³„:\n",
      "Min:  0.000754\n",
      "Max:  0.789891\n",
      "Mean: 0.257188\n",
      "\n",
      "Submission saved!\n",
      "   File: ../outputs/03.3_seed123_CV0.743485.csv\n",
      "   Model: RandomForest_BAG_L2\n",
      "   Seed: 123\n",
      "Leaderboard saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "Computing feature importance via permutation shuffling for 77 features using 5000 rows with 5 shuffle sets...\n",
      "\t211.65s\t= Expected runtime (42.33s per shuffle set)\n",
      "\t34.8s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance saved\n",
      "\n",
      "\n",
      "================================================================================\n",
      "03.3ë²ˆ - Random Seed 123 ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ì „ëµ: 03ë²ˆ ì™„ì „ ë™ì¼ + Random Seedë§Œ 123ìœ¼ë¡œ ë³€ê²½\n",
      "\n",
      "Best Model: RandomForest_BAG_L2\n",
      "CV AUC: 0.743485\n",
      "\n",
      "ì„±ì  ë¹„êµ:\n",
      "  03ë²ˆ (Seed 42):  0.7407 (LB: 0.7420)\n",
      "  11ë²ˆ (Seed 123): 0.743485\n",
      "\n",
      "ì°¨ì´: +0.002785\n",
      "\n",
      "ì˜ˆìƒ LB: 0.746178\n",
      "í˜„ì¬ 1ë“±: 0.74209\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Summary saved\n",
      "\n",
      "================================================================================\n",
      "03.3ë²ˆ (Seed 123) COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"03.3ë²ˆ - Random Seed 123 ë²„ì „\")\n",
    "print(\"=\"*80)\n",
    "print(\"ì „ëµ: 03ë²ˆ ì™„ì „ ë™ì¼ + Seedë§Œ 123ìœ¼ë¡œ ë³€ê²½\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# 2. ì „ì²˜ë¦¬ í•¨ìˆ˜ (03ë²ˆê³¼ ì™„ì „ ë™ì¼)\n",
    "def preprocess(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # ì‹œìˆ _ëŒ€ë¶„ë¥˜\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x):\n",
    "            return \"Unknown\"\n",
    "        if \"IUI\" in x:\n",
    "            return \"IUI\"\n",
    "        if \"DI\" in x:\n",
    "            return \"Other\"\n",
    "        if \"ICSI\" in x:\n",
    "            return \"ICSI\"\n",
    "        if \"IVF\" in x:\n",
    "            return \"IVF\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df_copy[\"ì‹œìˆ _ëŒ€ë¶„ë¥˜\"] = df_copy[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(major_procedure)\n",
    "    \n",
    "    # BLASTOCYST í¬í•¨ ì—¬ë¶€\n",
    "    df_copy[\"BLASTOCYST_í¬í•¨\"] = df_copy[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    \n",
    "    # ë°°ì•„ ì´ì‹ ì—¬ë¶€\n",
    "    embryo_stage_cols = [\n",
    "        \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\", \"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\", \"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "        \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\", \"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\", \"í•´ë™ëœ ë°°ì•„ ìˆ˜\", \"í•´ë™ ë‚œì ìˆ˜\",\n",
    "        \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\", \"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "    ]\n",
    "    \n",
    "    df_copy[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"] = df_copy[embryo_stage_cols].isna().all(axis=1).astype(int)\n",
    "    df_copy[\"ë°°ì•„_ì´ì‹_ì—¬ë¶€\"] = 1 - df_copy[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"]\n",
    "    \n",
    "    # ë°°ì•„ ì§„í–‰ ë‹¨ê³„\n",
    "    def embryo_stage(row):\n",
    "        if row['ë°°ì•„_ì´ì‹_ì—¬ë¶€'] == 0:\n",
    "            return 'ë°°ì•„ë‹¨ê³„_ë¯¸ë„ë‹¬'\n",
    "        elif pd.isna(row['ì´ ìƒì„± ë°°ì•„ ìˆ˜']) or row['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] == 0:\n",
    "            return 'ë°°ì•„ìƒì„±_ì‹¤íŒ¨'\n",
    "        elif pd.isna(row['ì´ì‹ëœ ë°°ì•„ ìˆ˜']) or row['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] == 0:\n",
    "            return 'ì´ì‹_ë¯¸ì‹¤ì‹œ'\n",
    "        else:\n",
    "            return 'ì´ì‹_ì™„ë£Œ'\n",
    "    \n",
    "    df_copy['ë°°ì•„_ì§„í–‰_ë‹¨ê³„'] = df_copy.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    # ì´ì‹œìˆ _bin3\n",
    "    def collapse_trials(x):\n",
    "        if x == '0íšŒ':\n",
    "            return '0íšŒ'\n",
    "        elif x in ['1íšŒ', '2íšŒ']:\n",
    "            return '1-2íšŒ'\n",
    "        else:\n",
    "            return '3íšŒ ì´ìƒ'\n",
    "    \n",
    "    df_copy[\"ì´ì‹œìˆ _bin3\"] = df_copy[\"ì´ ì‹œìˆ  íšŸìˆ˜\"].apply(collapse_trials)\n",
    "    \n",
    "    # ë‚˜ì´_3êµ¬ê°„\n",
    "    def age_group_simple(age):\n",
    "        if age == 'ì•Œ ìˆ˜ ì—†ìŒ':\n",
    "            return 'Unknown'\n",
    "        elif age == 'ë§Œ18-34ì„¸':\n",
    "            return '34ì„¸ ì´í•˜'\n",
    "        elif age in ['ë§Œ35-37ì„¸', 'ë§Œ38-39ì„¸']:\n",
    "            return '35-39ì„¸'\n",
    "        else:\n",
    "            return '40ì„¸ ì´ìƒ'\n",
    "    \n",
    "    df_copy['ë‚˜ì´_3êµ¬ê°„'] = df_copy['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].apply(age_group_simple)\n",
    "    \n",
    "    # ì´ì‹ë°°ì•„_êµ¬ê°„\n",
    "    def embryo_count_bin(count):\n",
    "        if pd.isna(count) or count == 0:\n",
    "            return '0ê°œ'\n",
    "        elif count <= 2:\n",
    "            return '1-2ê°œ'\n",
    "        else:\n",
    "            return '3ê°œ ì´ìƒ'\n",
    "    \n",
    "    df_copy['ì´ì‹ë°°ì•„_êµ¬ê°„'] = df_copy['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].apply(embryo_count_bin)\n",
    "    \n",
    "    # Day5_ì´ì‹_ì—¬ë¶€\n",
    "    df_copy['Day5_ì´ì‹_ì—¬ë¶€'] = (df_copy['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'] == 5.0).astype(int)\n",
    "    \n",
    "    # ë¶ˆì„ì›ì¸_ë³µì¡ë„\n",
    "    infertility_cols = [\n",
    "        \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\", \"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\", \"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\", \"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "        \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\", \"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\", \"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\", \"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\", \"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\", \"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"\n",
    "    ]\n",
    "    \n",
    "    df_copy[\"ë¶ˆì„_ì›ì¸_ê°œìˆ˜\"] = df_copy[infertility_cols].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0:\n",
    "            return 'None'\n",
    "        elif count == 1:\n",
    "            return 'Single'\n",
    "        elif count == 2:\n",
    "            return 'Double'\n",
    "        else:\n",
    "            return 'Multiple'\n",
    "    \n",
    "    df_copy['ë¶ˆì„ì›ì¸_ë³µì¡ë„'] = df_copy['ë¶ˆì„_ì›ì¸_ê°œìˆ˜'].apply(infertility_complexity)\n",
    "    \n",
    "    # ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€\n",
    "    df_copy['ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€'] = df_copy['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].notna().astype(int)\n",
    "    \n",
    "    # ë°°ì•„ íš¨ìœ¨ ë¹„ìœ¨ ë³€ìˆ˜ë“¤\n",
    "    df_copy['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df_copy['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)\n",
    "    df_copy['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df_copy['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    df_copy['ë°°ì•„_ì €ì¥_ë¹„ìœ¨'] = df_copy['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    \n",
    "    # êµí˜¸ì‘ìš© ë³€ìˆ˜ë“¤\n",
    "    df_copy['ë‚˜ì´Ã—Day5'] = df_copy['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].astype(str) + '_' + df_copy['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    df_copy['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´'] = df_copy['ì´ì‹œìˆ _bin3'] + '_' + df_copy['ë‚˜ì´_3êµ¬ê°„']\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬ ì ìš©\n",
    "print(\"\\nì „ì²˜ë¦¬ ì¤‘...\")\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ Train shape: {train_df.shape}\")\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ Test shape: {test_df.shape}\")\n",
    "\n",
    "# 4. ID ì œê±°\n",
    "train_data = train_df.drop(columns=['ID', 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "test_data = test_df.drop(columns=['ID', 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "\n",
    "print(f\"\\nFinal Train shape: {train_data.shape}\")\n",
    "print(f\"Target distribution:\\n{train_data['ì„ì‹  ì„±ê³µ ì—¬ë¶€'].value_counts(normalize=True)}\")\n",
    "\n",
    "# ============================\n",
    "# 5. AutoGluon í•™ìŠµ (Seed 123)\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AutoGluon Training - Random Seed 123\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nì˜ˆìƒ ì†Œìš” ì‹œê°„: 2ì‹œê°„\")\n",
    "print(\"Random Seed: 123 (03ë²ˆì€ 42)\")\n",
    "print(\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 4-8GB\")\n",
    "print(\"\\ní•™ìŠµ ì‹œì‘...\\n\")\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label='ì„ì‹  ì„±ê³µ ì—¬ë¶€',\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='../outputs/autogluon_seed123_v2'\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=7200,  # 2ì‹œê°„\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=5,\n",
    "    num_bag_sets=1,\n",
    "    num_stack_levels=1,\n",
    "    ag_args_fit={'num_gpus': 0},\n",
    "    hyperparameters={\n",
    "        'GBM': {'seed': 123},\n",
    "        'CAT': {'random_seed': 123},\n",
    "        'XGB': {'seed': 123},\n",
    "        'NN_TORCH': {'seed': 123},\n",
    "        'FASTAI': {'seed': 123},\n",
    "        'RF': {'random_state': 123}\n",
    "    },\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 6. ê²°ê³¼ í™•ì¸\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Leaderboard (score_val ê¸°ì¤€ ì •ë ¬!)\n",
    "leaderboard = predictor.leaderboard(train_data, silent=True)\n",
    "leaderboard_sorted = leaderboard.sort_values('score_val', ascending=False)\n",
    "\n",
    "print(\"\\n=== Model Leaderboard (Top 15, score_val ê¸°ì¤€) ===\")\n",
    "print(leaderboard_sorted.head(15)[['model', 'score_val']].to_string())\n",
    "\n",
    "# Best model\n",
    "best_model = leaderboard_sorted.iloc[0]['model']\n",
    "best_score = leaderboard_sorted.iloc[0]['score_val']\n",
    "\n",
    "print(f\"\\nğŸ† Best Model: {best_model}\")\n",
    "print(f\"ğŸ¯ Best CV AUC: {best_score:.6f}\")\n",
    "\n",
    "# ============================\n",
    "# 7. ì˜ˆì¸¡ ë° Submission\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test ì˜ˆì¸¡ (Best Model ì‚¬ìš©!)\n",
    "test_predictions = predictor.predict_proba(test_data, model=best_model)\n",
    "\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    test_proba = test_predictions[1].values\n",
    "else:\n",
    "    test_proba = test_predictions\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ê°’ í†µê³„:\")\n",
    "print(f\"Min:  {test_proba.min():.6f}\")\n",
    "print(f\"Max:  {test_proba.max():.6f}\")\n",
    "print(f\"Mean: {test_proba.mean():.6f}\")\n",
    "\n",
    "# Submission ìƒì„±\n",
    "submission['probability'] = test_proba\n",
    "output_file = f\"../outputs/03.3_seed123_CV{best_score:.6f}.csv\"\n",
    "submission.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved!\")\n",
    "print(f\"   File: {output_file}\")\n",
    "print(f\"   Model: {best_model}\")\n",
    "print(f\"   Seed: 123\")\n",
    "\n",
    "# ============================\n",
    "# 8. ìƒì„¸ ì •ë³´ ì €ì¥\n",
    "# ============================\n",
    "leaderboard_sorted.to_csv(\"../outputs/03.3_seed123_leaderboard.csv\", index=False)\n",
    "print(\"Leaderboard saved\")\n",
    "\n",
    "try:\n",
    "    importance = predictor.feature_importance(train_data)\n",
    "    importance.to_csv(\"../outputs/03.3_seed123_feature_importance.csv\")\n",
    "    print(\"Feature importance saved\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ìš”ì•½\n",
    "summary = f\"\"\"\n",
    "{'='*80}\n",
    "03.3ë²ˆ - Random Seed 123 ê²°ê³¼\n",
    "{'='*80}\n",
    "\n",
    "ì „ëµ: 03ë²ˆ ì™„ì „ ë™ì¼ + Random Seedë§Œ 123ìœ¼ë¡œ ë³€ê²½\n",
    "\n",
    "Best Model: {best_model}\n",
    "CV AUC: {best_score:.6f}\n",
    "\n",
    "ì„±ì  ë¹„êµ:\n",
    "  03ë²ˆ (Seed 42):  0.7407 (LB: 0.7420)\n",
    "  11ë²ˆ (Seed 123): {best_score:.6f}\n",
    "  \n",
    "ì°¨ì´: {best_score - 0.7407:+.6f}\n",
    "\n",
    "ì˜ˆìƒ LB: {expected_lb:.6f}\n",
    "í˜„ì¬ 1ë“±: 0.74209\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + summary)\n",
    "\n",
    "with open(\"../outputs/03.3_seed123_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"Summary saved\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"03.3ë²ˆ (Seed 123) COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d41714",
   "metadata": {},
   "source": [
    "### 03.4 num_bag_sets=3ìœ¼ë¡œ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c131b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AutoGluon Experiment 03.4\n",
      "============================================================\n",
      "\n",
      "Train shape: (256351, 69)\n",
      "Test shape: (90067, 68)\n",
      "\n",
      "ì „ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../outputs/autogluon_models_03.4\"\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=3\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 10800 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: ../outputs/autogluon_models_03.4/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ í›„ Train shape: (256351, 86)\n",
      "ì „ì²˜ë¦¬ í›„ Test shape: (90067, 85)\n",
      "\n",
      "Final Train shape: (256351, 84)\n",
      "Target distribution:\n",
      "ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "0    0.741651\n",
      "1    0.258349\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "Starting AutoGluon Training\n",
      "============================================================\n",
      "\n",
      "â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2ì‹œê°„\n",
      "ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 4-8GB ì˜ˆìƒ\n",
      "\n",
      "í•™ìŠµ ì‹œì‘...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 2774 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 8026 seconds.\n",
      "Starting full fit now with num_stack_levels 0.\n",
      "Beginning AutoGluon training ... Time limit = 8026s\n",
      "AutoGluon will save models to \"../outputs/autogluon_models_03.4\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       4.72 GB / 16.00 GB (29.5%)\n",
      "Disk Space Avail:   205.41 GB / 460.43 GB (44.6%)\n",
      "===================================================\n",
      "Train Data Rows:    256351\n",
      "Train Data Columns: 83\n",
      "Label Column:       ì„ì‹  ì„±ê³µ ì—¬ë¶€\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5581.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 752.89 MB (13.5% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 13.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 26 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 32 | ['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', ...]\n",
      "\t\t('int', [])    : 17 | ['ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t\t('object', []) : 28 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ì‹œìˆ  ìœ í˜•', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 27 | ['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìœ ë„ ìœ í˜•', 'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ', ...]\n",
      "\t\t('float', [])     : 28 | ['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', ...]\n",
      "\t\t('int', [])       :  1 | ['ë¶ˆì„_ì›ì¸_ê°œìˆ˜']\n",
      "\t\t('int', ['bool']) : 21 | ['ì‹œìˆ  ìœ í˜•', 'ë°°ë€ ìê·¹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', ...]\n",
      "\t2.7s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 68.46 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 8022.94s of the 8022.93s of remaining time.\n",
      "\t0.6413\t = Validation score   (roc_auc)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t28.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 7993.9s of the 7993.9s of remaining time.\n",
      "\t0.6262\t = Validation score   (roc_auc)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t27.9s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 7965.6s of the 7965.6s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.65%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t7.43s\t = Training   runtime\n",
      "\t2.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 7955.2s of the 7955.2s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.60%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t5.93s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 7947.05s of the 7947.05s of remaining time.\n",
      "\t0.73\t = Validation score   (roc_auc)\n",
      "\t14.49s\t = Training   runtime\n",
      "\t8.27s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 7923.72s of the 7923.72s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 261 due to low memory. Expected memory usage reduced from 17.19% -> 15.0% of available memory...\n",
      "\t0.7308\t = Validation score   (roc_auc)\n",
      "\t14.54s\t = Training   runtime\n",
      "\t7.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 7901.54s of the 7901.54s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.62%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t1053.5s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 6845.57s of the 6845.56s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 279 due to low memory. Expected memory usage reduced from 16.09% -> 15.0% of available memory...\n",
      "\t0.7324\t = Validation score   (roc_auc)\n",
      "\t10.24s\t = Training   runtime\n",
      "\t7.28s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 6827.34s of the 6827.33s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 263 due to low memory. Expected memory usage reduced from 17.11% -> 15.0% of available memory...\n",
      "\t0.7324\t = Validation score   (roc_auc)\n",
      "\t10.69s\t = Training   runtime\n",
      "\t7.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 6809.1s of the 6809.1s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.70% memory usage per fold, 74.79%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=18.70%)\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t127.43s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 6678.83s of the 6678.82s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=13.40%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t596.15s\t = Training   runtime\n",
      "\t1.92s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 6079.73s of the 6079.72s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.39%)\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t133.81s\t = Training   runtime\n",
      "\t2.7s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 5942.99s of the 5942.98s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.79%)\n",
      "\t0.7383\t = Validation score   (roc_auc)\n",
      "\t11.41s\t = Training   runtime\n",
      "\t2.9s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 5928.28s of the 5928.28s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.13%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t185.38s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 5740.4s of the 5740.4s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.18%)\n",
      "\t0.7378\t = Validation score   (roc_auc)\n",
      "\t156.62s\t = Training   runtime\n",
      "\t2.73s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 5580.69s of the 5580.68s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.85%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t21.89s\t = Training   runtime\n",
      "\t8.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 5554.73s of the 5554.72s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.47%)\n",
      "\t0.7355\t = Validation score   (roc_auc)\n",
      "\t401.41s\t = Training   runtime\n",
      "\t3.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 5150.55s of the 5150.54s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=7.64%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t145.15s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 5003.01s of the 5003.01s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=6.41%)\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t41.32s\t = Training   runtime\n",
      "\t10.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 4956.87s of the 4956.87s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.87%)\n",
      "\t0.737\t = Validation score   (roc_auc)\n",
      "\t233.19s\t = Training   runtime\n",
      "\t2.75s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 4721.31s of the 4721.31s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.59%)\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t1591.76s\t = Training   runtime\n",
      "\t6.85s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 3125.81s of the 3125.81s of remaining time.\n",
      "\t0.7223\t = Validation score   (roc_auc)\n",
      "\t62.25s\t = Training   runtime\n",
      "\t8.65s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 3054.14s of the 3054.13s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.70%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t1781.74s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1269.69s of the 1269.68s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.07% memory usage per fold, 64.29%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=16.07%)\n",
      "\t0.7365\t = Validation score   (roc_auc)\n",
      "\t81.1s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 1185.76s of the 1185.76s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.12%)\n",
      "\t0.7399\t = Validation score   (roc_auc)\n",
      "\t410.96s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 772.16s of the 772.16s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 209 due to low memory. Expected memory usage reduced from 21.52% -> 15.0% of available memory...\n",
      "\t0.7035\t = Validation score   (roc_auc)\n",
      "\t57.59s\t = Training   runtime\n",
      "\t7.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 706.6s of the 706.6s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=8.04%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t10.21s\t = Training   runtime\n",
      "\t3.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 693.28s of the 693.27s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.33%)\n",
      "\t0.7369\t = Validation score   (roc_auc)\n",
      "\t451.62s\t = Training   runtime\n",
      "\t4.36s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 238.65s of the 238.65s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=9.00%)\n",
      "\t0.7376\t = Validation score   (roc_auc)\n",
      "\t193.67s\t = Training   runtime\n",
      "\t1.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 42.35s of the 42.34s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=5.79%)\n",
      "\t0.7334\t = Validation score   (roc_auc)\n",
      "\t35.09s\t = Training   runtime\n",
      "\t3.31s\t = Validation runtime\n",
      "Completed 1/3 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 802.29s of the 4.33s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.182, 'NeuralNetTorch_r79_BAG_L1': 0.136, 'CatBoost_r137_BAG_L1': 0.136, 'LightGBMXT_BAG_L1': 0.091, 'NeuralNetFastAI_r145_BAG_L1': 0.091, 'RandomForestEntr_BAG_L1': 0.045, 'XGBoost_BAG_L1': 0.045, 'NeuralNetTorch_BAG_L1': 0.045, 'CatBoost_r177_BAG_L1': 0.045, 'LightGBM_r96_BAG_L1': 0.045, 'NeuralNetTorch_r22_BAG_L1': 0.045, 'NeuralNetFastAI_r102_BAG_L1': 0.045, 'LightGBM_r188_BAG_L1': 0.045}\n",
      "\t0.7408\t = Validation score   (roc_auc)\n",
      "\t26.44s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8048.21s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../outputs/autogluon_models_03.4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "AutoGluon Results\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'ë°°ì•„_ì´ì‹_ì—¬ë¶€']\n",
      "Computing feature importance via permutation shuffling for 77 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Leaderboard (Top 15) ===\n",
      "                       model  score_test  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForest_r195_BAG_L1    0.998909   0.703452     roc_auc        3.734834       7.134382    57.589181                 3.734834                7.134382          57.589181            1       True         26\n",
      "1      ExtraTrees_r42_BAG_L1    0.958349   0.722289     roc_auc        2.676122       8.648223    62.250063                 2.676122                8.648223          62.250063            1       True         22\n",
      "2    RandomForestEntr_BAG_L1    0.929971   0.730819     roc_auc        1.876779       7.104161    14.544785                 1.876779                7.104161          14.544785            1       True          6\n",
      "3    RandomForestGini_BAG_L1    0.928349   0.730036     roc_auc        2.060276       8.269329    14.485444                 2.060276                8.269329          14.485444            1       True          5\n",
      "4      ExtraTreesGini_BAG_L1    0.903355   0.732446     roc_auc        1.946964       7.277485    10.240424                 1.946964                7.277485          10.240424            1       True          8\n",
      "5      ExtraTreesEntr_BAG_L1    0.903306   0.732362     roc_auc        1.893111       7.005302    10.686144                 1.893111                7.005302          10.686144            1       True          9\n",
      "6      KNeighborsDist_BAG_L1    0.856610   0.626226     roc_auc       27.095851      27.900462     0.199656                27.095851               27.900462           0.199656            1       True          2\n",
      "7         XGBoost_r33_BAG_L1    0.785411   0.737103     roc_auc       11.148919       6.845822  1591.764445                11.148919                6.845822        1591.764445            1       True         21\n",
      "8       LightGBMLarge_BAG_L1    0.772624   0.738310     roc_auc        3.977479       2.903145    11.406957                 3.977479                2.903145          11.406957            1       True         13\n",
      "9       LightGBM_r188_BAG_L1    0.764957   0.739131     roc_auc        4.602650       3.066945    10.212116                 4.602650                3.066945          10.212116            1       True         27\n",
      "10       WeightedEnsemble_L2    0.761567   0.740752     roc_auc      104.755133      39.580022  4773.046412                 0.012693                0.042442          26.441299            2       True         31\n",
      "11      LightGBM_r131_BAG_L1    0.757204   0.739494     roc_auc       10.557163       8.122710    21.886694                10.557163                8.122710          21.886694            1       True         16\n",
      "12     KNeighborsUnif_BAG_L1    0.757089   0.641296     roc_auc       27.314079      28.625861     0.194956                27.314079               28.625861           0.194956            1       True          1\n",
      "13       CatBoost_r13_BAG_L1    0.754969   0.739873     roc_auc        0.544106       0.568142   410.957438                 0.544106                0.568142         410.957438            1       True         25\n",
      "14      CatBoost_r177_BAG_L1    0.753377   0.739703     roc_auc        0.339142       0.224925   185.377476                 0.339142                0.224925         185.377476            1       True         14\n",
      "\n",
      "Best Model: RandomForest_r195_BAG_L1\n",
      "Best CV AUC: 0.703452\n",
      "\n",
      "============================================================\n",
      "Feature Importance\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1263.88s\t= Expected runtime (252.78s per shuffle set)\n",
      "\t719.41s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 20 Features ===\n",
      "                  importance    stddev       p_value  n  p99_high   p99_low\n",
      "ì´ì‹ëœ ë°°ì•„ ìˆ˜            0.021769  0.004232  1.630955e-04  5  0.030483  0.013055\n",
      "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´            0.011291  0.003111  6.266278e-04  5  0.017696  0.004886\n",
      "ë‚˜ì´_3êµ¬ê°„              0.010415  0.003554  1.401910e-03  5  0.017732  0.003098\n",
      "ë°°ì•„_ì´ì‹_ë¹„ìœ¨            0.009373  0.002086  2.757492e-04  5  0.013667  0.005079\n",
      "ì´ì‹ë°°ì•„_êµ¬ê°„             0.009241  0.003163  1.418034e-03  5  0.015753  0.002728\n",
      "ë‚˜ì´Ã—Day5             0.007598  0.002226  7.911116e-04  5  0.012182  0.003015\n",
      "ë°°ì•„_ì €ì¥_ë¹„ìœ¨            0.007538  0.002600  1.460510e-03  5  0.012892  0.002183\n",
      "ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼           0.007324  0.001887  4.852665e-04  5  0.011210  0.003438\n",
      "ì´ ìƒì„± ë°°ì•„ ìˆ˜           0.006645  0.002688  2.617837e-03  5  0.012180  0.001109\n",
      "ë°°ì•„_ìƒì„±_íš¨ìœ¨            0.006558  0.001146  1.073808e-04  5  0.008917  0.004199\n",
      "ì‹œìˆ  ì‹œê¸° ì½”ë“œ            0.006548  0.000496  3.929399e-06  5  0.007569  0.005526\n",
      "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜         0.004736  0.000636  3.805669e-05  5  0.006045  0.003427\n",
      "Day5_ì´ì‹_ì—¬ë¶€          0.004322  0.001311  9.012991e-04  5  0.007021  0.001624\n",
      "ë°°ì•„_ì§„í–‰_ë‹¨ê³„            0.004184  0.001586  2.067755e-03  5  0.007451  0.000918\n",
      "í˜¼í•©ëœ ë‚œì ìˆ˜            0.003867  0.000151  2.764456e-07  5  0.004178  0.003557\n",
      "íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜    0.003683  0.000060  8.545824e-09  5  0.003807  0.003559\n",
      "ì €ì¥ëœ ë°°ì•„ ìˆ˜            0.003525  0.002079  9.616641e-03  5  0.007805 -0.000755\n",
      "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜          0.003220  0.000439  4.038036e-05  5  0.004124  0.002317\n",
      "ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´             0.003141  0.001085  1.464811e-03  5  0.005375  0.000908\n",
      "í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜       0.003126  0.000868  6.449965e-04  5  0.004913  0.001339\n",
      "\n",
      "============================================================\n",
      "Generating Predictions\n",
      "============================================================\n",
      "\n",
      "ì˜ˆì¸¡ê°’ í†µê³„:\n",
      "Min:  0.000240\n",
      "Max:  0.717531\n",
      "Mean: 0.258832\n",
      "Std:  0.159566\n",
      "\n",
      "AutoGluon Submission saved!\n",
      "   File: ../outputs/03.4_submission_autogluon(0209).csv\n",
      "\n",
      "============================================================\n",
      "Saving Details\n",
      "============================================================\n",
      "âœ… Leaderboard saved: ../outputs/03.4_autogluon_leaderboard.csv\n",
      "âœ… Feature importance saved: ../outputs/03.4_autogluon_feature_importance.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "Best Model: RandomForest_r195_BAG_L1\n",
      "CV AUC: 0.703452\n",
      "\n",
      "Total Models Trained: 31\n",
      "Ensemble Type: WeightedEnsemble_L2\n",
      "\n",
      "Top 3 Models:\n",
      "  1. RandomForest_r195_BAG_L1: 0.703452\n",
      "  2. ExtraTrees_r42_BAG_L1: 0.722289\n",
      "  3. RandomForestEntr_BAG_L1: 0.730819\n",
      "\n",
      "\n",
      "âœ… Summary saved: ../outputs/03.4_autogluon_summary.txt\n",
      "\n",
      "============================================================\n",
      "AutoGluon Experiment Complete! ğŸ‰\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AutoGluon Experiment 03.4\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# 2. ì „ì²˜ë¦¬ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "def preprocess(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # ì‹œìˆ _ëŒ€ë¶„ë¥˜\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x):\n",
    "            return \"Unknown\"\n",
    "        if \"IUI\" in x:\n",
    "            return \"IUI\"\n",
    "        if \"DI\" in x:\n",
    "            return \"Other\"\n",
    "        if \"ICSI\" in x:\n",
    "            return \"ICSI\"\n",
    "        if \"IVF\" in x:\n",
    "            return \"IVF\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    df_copy[\"ì‹œìˆ _ëŒ€ë¶„ë¥˜\"] = df_copy[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(major_procedure)\n",
    "    \n",
    "    # BLASTOCYST í¬í•¨ ì—¬ë¶€\n",
    "    df_copy[\"BLASTOCYST_í¬í•¨\"] = df_copy[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].str.contains(\"BLASTOCYST\", na=False).astype(int)\n",
    "    \n",
    "    # ë°°ì•„ ì´ì‹ ì—¬ë¶€\n",
    "    embryo_stage_cols = [\n",
    "        \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\", \"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\", \"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "        \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\", \"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "        \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\", \"í•´ë™ëœ ë°°ì•„ ìˆ˜\", \"í•´ë™ ë‚œì ìˆ˜\",\n",
    "        \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\", \"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "        \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "    ]\n",
    "    \n",
    "    df_copy[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"] = df_copy[embryo_stage_cols].isna().all(axis=1).astype(int)\n",
    "    df_copy[\"ë°°ì•„_ì´ì‹_ì—¬ë¶€\"] = 1 - df_copy[\"ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬\"]\n",
    "    \n",
    "    # ë°°ì•„ ì§„í–‰ ë‹¨ê³„\n",
    "    def embryo_stage(row):\n",
    "        if row['ë°°ì•„_ì´ì‹_ì—¬ë¶€'] == 0:\n",
    "            return 'ë°°ì•„ë‹¨ê³„_ë¯¸ë„ë‹¬'\n",
    "        elif pd.isna(row['ì´ ìƒì„± ë°°ì•„ ìˆ˜']) or row['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] == 0:\n",
    "            return 'ë°°ì•„ìƒì„±_ì‹¤íŒ¨'\n",
    "        elif pd.isna(row['ì´ì‹ëœ ë°°ì•„ ìˆ˜']) or row['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] == 0:\n",
    "            return 'ì´ì‹_ë¯¸ì‹¤ì‹œ'\n",
    "        else:\n",
    "            return 'ì´ì‹_ì™„ë£Œ'\n",
    "    \n",
    "    df_copy['ë°°ì•„_ì§„í–‰_ë‹¨ê³„'] = df_copy.apply(embryo_stage, axis=1)\n",
    "    \n",
    "    # ì´ì‹œìˆ _bin3\n",
    "    def collapse_trials(x):\n",
    "        if x == '0íšŒ':\n",
    "            return '0íšŒ'\n",
    "        elif x in ['1íšŒ', '2íšŒ']:\n",
    "            return '1â€“2íšŒ'\n",
    "        else:\n",
    "            return '3íšŒ ì´ìƒ'\n",
    "    \n",
    "    df_copy[\"ì´ì‹œìˆ _bin3\"] = df_copy[\"ì´ ì‹œìˆ  íšŸìˆ˜\"].apply(collapse_trials)\n",
    "    \n",
    "    # ë‚˜ì´_3êµ¬ê°„\n",
    "    def age_group_simple(age):\n",
    "        if age == 'ì•Œ ìˆ˜ ì—†ìŒ':\n",
    "            return 'Unknown'\n",
    "        elif age == 'ë§Œ18-34ì„¸':\n",
    "            return '34ì„¸ ì´í•˜'\n",
    "        elif age in ['ë§Œ35-37ì„¸', 'ë§Œ38-39ì„¸']:\n",
    "            return '35-39ì„¸'\n",
    "        else:\n",
    "            return '40ì„¸ ì´ìƒ'\n",
    "    \n",
    "    df_copy['ë‚˜ì´_3êµ¬ê°„'] = df_copy['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].apply(age_group_simple)\n",
    "    \n",
    "    # ì´ì‹ë°°ì•„_êµ¬ê°„\n",
    "    def embryo_count_bin(count):\n",
    "        if pd.isna(count) or count == 0:\n",
    "            return '0ê°œ'\n",
    "        elif count <= 2:\n",
    "            return '1-2ê°œ'\n",
    "        else:\n",
    "            return '3ê°œ ì´ìƒ'\n",
    "    \n",
    "    df_copy['ì´ì‹ë°°ì•„_êµ¬ê°„'] = df_copy['ì´ì‹ëœ ë°°ì•„ ìˆ˜'].apply(embryo_count_bin)\n",
    "    \n",
    "    # Day5_ì´ì‹_ì—¬ë¶€\n",
    "    df_copy['Day5_ì´ì‹_ì—¬ë¶€'] = (df_copy['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'] == 5.0).astype(int)\n",
    "    \n",
    "    # ë¶ˆì„ì›ì¸_ë³µì¡ë„\n",
    "    infertility_cols = [\n",
    "        \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\", \"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\", \"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\", \"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "        \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\", \"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\", \"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\", \"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\", \"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\", \"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "        \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"\n",
    "    ]\n",
    "    \n",
    "    df_copy[\"ë¶ˆì„_ì›ì¸_ê°œìˆ˜\"] = df_copy[infertility_cols].sum(axis=1)\n",
    "    \n",
    "    def infertility_complexity(count):\n",
    "        if count == 0:\n",
    "            return 'None'\n",
    "        elif count == 1:\n",
    "            return 'Single'\n",
    "        elif count == 2:\n",
    "            return 'Double'\n",
    "        else:\n",
    "            return 'Multiple'\n",
    "    \n",
    "    df_copy['ë¶ˆì„ì›ì¸_ë³µì¡ë„'] = df_copy['ë¶ˆì„_ì›ì¸_ê°œìˆ˜'].apply(infertility_complexity)\n",
    "    \n",
    "    # ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€\n",
    "    df_copy['ë°°ì•„_í•´ë™_ì‹¤ì‹œ_ì—¬ë¶€'] = df_copy['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].notna().astype(int)\n",
    "    \n",
    "    # ë°°ì•„ íš¨ìœ¨ ë¹„ìœ¨ ë³€ìˆ˜ë“¤\n",
    "    df_copy['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df_copy['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)\n",
    "    df_copy['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df_copy['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    df_copy['ë°°ì•„_ì €ì¥_ë¹„ìœ¨'] = df_copy['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (df_copy['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "    \n",
    "    # êµí˜¸ì‘ìš© ë³€ìˆ˜ë“¤\n",
    "    df_copy['ë‚˜ì´Ã—Day5'] = df_copy['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].astype(str) + '_' + df_copy['Day5_ì´ì‹_ì—¬ë¶€'].astype(str)\n",
    "    df_copy['ì‹œìˆ íšŸìˆ˜Ã—ë‚˜ì´'] = df_copy['ì´ì‹œìˆ _bin3'] + '_' + df_copy['ë‚˜ì´_3êµ¬ê°„']\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬ ì ìš©\n",
    "print(\"\\nì „ì²˜ë¦¬ ì¤‘...\")\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ Train shape: {train_df.shape}\")\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ Test shape: {test_df.shape}\")\n",
    "\n",
    "# 4. ID ì œê±° (AutoGluonì€ ìë™ìœ¼ë¡œ íƒ€ê²Ÿ ì°¾ìŒ)\n",
    "train_data = train_df.drop(columns=['ID', 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "test_data = test_df.drop(columns=['ID', 'ë°°ì•„_ì´ì‹_ë¯¸ë„ë‹¬'])\n",
    "\n",
    "print(f\"\\nFinal Train shape: {train_data.shape}\")\n",
    "print(f\"Target distribution:\\n{train_data['ì„ì‹  ì„±ê³µ ì—¬ë¶€'].value_counts(normalize=True)}\")\n",
    "\n",
    "# ============================\n",
    "# 5. AutoGluon í•™ìŠµ\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting AutoGluon Training\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2ì‹œê°„\")\n",
    "print(\"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 4-8GB ì˜ˆìƒ\")\n",
    "print(\"\\ní•™ìŠµ ì‹œì‘...\\n\")\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label='ì„ì‹  ì„±ê³µ ì—¬ë¶€',\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary',\n",
    "    path='../outputs/autogluon_models_03.4'\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=10800,  # 2ì‹œê°„\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=5,\n",
    "    num_bag_sets=3,\n",
    "    num_stack_levels=1,\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 6. ê²°ê³¼ í™•ì¸\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AutoGluon Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Leaderboard\n",
    "leaderboard = predictor.leaderboard(train_data, silent=True)\n",
    "print(\"\\n=== Model Leaderboard (Top 15) ===\")\n",
    "print(leaderboard.head(15).to_string())\n",
    "\n",
    "# Best model\n",
    "best_model = leaderboard.iloc[0]['model']\n",
    "best_score = leaderboard.iloc[0]['score_val']\n",
    "print(f\"\\nBest Model: {best_model}\")\n",
    "print(f\"Best CV AUC: {best_score:.6f}\")\n",
    "\n",
    "# ============================\n",
    "# 7. Feature Importance\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Feature Importance\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    importance = predictor.feature_importance(train_data)\n",
    "    print(\"\\n=== Top 20 Features ===\")\n",
    "    print(importance.head(20).to_string())\n",
    "except:\n",
    "    print(\"Feature importance not available for ensemble model\")\n",
    "\n",
    "# ============================\n",
    "# 8. ì˜ˆì¸¡ ë° Submission\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Predictions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test ì˜ˆì¸¡\n",
    "test_predictions = predictor.predict_proba(test_data)\n",
    "\n",
    "# í™•ë¥ ê°’ ì¶”ì¶œ (í´ë˜ìŠ¤ 1ì˜ í™•ë¥ )\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    test_proba = test_predictions[1].values\n",
    "else:\n",
    "    test_proba = test_predictions\n",
    "\n",
    "print(f\"\\nì˜ˆì¸¡ê°’ í†µê³„:\")\n",
    "print(f\"Min:  {test_proba.min():.6f}\")\n",
    "print(f\"Max:  {test_proba.max():.6f}\")\n",
    "print(f\"Mean: {test_proba.mean():.6f}\")\n",
    "print(f\"Std:  {test_proba.std():.6f}\")\n",
    "\n",
    "# Submission ìƒì„±\n",
    "submission['probability'] = test_proba\n",
    "submission.to_csv(\"../outputs/03.4_submission_autogluon(0209).csv\", index=False)\n",
    "\n",
    "print(\"\\nAutoGluon Submission saved!\")\n",
    "print(f\"   File: ../outputs/03.4_submission_autogluon(0209).csv\")\n",
    "\n",
    "# ============================\n",
    "# 9. ìƒì„¸ ì •ë³´ ì €ì¥\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Saving Details\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Leaderboard ì „ì²´ ì €ì¥\n",
    "leaderboard.to_csv(\"../outputs/03.4_autogluon_leaderboard.csv\", index=False)\n",
    "print(\"âœ… Leaderboard saved: ../outputs/03.4_autogluon_leaderboard.csv\")\n",
    "\n",
    "# Feature importance ì €ì¥\n",
    "try:\n",
    "    importance.to_csv(\"../outputs/03.4_autogluon_feature_importance.csv\")\n",
    "    print(\"âœ… Feature importance saved: ../outputs/03.4_autogluon_feature_importance.csv\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ============================\n",
    "# 10. ìš”ì•½\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Best Model: {best_model}\n",
    "CV AUC: {best_score:.6f}\n",
    "\n",
    "Total Models Trained: {len(leaderboard)}\n",
    "Ensemble Type: {predictor.model_best}\n",
    "\n",
    "Top 3 Models:\n",
    "\"\"\"\n",
    "\n",
    "for i in range(min(3, len(leaderboard))):\n",
    "    summary += f\"  {i+1}. {leaderboard.iloc[i]['model']}: {leaderboard.iloc[i]['score_val']:.6f}\\n\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# ìš”ì•½ íŒŒì¼ ì €ì¥\n",
    "with open(\"../outputs/autogluon_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\nâœ… Summary saved: ../outputs/03.4_autogluon_summary.txt\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AutoGluon Experiment Complete! ğŸ‰\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a898c1",
   "metadata": {},
   "source": [
    "03.4 ê²°ê³¼ëŠ” ì‚¬ìš© ëª»í•  ê²ƒ ê°™ìŒ. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877385f3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fertility_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
