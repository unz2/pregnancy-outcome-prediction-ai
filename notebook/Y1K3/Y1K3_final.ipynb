{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703403f6",
   "metadata": {},
   "source": [
    "seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 1] Imports & Config\n",
    "import os, gc, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import catboost as cb\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    HAS_OPTUNA = True\n",
    "except ImportError:\n",
    "    HAS_OPTUNA = False\n",
    "    print(\"[INFO] optuna 미설치 → 기본 파라미터 사용\")\n",
    "\n",
    "# -------------------------\n",
    "# Paths\n",
    "# -------------------------\n",
    "DATA_DIR = \"../data\"\n",
    "OUT_DIR  = \"../outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_COL = \"임신 성공 여부\"\n",
    "ID_COL = \"ID\"\n",
    "\n",
    "# -------------------------\n",
    "# CV / Seeds\n",
    "# -------------------------\n",
    "N_FOLDS_TRAIN = 20\n",
    "N_FOLDS_TUNE  = 5\n",
    "N_FOLDS_TE    = 5\n",
    "\n",
    "SEED = 42 \n",
    "SEEDS = [42]\n",
    "TUNE_SEED = 42           \n",
    "\n",
    "OPTUNA_TRIALS = 40\n",
    "\n",
    "# -------------------------\n",
    "# GPU Auto Detect\n",
    "# -------------------------\n",
    "import subprocess\n",
    "def has_gpu():\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
    "        return result.returncode == 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "TASK_TYPE = \"GPU\" if has_gpu() else \"CPU\"\n",
    "print(f\"[INFO] Device: {TASK_TYPE}\")\n",
    "\n",
    "# [Cell 2] Utils\n",
    "def add_na_indicators(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[f\"{c}__isna\"] = df[c].isna().astype(np.int8)\n",
    "    return df\n",
    "\n",
    "def safe_div(a, b, eps=1.0):\n",
    "    return (a + eps) / (b + eps)\n",
    "\n",
    "def clip_log1p(s, lo=None, hi=None):\n",
    "    x = s.copy()\n",
    "    if lo is not None: x = x.clip(lower=lo)\n",
    "    if hi is not None: x = x.clip(upper=hi)\n",
    "    return np.log1p(x)\n",
    "\n",
    "def choose_smoothing(train_df, col, base=20):\n",
    "    nunique = train_df[col].nunique(dropna=False)\n",
    "    if nunique <= 10:   return base\n",
    "    if nunique <= 50:   return base * 3\n",
    "    if nunique <= 200:  return base * 8\n",
    "    return base * 15\n",
    "\n",
    "# [Cell 3] Imputation (DI rule-fill + continuous-only KNN)\n",
    "def impute_missing(train_df, test_df):\n",
    "    di_fill_cols = [\n",
    "        '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '총 생성 배아 수', '이식된 배아 수',\n",
    "        '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수',\n",
    "        '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수',\n",
    "        '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수',\n",
    "        '난자 채취 경과일', '난자 해동 경과일', '배아 이식 경과일', '배아 해동 경과일',\n",
    "        '난자 혼합 경과일', '임신 시도 또는 마지막 임신 경과 연수',\n",
    "    ]\n",
    "\n",
    "    for df in [train_df, test_df]:\n",
    "        if '시술 유형' in df.columns:\n",
    "            di_mask = df['시술 유형'] == 'DI'\n",
    "            for col in di_fill_cols:\n",
    "                if col in df.columns:\n",
    "                    df.loc[di_mask, col] = df.loc[di_mask, col].fillna(0)\n",
    "\n",
    "    # continuous-only KNN (binary flags 제외)\n",
    "    knn_cols = [\n",
    "        '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수',\n",
    "        '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수',\n",
    "        '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수',\n",
    "        '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수',\n",
    "        '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수',\n",
    "        '배아 이식 경과일', '난자 혼합 경과일', '배아 해동 경과일',\n",
    "        '난자 채취 경과일', '난자 해동 경과일', '임신 시도 또는 마지막 임신 경과 연수',\n",
    "    ]\n",
    "    knn_cols = [c for c in knn_cols if c in train_df.columns]\n",
    "    has_null = [c for c in knn_cols if train_df[c].isnull().any()]\n",
    "\n",
    "    if has_null:\n",
    "        print(f\"  KNN Imputing {len(has_null)} continuous columns...\")\n",
    "        imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "        train_df[has_null] = imputer.fit_transform(train_df[has_null])\n",
    "        test_df[has_null]  = imputer.transform(test_df[has_null])\n",
    "        print(\"  Done.\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# [Cell 4] Feature Engineering\n",
    "def preprocess(df):\n",
    "    d = df.copy()\n",
    "\n",
    "    def major_procedure(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        x = str(x)\n",
    "        if \"IUI\" in x:  return \"IUI\"\n",
    "        if \"ICSI\" in x: return \"ICSI\"\n",
    "        if \"IVF\" in x:  return \"IVF\"\n",
    "        if \"DI\" in x:   return \"DI\"\n",
    "        return \"Other\"\n",
    "\n",
    "    d[\"시술_대분류\"] = d[\"특정 시술 유형\"].apply(major_procedure)\n",
    "    d[\"BLASTOCYST_포함\"] = d[\"특정 시술 유형\"].astype(str).str.contains(\"BLASTOCYST\", na=False).astype(np.int8)\n",
    "    d[\"AH_포함\"] = d[\"특정 시술 유형\"].astype(str).str.contains(\"AH\", na=False).astype(np.int8)\n",
    "\n",
    "    embryo_stage_cols = [\n",
    "        \"단일 배아 이식 여부\", \"착상 전 유전 진단 사용 여부\", \"배아 생성 주요 이유\",\n",
    "        \"총 생성 배아 수\", \"미세주입된 난자 수\", \"미세주입에서 생성된 배아 수\",\n",
    "        \"이식된 배아 수\", \"미세주입 배아 이식 수\", \"저장된 배아 수\",\n",
    "        \"미세주입 후 저장된 배아 수\", \"해동된 배아 수\", \"해동 난자 수\",\n",
    "        \"수집된 신선 난자 수\", \"저장된 신선 난자 수\", \"혼합된 난자 수\",\n",
    "        \"파트너 정자와 혼합된 난자 수\", \"기증자 정자와 혼합된 난자 수\",\n",
    "        \"동결 배아 사용 여부\", \"신선 배아 사용 여부\", \"기증 배아 사용 여부\", \"대리모 여부\",\n",
    "    ]\n",
    "    exist_cols = [c for c in embryo_stage_cols if c in d.columns]\n",
    "    d[\"배아_이식_여부\"] = 1 - d[exist_cols].isna().all(axis=1).astype(np.int8)\n",
    "\n",
    "    def embryo_stage(row):\n",
    "        if row[\"배아_이식_여부\"] == 0: return \"배아단계_미도달\"\n",
    "        if pd.isna(row.get(\"총 생성 배아 수\")) or row.get(\"총 생성 배아 수\", 0) == 0: return \"배아생성_실패\"\n",
    "        if pd.isna(row.get(\"이식된 배아 수\")) or row.get(\"이식된 배아 수\", 0) == 0: return \"이식_미실시\"\n",
    "        return \"이식_완료\"\n",
    "\n",
    "    d[\"배아_진행_단계\"] = d.apply(embryo_stage, axis=1)\n",
    "\n",
    "    def collapse_trials(x):\n",
    "        if pd.isna(x): return \"Unknown\"\n",
    "        if x == \"0회\": return \"0회\"\n",
    "        if x in [\"1회\", \"2회\"]: return \"1–2회\"\n",
    "        return \"3회 이상\"\n",
    "    d[\"총시술_bin3\"] = d[\"총 시술 횟수\"].apply(collapse_trials)\n",
    "\n",
    "    def age_group_simple(age):\n",
    "        if pd.isna(age) or age == \"알 수 없음\": return \"Unknown\"\n",
    "        if age == \"만18-34세\": return \"34세 이하\"\n",
    "        if age in [\"만35-37세\", \"만38-39세\"]: return \"35-39세\"\n",
    "        return \"40세 이상\"\n",
    "    d[\"나이_3구간\"] = d[\"시술 당시 나이\"].apply(age_group_simple)\n",
    "\n",
    "    def embryo_count_bin(count):\n",
    "        if pd.isna(count) or count == 0: return \"0개\"\n",
    "        if count <= 2: return \"1-2개\"\n",
    "        return \"3개 이상\"\n",
    "    d[\"이식배아_구간\"] = d[\"이식된 배아 수\"].apply(embryo_count_bin)\n",
    "\n",
    "    d[\"Day5_이식_여부\"] = (d[\"배아 이식 경과일\"] == 5.0).astype(np.int8)\n",
    "\n",
    "    infertility_cols = [\n",
    "        \"남성 주 불임 원인\", \"남성 부 불임 원인\", \"여성 주 불임 원인\", \"여성 부 불임 원인\",\n",
    "        \"부부 주 불임 원인\", \"부부 부 불임 원인\", \"불명확 불임 원인\",\n",
    "        \"불임 원인 - 난관 질환\", \"불임 원인 - 남성 요인\", \"불임 원인 - 배란 장애\",\n",
    "        \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\",\n",
    "        \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\",\n",
    "        \"불임 원인 - 정자 형태\"\n",
    "    ]\n",
    "    icols = [c for c in infertility_cols if c in d.columns]\n",
    "    d[\"불임_원인_개수\"] = d[icols].sum(axis=1) if icols else 0\n",
    "\n",
    "    d[\"배아_해동_실시_여부\"] = d[\"배아 해동 경과일\"].notna().astype(np.int8)\n",
    "\n",
    "    # ratios: Laplace + log1p\n",
    "    d[\"배아_이식_비율\"] = clip_log1p(safe_div(d[\"이식된 배아 수\"].fillna(0), d[\"총 생성 배아 수\"].fillna(0)))\n",
    "    d[\"배아_저장_비율\"] = clip_log1p(safe_div(d[\"저장된 배아 수\"].fillna(0), d[\"총 생성 배아 수\"].fillna(0)))\n",
    "    d[\"배아_생성_효율\"] = clip_log1p(safe_div(d[\"총 생성 배아 수\"].fillna(0), d[\"수집된 신선 난자 수\"].fillna(0)))\n",
    "    d[\"미세주입_생성_효율\"] = clip_log1p(safe_div(d[\"미세주입에서 생성된 배아 수\"].fillna(0), d[\"미세주입된 난자 수\"].fillna(0)))\n",
    "    d[\"난자_활용률\"] = clip_log1p(safe_div(d[\"혼합된 난자 수\"].fillna(0), d[\"수집된 신선 난자 수\"].fillna(0)))\n",
    "\n",
    "    # interactions\n",
    "    d[\"나이×Day5\"] = d[\"시술 당시 나이\"].astype(str) + \"_\" + d[\"Day5_이식_여부\"].astype(str)\n",
    "    d[\"시술횟수×나이\"] = d[\"총시술_bin3\"].astype(str) + \"_\" + d[\"나이_3구간\"].astype(str)\n",
    "    d[\"나이×배아진행\"] = d[\"시술 당시 나이\"].astype(str) + \"_\" + d[\"배아_진행_단계\"]\n",
    "    d[\"시기코드×나이\"] = d[\"시술 시기 코드\"].astype(str) + \"_\" + d[\"나이_3구간\"].astype(str)\n",
    "    d[\"나이×단일이식\"] = d[\"시술 당시 나이\"].astype(str) + \"_\" + d[\"단일 배아 이식 여부\"].fillna(-1).astype(int).astype(str)\n",
    "\n",
    "    # culture time\n",
    "    d[\"배양기간\"] = d[\"배아 이식 경과일\"] - d[\"난자 혼합 경과일\"]\n",
    "\n",
    "    # ordinal map\n",
    "    ord_map = {\"0회\":0, \"1회\":1, \"2회\":2, \"3회\":3, \"4회\":4, \"5회\":5, \"6회 이상\":6}\n",
    "    ord_pairs = [\n",
    "        (\"총시술_ord\",\"총 시술 횟수\"), (\"IVF시술_ord\",\"IVF 시술 횟수\"),\n",
    "        (\"클리닉시술_ord\",\"클리닉 내 총 시술 횟수\"), (\"DI시술_ord\",\"DI 시술 횟수\"),\n",
    "        (\"총임신_ord\",\"총 임신 횟수\"), (\"IVF임신_ord\",\"IVF 임신 횟수\"),\n",
    "        (\"총출산_ord\",\"총 출산 횟수\"), (\"IVF출산_ord\",\"IVF 출산 횟수\"),\n",
    "        (\"DI임신_ord\",\"DI 임신 횟수\"), (\"DI출산_ord\",\"DI 출산 횟수\"),\n",
    "    ]\n",
    "    for newc, src in ord_pairs:\n",
    "        if src in d.columns:\n",
    "            d[newc] = d[src].map(ord_map)\n",
    "\n",
    "    # egg age\n",
    "    def get_egg_age(row):\n",
    "        src = row.get(\"난자 출처\")\n",
    "        if src == \"본인 제공\":\n",
    "            return row.get(\"시술 당시 나이\")\n",
    "        if src == \"기증 제공\":\n",
    "            donor = row.get(\"난자 기증자 나이\")\n",
    "            return donor if (pd.notna(donor) and donor != \"알 수 없음\") else \"만18-34세\"\n",
    "        return row.get(\"시술 당시 나이\")\n",
    "    d[\"난자_나이\"] = d.apply(get_egg_age, axis=1)\n",
    "\n",
    "    # embryo source\n",
    "    def get_embryo_source(row):\n",
    "        fr = int(row.get(\"동결 배아 사용 여부\") or 0) if pd.notna(row.get(\"동결 배아 사용 여부\")) else 0\n",
    "        fs = int(row.get(\"신선 배아 사용 여부\") or 0) if pd.notna(row.get(\"신선 배아 사용 여부\")) else 0\n",
    "        if fr and fs: return \"both\"\n",
    "        if fr: return \"frozen\"\n",
    "        if fs: return \"fresh\"\n",
    "        return \"none\"\n",
    "    d[\"배아_출처\"] = d.apply(get_embryo_source, axis=1)\n",
    "    d[\"시기×배아출처\"] = d[\"시술 시기 코드\"].astype(str) + \"_\" + d[\"배아_출처\"]\n",
    "\n",
    "    # embryo reason simple\n",
    "    def embryo_reason_simple(x):\n",
    "        if pd.isna(x): return \"미도달\"\n",
    "        x = str(x)\n",
    "        if \"현재 시술용\" in x: return \"시술용\"\n",
    "        if \"기증\" in x: return \"기증\"\n",
    "        if \"연구\" in x: return \"연구\"\n",
    "        return \"저장\"\n",
    "    d[\"배아생성이유\"] = d[\"배아 생성 주요 이유\"].apply(embryo_reason_simple)\n",
    "\n",
    "    # ovulation stim × type\n",
    "    if \"배란 유도 유형\" in d.columns:\n",
    "        d[\"배란 유도 유형\"] = d[\"배란 유도 유형\"].replace({\n",
    "            '생식선 자극 호르몬': '기록되지 않은 시행',\n",
    "            '세트로타이드 (억제제)': '기록되지 않은 시행'\n",
    "        })\n",
    "    d[\"배란_자극_유도\"] = d[\"배란 자극 여부\"].astype(str) + \"_\" + d[\"배란 유도 유형\"].astype(str)\n",
    "\n",
    "    d[\"나이_알수없음\"] = (d[\"시술 당시 나이\"] == \"알 수 없음\").astype(np.int8)\n",
    "\n",
    "    # male/female infertility\n",
    "    male_inf = [\"불임 원인 - 남성 요인\", \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\",\n",
    "                \"불임 원인 - 정자 운동성\", \"불임 원인 - 정자 형태\"]\n",
    "    female_inf = [\"불임 원인 - 난관 질환\", \"불임 원인 - 배란 장애\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\"]\n",
    "    male_cols = [c for c in male_inf if c in d.columns]\n",
    "    fem_cols  = [c for c in female_inf if c in d.columns]\n",
    "    d[\"남성_불임_수\"] = d[male_cols].sum(axis=1) if male_cols else 0\n",
    "    d[\"여성_불임_수\"] = d[fem_cols].sum(axis=1) if fem_cols else 0\n",
    "    denom = (d[\"남성_불임_수\"] + d[\"여성_불임_수\"]).replace(0, np.nan)\n",
    "    d[\"여성_불임_비율\"] = (d[\"여성_불임_수\"] / denom).fillna(0.0)\n",
    "\n",
    "    # history rates (Laplace + log1p)\n",
    "    for c in [\"IVF시술_ord\",\"IVF임신_ord\",\"IVF출산_ord\",\"총시술_ord\",\"총임신_ord\",\"총출산_ord\",\"클리닉시술_ord\"]:\n",
    "        if c in d.columns:\n",
    "            d[c] = d[c].fillna(0)\n",
    "\n",
    "    d[\"IVF_임신률\"] = clip_log1p(safe_div(d[\"IVF임신_ord\"], d[\"IVF시술_ord\"]))\n",
    "    d[\"IVF_출산률\"] = clip_log1p(safe_div(d[\"IVF출산_ord\"], d[\"IVF임신_ord\"]))\n",
    "    d[\"총_출산률\"]  = clip_log1p(safe_div(d[\"총출산_ord\"], d[\"총임신_ord\"]))\n",
    "    d[\"클리닉_비율\"] = clip_log1p(safe_div(d[\"클리닉시술_ord\"], d[\"총시술_ord\"]))\n",
    "\n",
    "    # extra\n",
    "    d[\"미세주입_이식_비율\"] = clip_log1p(safe_div(d[\"미세주입 배아 이식 수\"].fillna(0), d[\"이식된 배아 수\"].fillna(0)))\n",
    "    d[\"혼합_생성률\"] = clip_log1p(safe_div(d[\"총 생성 배아 수\"].fillna(0), (d[\"혼합된 난자 수\"].fillna(0) + d[\"해동 난자 수\"].fillna(0))))\n",
    "    d[\"미세주입_배아_생성률\"] = clip_log1p(safe_div(d[\"미세주입에서 생성된 배아 수\"].fillna(0), d[\"미세주입된 난자 수\"].fillna(0)))\n",
    "    d[\"총_사용_배아\"] = d[\"해동된 배아 수\"].fillna(0) + d[\"총 생성 배아 수\"].fillna(0)\n",
    "    d[\"IVF_정자_미혼합\"] = ((d[\"파트너 정자와 혼합된 난자 수\"].fillna(0) == 0) &\n",
    "                         (d[\"기증자 정자와 혼합된 난자 수\"].fillna(0) == 0) &\n",
    "                         (d[\"시술 유형\"] == \"IVF\")).astype(np.int8)\n",
    "\n",
    "    # time interactions\n",
    "    d[\"시기×단일이식\"] = d[\"시술 시기 코드\"].astype(str) + \"_\" + d[\"단일 배아 이식 여부\"].fillna(0).astype(int).astype(str)\n",
    "    d[\"시기×배란자극\"] = d[\"시술 시기 코드\"].astype(str) + \"_\" + d[\"배란 자극 여부\"].astype(str)\n",
    "    d[\"시기×유전진단\"] = d[\"시술 시기 코드\"].astype(str) + \"_\" + d[\"착상 전 유전 진단 사용 여부\"].fillna(0).astype(int).astype(str)\n",
    "\n",
    "    d[\"신선_배양시간\"] = d[\"배아 이식 경과일\"] - d[\"난자 혼합 경과일\"]\n",
    "    d[\"동결_배양시간\"] = d[\"배아 이식 경과일\"] - d[\"배아 해동 경과일\"]\n",
    "    d[\"이상적_배양\"] = d[\"배아 이식 경과일\"].isin([3.0, 5.0]).astype(np.int8)\n",
    "\n",
    "    def fresh_egg_tier(row):\n",
    "        if pd.isna(row.get(\"신선 배아 사용 여부\")) or int(row.get(\"신선 배아 사용 여부\") or 0) == 0:\n",
    "            return \"not_fresh\"\n",
    "        eggs = row.get(\"수집된 신선 난자 수\")\n",
    "        eggs = 0 if pd.isna(eggs) else eggs\n",
    "        code = str(row.get(\"시술 시기 코드\"))\n",
    "        if eggs > 10: return f\"{code}_E3\"\n",
    "        if eggs > 0:  return f\"{code}_E2\"\n",
    "        return f\"{code}_E1\"\n",
    "    d[\"시기별_신선난자_구간\"] = d.apply(fresh_egg_tier, axis=1)\n",
    "\n",
    "    def frozen_thaw_tier(row):\n",
    "        if pd.isna(row.get(\"동결 배아 사용 여부\")) or int(row.get(\"동결 배아 사용 여부\") or 0) == 0:\n",
    "            return \"not_frozen\"\n",
    "        thawed = row.get(\"해동된 배아 수\")\n",
    "        thawed = 0 if pd.isna(thawed) else thawed\n",
    "        code = str(row.get(\"시술 시기 코드\"))\n",
    "        if thawed > 3: return f\"{code}_T3\"\n",
    "        if thawed > 0: return f\"{code}_T2\"\n",
    "        return f\"{code}_T1\"\n",
    "    d[\"시기별_해동배아_구간\"] = d.apply(frozen_thaw_tier, axis=1)\n",
    "\n",
    "    d[\"유전검사_합\"] = d[\"착상 전 유전 진단 사용 여부\"].fillna(0) + d[\"착상 전 유전 검사 사용 여부\"].fillna(0)\n",
    "    d[\"PGD_실시\"] = d[\"PGD 시술 여부\"].fillna(0).astype(int)\n",
    "    d[\"PGS_실시\"] = d[\"PGS 시술 여부\"].fillna(0).astype(int)\n",
    "\n",
    "    d[\"대리모 여부\"] = d[\"대리모 여부\"].fillna(-1)\n",
    "\n",
    "    # NA indicators (핵심)\n",
    "    na_cols = [\n",
    "        \"총 생성 배아 수\",\"이식된 배아 수\",\"저장된 배아 수\",\n",
    "        \"수집된 신선 난자 수\",\"혼합된 난자 수\",\n",
    "        \"배아 이식 경과일\",\"난자 혼합 경과일\",\"배아 해동 경과일\",\n",
    "        \"신선_배양시간\",\"동결_배양시간\",\"배양기간\",\n",
    "    ]\n",
    "    d = add_na_indicators(d, na_cols)\n",
    "\n",
    "    return d\n",
    "\n",
    "# [Cell 5] Target Encoding (OOF 5-fold 고정, smoothing 자동)\n",
    "def oof_target_encode(train_df, test_df, col, target_col, n_folds=5, seed=42, smoothing=20):\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    train_enc = pd.Series(np.nan, index=train_df.index, dtype=float)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    for tr_idx, va_idx in skf.split(train_df, train_df[target_col]):\n",
    "        tr = train_df.iloc[tr_idx]\n",
    "        stats = tr.groupby(col)[target_col].agg([\"mean\", \"count\"])\n",
    "        stats[\"enc\"] = (stats[\"mean\"] * stats[\"count\"] + global_mean * smoothing) / (stats[\"count\"] + smoothing)\n",
    "        mapping = stats[\"enc\"].to_dict()\n",
    "        train_enc.iloc[va_idx] = train_df.iloc[va_idx][col].map(mapping).fillna(global_mean)\n",
    "\n",
    "    stats = train_df.groupby(col)[target_col].agg([\"mean\", \"count\"])\n",
    "    stats[\"enc\"] = (stats[\"mean\"] * stats[\"count\"] + global_mean * smoothing) / (stats[\"count\"] + smoothing)\n",
    "    test_enc = test_df[col].map(stats[\"enc\"].to_dict()).fillna(global_mean)\n",
    "\n",
    "    return train_enc.values, test_enc.values\n",
    "\n",
    "# [Cell 6] Optuna (seed=42에서만 1회)\n",
    "def tune_catboost_optuna(X_train, y, cat_indices, task_type, n_trials=40, seed=42, n_folds=5):\n",
    "    if not HAS_OPTUNA:\n",
    "        print(\"[SKIP] Optuna 미설치\")\n",
    "        return None\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'iterations': 2500,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.12, log=True),\n",
    "            'depth': trial.suggest_int('depth', 5, 10),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 20.0, log=True),\n",
    "            'random_strength': trial.suggest_float('random_strength', 0.1, 2.5),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "            'border_count': trial.suggest_int('border_count', 64, 255),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 80),\n",
    "            'rsm': trial.suggest_float('rsm', 0.6, 1.0),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'random_seed': seed,\n",
    "            'eval_metric': 'AUC',\n",
    "            'loss_function': 'Logloss',\n",
    "            'verbose': 0,\n",
    "            'early_stopping_rounds': 120,\n",
    "            'use_best_model': True,\n",
    "            'task_type': task_type,\n",
    "        }\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        aucs = []\n",
    "\n",
    "        for tr_idx, va_idx in skf.split(X_train, y):\n",
    "            pool_tr = cb.Pool(X_train.iloc[tr_idx], y[tr_idx], cat_features=cat_indices)\n",
    "            pool_va = cb.Pool(X_train.iloc[va_idx], y[va_idx], cat_features=cat_indices)\n",
    "\n",
    "            model = cb.CatBoostClassifier(**params)\n",
    "            model.fit(pool_tr, eval_set=pool_va)\n",
    "\n",
    "            pred = model.predict_proba(X_train.iloc[va_idx])[:, 1]\n",
    "            aucs.append(roc_auc_score(y[va_idx], pred))\n",
    "\n",
    "        return float(np.mean(aucs))\n",
    "\n",
    "    print(f\"\\n[Optuna] CatBoost 튜닝 (trials={n_trials}, folds={n_folds}, seed={seed})\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(f\"[Optuna] Best CV AUC: {study.best_value:.6f}\")\n",
    "    print(f\"[Optuna] Best params: {study.best_params}\")\n",
    "    return study.best_params\n",
    "\n",
    "# [Cell 7] One Run (single seed) - 20fold train/predict\n",
    "def train_cb_oof(\n",
    "    train_df, test_df, y,\n",
    "    feature_cols, cat_cols, task_type,\n",
    "    seed, cb_params_base,\n",
    "    n_folds=20\n",
    "):\n",
    "    X_train = train_df[feature_cols].copy()\n",
    "    X_test  = test_df[feature_cols].copy()\n",
    "\n",
    "    for c in cat_cols:\n",
    "        X_train[c] = X_train[c].astype(str).fillna(\"NA\")\n",
    "        X_test[c]  = X_test[c].astype(str).fillna(\"NA\")\n",
    "\n",
    "    cat_indices = [feature_cols.index(c) for c in cat_cols]\n",
    "\n",
    "    cb_params = dict(cb_params_base)\n",
    "    cb_params[\"random_seed\"] = seed\n",
    "    cb_params[\"task_type\"]   = task_type\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    oof_pred = np.zeros(len(train_df), dtype=float)\n",
    "    test_pred = np.zeros(len(test_df), dtype=float)\n",
    "    fold_aucs = []\n",
    "    fi_sum = np.zeros(len(feature_cols), dtype=float)\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_train, y), 1):\n",
    "        pool_tr = cb.Pool(X_train.iloc[tr_idx], y[tr_idx], cat_features=cat_indices)\n",
    "        pool_va = cb.Pool(X_train.iloc[va_idx], y[va_idx], cat_features=cat_indices)\n",
    "\n",
    "        model = cb.CatBoostClassifier(**cb_params)\n",
    "        model.fit(pool_tr, eval_set=pool_va)\n",
    "\n",
    "        oof_pred[va_idx] = model.predict_proba(X_train.iloc[va_idx])[:, 1]\n",
    "        test_pred += model.predict_proba(X_test)[:, 1] / n_folds\n",
    "\n",
    "        fauc = roc_auc_score(y[va_idx], oof_pred[va_idx])\n",
    "        fold_aucs.append(fauc)\n",
    "\n",
    "        # fold별 FI 누적(평균용)\n",
    "        fi_sum += model.get_feature_importance(pool_tr)\n",
    "\n",
    "        best_iter = getattr(model, \"best_iteration_\", None)\n",
    "        print(f\"  seed={seed} | fold {fold}/{n_folds} | AUC={fauc:.6f} | best_iter={best_iter}\")\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    oof_auc = roc_auc_score(y, oof_pred)\n",
    "    fi_mean = fi_sum / n_folds\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"oof_auc\": oof_auc,\n",
    "        \"fold_mean\": float(np.mean(fold_aucs)),\n",
    "        \"fold_std\": float(np.std(fold_aucs)),\n",
    "        \"oof_pred\": oof_pred,\n",
    "        \"test_pred\": test_pred,\n",
    "        \"fi_mean\": fi_mean\n",
    "    }\n",
    "\n",
    "# [Cell 8] Main Notebook Run (Seed별 TE 재생성 버전)\n",
    "# Load → Impute → FE(공통) → [Seed loop: TE 재생성 → Train 20-fold] → Ensemble\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"12v3 Notebook (B안): DI+KNN → FE → [TE per seed] → 20-fold × Seeds → Ensemble\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# -------------------------\n",
    "# 0) Load\n",
    "# -------------------------\n",
    "train_raw = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_raw  = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "sub       = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "# -------------------------\n",
    "# 1) Imputation (공통 1회)\n",
    "# -------------------------\n",
    "print(\"\\n[Step 1] Imputation...\")\n",
    "train_raw, test_raw = impute_missing(train_raw, test_raw)\n",
    "\n",
    "# -------------------------\n",
    "# 2) Feature Engineering (공통 1회)\n",
    "# -------------------------\n",
    "print(\"\\n[Step 2] Feature Engineering...\")\n",
    "train_fe = preprocess(train_raw)\n",
    "test_fe  = preprocess(test_raw)\n",
    "\n",
    "y = train_fe[TARGET_COL].astype(int).values\n",
    "\n",
    "# drop / base feature cols (TE 추가 전 기준)\n",
    "drop_cols = [ID_COL, TARGET_COL]\n",
    "base_feature_cols = [c for c in train_fe.columns if c not in drop_cols]\n",
    "\n",
    "# cat cols (TE 추가 전 기준)\n",
    "base_cat_cols = [c for c in base_feature_cols if str(train_fe[c].dtype) in [\"object\", \"category\"]]\n",
    "\n",
    "print(f\"\\nBase Features: {len(base_feature_cols)} (cat={len(base_cat_cols)}, num={len(base_feature_cols)-len(base_cat_cols)})\")\n",
    "\n",
    "# -------------------------\n",
    "# 3) Optuna (딱 1회) - TE 포함된 데이터로 튜닝하는게 더 맞음\n",
    "#    -> TUNE_SEED로 TE를 한 번 만들고 그걸로 튜닝\n",
    "# -------------------------\n",
    "te_cols = [\n",
    "    \"시술 시기 코드\", \"특정 시술 유형\", \"시술 당시 나이\",\n",
    "    \"배아_진행_단계\", \"시술_대분류\",\n",
    "    \"시기×배아출처\", \"배란_자극_유도\",\n",
    "    \"시기×단일이식\", \"시기×유전진단\",\n",
    "    \"시술횟수×나이\", \"나이×배아진행\",\n",
    "    \"시기별_신선난자_구간\", \"시기별_해동배아_구간\",\n",
    "]\n",
    "\n",
    "def apply_te_for_seed(train_df, test_df, seed_for_te):\n",
    "    \"\"\"train_df/test_df에 TE__* 컬럼을 생성해서 리턴 (원본 변경 X)\"\"\"\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    for col in te_cols:\n",
    "        if col not in tr.columns:\n",
    "            continue\n",
    "        sm = choose_smoothing(tr, col, base=20)\n",
    "        tr_enc, te_enc = oof_target_encode(\n",
    "            tr, te, col, TARGET_COL,\n",
    "            n_folds=N_FOLDS_TE, seed=seed_for_te, smoothing=sm\n",
    "        )\n",
    "        tr[f\"TE__{col}\"] = tr_enc\n",
    "        te[f\"TE__{col}\"] = te_enc\n",
    "    return tr, te\n",
    "\n",
    "print(\"\\n[Step 3] Optuna 준비 (TUNE_SEED로 TE 1회 생성)...\")\n",
    "train_tune, test_tune = apply_te_for_seed(train_fe, test_fe, seed_for_te=TUNE_SEED)\n",
    "\n",
    "# 최종 feature/cat cols (TE 포함 기준)\n",
    "feature_cols = [c for c in train_tune.columns if c not in drop_cols]\n",
    "cat_cols = [c for c in feature_cols if str(train_tune[c].dtype) in [\"object\", \"category\"]]\n",
    "print(f\"Features(+TE): {len(feature_cols)} (cat={len(cat_cols)}, num={len(feature_cols)-len(cat_cols)})\")\n",
    "\n",
    "print(\"\\n[Step 4] Optuna (once)...\")\n",
    "best_params = None\n",
    "if HAS_OPTUNA and OPTUNA_TRIALS > 0:\n",
    "    X_tune = train_tune[feature_cols].copy()\n",
    "\n",
    "    # CatBoost 입력: cat은 str\n",
    "    for c in cat_cols:\n",
    "        X_tune[c] = X_tune[c].astype(str).fillna(\"NA\")\n",
    "\n",
    "    # 안전장치: inf 방지\n",
    "    X_tune.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    cat_indices = [feature_cols.index(c) for c in cat_cols]\n",
    "    best_params = tune_catboost_optuna(\n",
    "        X_tune, y, cat_indices,\n",
    "        task_type=TASK_TYPE,\n",
    "        n_trials=OPTUNA_TRIALS,\n",
    "        seed=TUNE_SEED,\n",
    "        n_folds=N_FOLDS_TUNE\n",
    "    )\n",
    "else:\n",
    "    print(\"[Optuna] skip\")\n",
    "\n",
    "# -------------------------\n",
    "# 4) Base params (호환/안정 버전)\n",
    "# - Bayesian + bagging_temperature 조합\n",
    "# - subsample은 제거(혼선/제약 피하기)\n",
    "# -------------------------\n",
    "cb_params_base = {\n",
    "    \"iterations\": 5000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 7,\n",
    "    \"l2_leaf_reg\": 6.0,\n",
    "    \"random_strength\": 1.0,\n",
    "    \"bagging_temperature\": 0.2,\n",
    "    \"border_count\": 180,\n",
    "    \"rsm\": 0.85,\n",
    "\n",
    "    \"bootstrap_type\": \"Bayesian\",\n",
    "\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"verbose\": 300,\n",
    "    \"early_stopping_rounds\": 200,\n",
    "    \"use_best_model\": True,\n",
    "}\n",
    "if best_params:\n",
    "    # Optuna 결과 merge (불필요/충돌 가능 파라미터가 섞이면 제거)\n",
    "    cb_params_base.update(best_params)\n",
    "    # Bayesian에서는 subsample 혼선 가능 → 혹시 들어오면 제거\n",
    "    cb_params_base.pop(\"subsample\", None)\n",
    "\n",
    "print(\"\\n[Final Params] CatBoost base params:\")\n",
    "print(cb_params_base)\n",
    "\n",
    "# -------------------------\n",
    "# 5) Seed loop: seed별 TE 재생성 + 20-fold 학습\n",
    "# -------------------------\n",
    "print(\"\\n[Step 5] Train 20-fold × Seeds (TE per seed)...\")\n",
    "\n",
    "results = []\n",
    "oof_ens = np.zeros(len(train_fe), dtype=float)\n",
    "test_ens = np.zeros(len(test_fe), dtype=float)\n",
    "fi_ens = np.zeros(len(feature_cols), dtype=float)\n",
    "\n",
    "for s in SEEDS:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(f\"Seed {s} run (TE seed={s}, CV seed={s})\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    # seed별 TE 생성\n",
    "    train_s, test_s = apply_te_for_seed(train_fe, test_fe, seed_for_te=s)\n",
    "\n",
    "    # train_cb_oof는 내부에서 cat str 처리함.\n",
    "    # 대신 여기서 inf 방지 한 번 더 안전하게 적용\n",
    "    train_s.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    test_s.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    res = train_cb_oof(\n",
    "        train_s, test_s, y,\n",
    "        feature_cols, cat_cols,\n",
    "        task_type=TASK_TYPE,\n",
    "        seed=s,\n",
    "        cb_params_base=cb_params_base,\n",
    "        n_folds=N_FOLDS_TRAIN\n",
    "    )\n",
    "\n",
    "    results.append(res)\n",
    "    oof_ens += res[\"oof_pred\"] / len(SEEDS)\n",
    "    test_ens += res[\"test_pred\"] / len(SEEDS)\n",
    "    fi_ens  += res[\"fi_mean\"] / len(SEEDS)\n",
    "\n",
    "# -------------------------\n",
    "# 6) Ensemble Summary\n",
    "# -------------------------\n",
    "oof_auc_ens = roc_auc_score(y, oof_ens)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Seed-wise summary\")\n",
    "for r in results:\n",
    "    print(f\" seed={r['seed']} | OOF_AUC={r['oof_auc']:.6f} | fold_mean={r['fold_mean']:.6f} ± {r['fold_std']:.6f}\")\n",
    "print(f\"\\n >>> Ensemble OOF AUC = {oof_auc_ens:.6f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -------------------------\n",
    "# 7) Save artifacts\n",
    "# -------------------------\n",
    "tag = f\"12v3B_cb_ens_{oof_auc_ens:.6f}_S{'-'.join(map(str, SEEDS))}_F{N_FOLDS_TRAIN}_TE{N_FOLDS_TE}\"\n",
    "\n",
    "oof_path = os.path.join(OUT_DIR, f\"{tag}_oof.npy\")\n",
    "test_path = os.path.join(OUT_DIR, f\"{tag}_test.npy\")\n",
    "np.save(oof_path, oof_ens)\n",
    "np.save(test_path, test_ens)\n",
    "\n",
    "# submission\n",
    "sub2 = sub.copy()\n",
    "sub2[\"probability\"] = test_ens\n",
    "sub_path = os.path.join(OUT_DIR, f\"{tag}_submit.csv\")\n",
    "sub2.to_csv(sub_path, index=False)\n",
    "\n",
    "# feature importance (ensemble mean)\n",
    "fi_df = pd.DataFrame({\"feature\": feature_cols, \"importance\": fi_ens}).sort_values(\"importance\", ascending=False)\n",
    "fi_path = os.path.join(OUT_DIR, f\"{tag}_fi.csv\")\n",
    "fi_df.to_csv(fi_path, index=False)\n",
    "\n",
    "# params log\n",
    "summary_path = os.path.join(OUT_DIR, f\"{tag}_summary.txt\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"12v3 B안 (Seed별 TE 재생성) CatBoost Ensemble\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"DEVICE: {TASK_TYPE}\\n\")\n",
    "    f.write(f\"SEEDS: {SEEDS}\\n\")\n",
    "    f.write(f\"N_FOLDS_TRAIN: {N_FOLDS_TRAIN}\\n\")\n",
    "    f.write(f\"N_FOLDS_TE: {N_FOLDS_TE}\\n\")\n",
    "    f.write(f\"N_FOLDS_TUNE: {N_FOLDS_TUNE}\\n\")\n",
    "    f.write(f\"OOF_AUC_ENSEMBLE: {oof_auc_ens:.6f}\\n\\n\")\n",
    "    f.write(\"[Seed results]\\n\")\n",
    "    for r in results:\n",
    "        f.write(f\" seed={r['seed']} | OOF_AUC={r['oof_auc']:.6f} | fold_mean={r['fold_mean']:.6f} ± {r['fold_std']:.6f}\\n\")\n",
    "    f.write(\"\\n[CatBoost params]\\n\")\n",
    "    f.write(str(cb_params_base) + \"\\n\")\n",
    "    f.write(\"\\n[Optuna best_params]\\n\")\n",
    "    f.write(str(best_params) + \"\\n\")\n",
    "    f.write(\"\\n[Top 30 FI]\\n\")\n",
    "    f.write(fi_df.head(30).to_string(index=False) + \"\\n\")\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" -\", sub_path)\n",
    "print(\" -\", oof_path)\n",
    "print(\" -\", test_path)\n",
    "print(\" -\", fi_path)\n",
    "print(\" -\", summary_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09122ad4",
   "metadata": {},
   "source": [
    "seed 42 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace518db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== SAVE ONLY SEED=42 RESULTS (after seed 42 finished) ======\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"[OUT_DIR]\", os.path.abspath(OUT_DIR))\n",
    "\n",
    "# 1) results 안에서 seed=42 결과 찾기\n",
    "res42 = None\n",
    "for r in results:\n",
    "    if r[\"seed\"] == 42:\n",
    "        res42 = r\n",
    "        break\n",
    "\n",
    "if res42 is None:\n",
    "    raise ValueError(\"seed=42 결과가 results에 없습니다.)\")\n",
    "\n",
    "oof_42  = res42[\"oof_pred\"]\n",
    "test_42 = res42[\"test_pred\"]\n",
    "auc_42  = roc_auc_score(y, oof_42)\n",
    "\n",
    "print(f\"[OK] Seed 42 OOF AUC = {auc_42:.6f}\")\n",
    "print(f\"fold_mean={res42['fold_mean']:.6f} ± {res42['fold_std']:.6f}\")\n",
    "\n",
    "tag = f\"seed42_only_F{N_FOLDS_TRAIN}_TE{N_FOLDS_TE}_AUC{auc_42:.6f}\"\n",
    "\n",
    "# 2) submission 저장\n",
    "sub_out = sub.copy()\n",
    "sub_out[\"probability\"] = test_42\n",
    "sub_path = os.path.join(OUT_DIR, f\"{tag}_submit.csv\")\n",
    "sub_out.to_csv(sub_path, index=False)\n",
    "\n",
    "# 3) oof/test npy 저장\n",
    "np.save(os.path.join(OUT_DIR, f\"{tag}_oof.npy\"),  oof_42)\n",
    "np.save(os.path.join(OUT_DIR, f\"{tag}_test.npy\"), test_42)\n",
    "\n",
    "# 4) summary 저장\n",
    "with open(os.path.join(OUT_DIR, f\"{tag}_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"CatBoost seed=42 only (partial run)\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(f\"DEVICE: {TASK_TYPE}\\n\")\n",
    "    f.write(f\"N_FOLDS_TRAIN: {N_FOLDS_TRAIN}\\n\")\n",
    "    f.write(f\"N_FOLDS_TE: {N_FOLDS_TE}\\n\")\n",
    "    f.write(f\"Seed 42 OOF AUC: {auc_42:.6f}\\n\")\n",
    "    f.write(f\"fold_mean: {res42['fold_mean']:.6f} ± {res42['fold_std']:.6f}\\n\")\n",
    "    f.write(f\"CatBoost params: {cb_params_base}\\n\")\n",
    "    f.write(f\"Optuna best_params: {best_params}\\n\")\n",
    "    f.write(f\"len(results): {len(results)}\\n\")\n",
    "\n",
    "print(\"\\n[SAVED]\")\n",
    "print(\" -\", sub_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26061bdf",
   "metadata": {},
   "source": [
    "best_param 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1626b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best param 저장 \n",
    "import json, os\n",
    "\n",
    "# best_params는 dict (optuna 결과)\n",
    "param_path = os.path.join(OUT_DIR, \"optuna_best_params_seed42.json\")\n",
    "with open(param_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best_params, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"[SAVED] \", param_path)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c42ba7b",
   "metadata": {},
   "source": [
    "seed 202, 777 추가 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69235982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 5 only: Train remaining seeds (202, 777)\n",
    "# + optionally load saved seed42 outputs and make ensemble\n",
    "# ============================================================\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---- settings ----\n",
    "OUT_DIR = \"../outputs\"\n",
    "N_FOLDS_TRAIN = 20\n",
    "N_FOLDS_TE = 5\n",
    "\n",
    "DONE_SEEDS = [42]                 # 이미 끝난 seed\n",
    "RUN_SEEDS  = [202, 777]           # 지금 추가로 돌릴 seed\n",
    "ALL_SEEDS_FOR_ENSEMBLE = [42, 202, 777]  # 최종 앙상블에 포함할 seed\n",
    "\n",
    "SEED42_TAG_PREFIX = \"seed42_only_F20_TE5_AUC\"  \n",
    "\n",
    "def find_seed42_paths(out_dir):\n",
    "    \"\"\"outputs 폴더에서 seed42_only_F20_TE5_AUC*.npy 찾기\"\"\"\n",
    "    oof = None\n",
    "    test = None\n",
    "    for fn in os.listdir(out_dir):\n",
    "        if fn.startswith(SEED42_TAG_PREFIX) and fn.endswith(\"_oof.npy\"):\n",
    "            oof = os.path.join(out_dir, fn)\n",
    "        if fn.startswith(SEED42_TAG_PREFIX) and fn.endswith(\"_test.npy\"):\n",
    "            test = os.path.join(out_dir, fn)\n",
    "    return oof, test\n",
    "\n",
    "print(\"\\n[Step 5 ONLY] Train remaining seeds:\", RUN_SEEDS)\n",
    "\n",
    "results_new = []\n",
    "oof_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "# --- (A) 먼저 seed42 결과 로드 ---\n",
    "seed42_oof_path, seed42_test_path = find_seed42_paths(OUT_DIR)\n",
    "if seed42_oof_path and seed42_test_path:\n",
    "    oof_dict[42]  = np.load(seed42_oof_path)\n",
    "    test_dict[42] = np.load(seed42_test_path)\n",
    "    print(f\"[LOAD] seed42 oof:  {seed42_oof_path}\")\n",
    "    print(f\"[LOAD] seed42 test: {seed42_test_path}\")\n",
    "else:\n",
    "    print(\"[WARN] seed42 저장 파일을 outputs에서 못찾음. (앙상블은 202/777만으로 계산됨)\")\n",
    "\n",
    "# --- (B) 202,777 학습 ---\n",
    "for s in RUN_SEEDS:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(f\"Seed {s} run (TE seed={s}, CV seed={s})\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    # seed별 TE 생성 (train_fe/test_fe는 이미 만들어져 있어야 함)\n",
    "    train_s, test_s = apply_te_for_seed(train_fe, test_fe, seed_for_te=s)\n",
    "\n",
    "    # inf 방지\n",
    "    train_s.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    test_s.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    res = train_cb_oof(\n",
    "        train_s, test_s, y,\n",
    "        feature_cols, cat_cols,\n",
    "        task_type=TASK_TYPE,\n",
    "        seed=s,\n",
    "        cb_params_base=cb_params_base,\n",
    "        n_folds=N_FOLDS_TRAIN\n",
    "    )\n",
    "    results_new.append(res)\n",
    "\n",
    "    # seed별 저장\n",
    "    tag_s = f\"seed{s}_F{N_FOLDS_TRAIN}_TE{N_FOLDS_TE}_AUC{res['oof_auc']:.6f}\"\n",
    "    oof_path  = os.path.join(OUT_DIR, f\"{tag_s}_oof.npy\")\n",
    "    test_path = os.path.join(OUT_DIR, f\"{tag_s}_test.npy\")\n",
    "    sub_path  = os.path.join(OUT_DIR, f\"{tag_s}_submit.csv\")\n",
    "\n",
    "    np.save(oof_path,  res[\"oof_pred\"])\n",
    "    np.save(test_path, res[\"test_pred\"])\n",
    "\n",
    "    sub_s = sub.copy()\n",
    "    sub_s[\"probability\"] = res[\"test_pred\"]\n",
    "    sub_s.to_csv(sub_path, index=False)\n",
    "\n",
    "    print(f\"[SAVED seed={s}]\")\n",
    "    print(\" -\", oof_path)\n",
    "    print(\" -\", test_path)\n",
    "    print(\" -\", sub_path)\n",
    "\n",
    "    oof_dict[s]  = res[\"oof_pred\"]\n",
    "    test_dict[s] = res[\"test_pred\"]\n",
    "\n",
    "# --- (C) 앙상블 (가능한 seed만 평균) ---\n",
    "available_seeds = [s for s in ALL_SEEDS_FOR_ENSEMBLE if s in oof_dict]\n",
    "print(\"\\n[Ensemble] available seeds:\", available_seeds)\n",
    "\n",
    "oof_ens  = np.zeros_like(next(iter(oof_dict.values())))\n",
    "test_ens = np.zeros_like(next(iter(test_dict.values())))\n",
    "\n",
    "for s in available_seeds:\n",
    "    oof_ens  += oof_dict[s]  / len(available_seeds)\n",
    "    test_ens += test_dict[s] / len(available_seeds)\n",
    "\n",
    "oof_auc_ens = roc_auc_score(y, oof_ens)\n",
    "print(f\" >>> Ensemble OOF AUC = {oof_auc_ens:.6f}\")\n",
    "\n",
    "# ensemble 저장\n",
    "tag_ens = f\"cb_ens_{oof_auc_ens:.6f}_S{'-'.join(map(str, available_seeds))}_F{N_FOLDS_TRAIN}_TE{N_FOLDS_TE}\"\n",
    "\n",
    "ens_oof_path  = os.path.join(OUT_DIR, f\"{tag_ens}_oof.npy\")\n",
    "ens_test_path = os.path.join(OUT_DIR, f\"{tag_ens}_test.npy\")\n",
    "ens_sub_path  = os.path.join(OUT_DIR, f\"{tag_ens}_submit.csv\")\n",
    "ens_sum_path  = os.path.join(OUT_DIR, f\"{tag_ens}_summary.txt\")\n",
    "\n",
    "np.save(ens_oof_path,  oof_ens)\n",
    "np.save(ens_test_path, test_ens)\n",
    "\n",
    "sub_ens = sub.copy()\n",
    "sub_ens[\"probability\"] = test_ens\n",
    "sub_ens.to_csv(ens_sub_path, index=False)\n",
    "\n",
    "with open(ens_sum_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"CatBoost Ensemble (partial incremental run)\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"DEVICE: {TASK_TYPE}\\n\")\n",
    "    f.write(f\"SEEDS_USED: {available_seeds}\\n\")\n",
    "    f.write(f\"N_FOLDS_TRAIN: {N_FOLDS_TRAIN}\\n\")\n",
    "    f.write(f\"N_FOLDS_TE: {N_FOLDS_TE}\\n\")\n",
    "    f.write(f\"OOF_AUC_ENSEMBLE: {oof_auc_ens:.6f}\\n\\n\")\n",
    "    f.write(\"[cb_params_base]\\n\")\n",
    "    f.write(str(cb_params_base) + \"\\n\")\n",
    "\n",
    "print(\"\\n[ENSEMBLE SAVED]\")\n",
    "print(\" -\", ens_sub_path)\n",
    "print(\" -\", ens_oof_path)\n",
    "print(\" -\", ens_test_path)\n",
    "print(\" -\", ens_sum_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29076ac",
   "metadata": {},
   "source": [
    "seed 1024, 2048, 4096 추가 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295205b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 5 only: Train remaining seeds (1024, 2048, 4096)\n",
    "# + optionally load saved seed42 outputs and make ensemble\n",
    "# ============================================================\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---- settings ----\n",
    "OUT_DIR = \"../outputs\"\n",
    "N_FOLDS_TRAIN = 20\n",
    "N_FOLDS_TE = 5\n",
    "\n",
    "DONE_SEEDS = [42, 202, 777]                 # 이미 끝난 seed\n",
    "RUN_SEEDS  = [1024, 2048, 4096]           # 지금 추가로 돌릴 seed\n",
    "ALL_SEEDS_FOR_ENSEMBLE = [42, 202, 777]  # 최종 앙상블에 포함할 seed\n",
    "\n",
    "SEED42_TAG_PREFIX = \"seed42_only_F20_TE5_AUC\"  \n",
    "\n",
    "def find_seed42_paths(out_dir):\n",
    "    \"\"\"outputs 폴더에서 seed42_only_F20_TE5_AUC*.npy 찾기\"\"\"\n",
    "    oof = None\n",
    "    test = None\n",
    "    for fn in os.listdir(out_dir):\n",
    "        if fn.startswith(SEED42_TAG_PREFIX) and fn.endswith(\"_oof.npy\"):\n",
    "            oof = os.path.join(out_dir, fn)\n",
    "        if fn.startswith(SEED42_TAG_PREFIX) and fn.endswith(\"_test.npy\"):\n",
    "            test = os.path.join(out_dir, fn)\n",
    "    return oof, test\n",
    "\n",
    "print(\"\\n[Step 5 ONLY] Train remaining seeds:\", RUN_SEEDS)\n",
    "\n",
    "results_new = []\n",
    "oof_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "# --- (A) 먼저 seed42 결과 로드(있으면) ---\n",
    "seed42_oof_path, seed42_test_path = find_seed42_paths(OUT_DIR)\n",
    "if seed42_oof_path and seed42_test_path:\n",
    "    oof_dict[42]  = np.load(seed42_oof_path)\n",
    "    test_dict[42] = np.load(seed42_test_path)\n",
    "    print(f\"[LOAD] seed42 oof:  {seed42_oof_path}\")\n",
    "    print(f\"[LOAD] seed42 test: {seed42_test_path}\")\n",
    "else:\n",
    "    print(\"[WARN] seed42 저장 파일을 outputs에서 못찾음. (앙상블은 202/777만으로 계산됨)\")\n",
    "\n",
    "# --- (B) 202,777 학습 ---\n",
    "for s in RUN_SEEDS:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(f\"Seed {s} run (TE seed={s}, CV seed={s})\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    # seed별 TE 생성 (train_fe/test_fe는 이미 만들어져 있어야 함)\n",
    "    train_s, test_s = apply_te_for_seed(train_fe, test_fe, seed_for_te=s)\n",
    "\n",
    "    # inf 방지\n",
    "    train_s.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    test_s.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    res = train_cb_oof(\n",
    "        train_s, test_s, y,\n",
    "        feature_cols, cat_cols,\n",
    "        task_type=TASK_TYPE,\n",
    "        seed=s,\n",
    "        cb_params_base=cb_params_base,\n",
    "        n_folds=N_FOLDS_TRAIN\n",
    "    )\n",
    "    results_new.append(res)\n",
    "\n",
    "    # seed별 저장\n",
    "    tag_s = f\"seed{s}_F{N_FOLDS_TRAIN}_TE{N_FOLDS_TE}_AUC{res['oof_auc']:.6f}\"\n",
    "    oof_path  = os.path.join(OUT_DIR, f\"{tag_s}_oof.npy\")\n",
    "    test_path = os.path.join(OUT_DIR, f\"{tag_s}_test.npy\")\n",
    "    sub_path  = os.path.join(OUT_DIR, f\"{tag_s}_submit.csv\")\n",
    "\n",
    "    np.save(oof_path,  res[\"oof_pred\"])\n",
    "    np.save(test_path, res[\"test_pred\"])\n",
    "\n",
    "    sub_s = sub.copy()\n",
    "    sub_s[\"probability\"] = res[\"test_pred\"]\n",
    "    sub_s.to_csv(sub_path, index=False)\n",
    "\n",
    "    print(f\"[SAVED seed={s}]\")\n",
    "    print(\" -\", oof_path)\n",
    "    print(\" -\", test_path)\n",
    "    print(\" -\", sub_path)\n",
    "\n",
    "    oof_dict[s]  = res[\"oof_pred\"]\n",
    "    test_dict[s] = res[\"test_pred\"]\n",
    "\n",
    "# --- (C) 앙상블 (가능한 seed만 평균) ---\n",
    "available_seeds = [s for s in ALL_SEEDS_FOR_ENSEMBLE if s in oof_dict]\n",
    "print(\"\\n[Ensemble] available seeds:\", available_seeds)\n",
    "\n",
    "oof_ens  = np.zeros_like(next(iter(oof_dict.values())))\n",
    "test_ens = np.zeros_like(next(iter(test_dict.values())))\n",
    "\n",
    "for s in available_seeds:\n",
    "    oof_ens  += oof_dict[s]  / len(available_seeds)\n",
    "    test_ens += test_dict[s] / len(available_seeds)\n",
    "\n",
    "oof_auc_ens = roc_auc_score(y, oof_ens)\n",
    "print(f\" >>> Ensemble OOF AUC = {oof_auc_ens:.6f}\")\n",
    "\n",
    "# ensemble 저장\n",
    "tag_ens = f\"extra_cb_ens_{oof_auc_ens:.6f}_S{'-'.join(map(str, available_seeds))}_F{N_FOLDS_TRAIN}_TE{N_FOLDS_TE}\"\n",
    "\n",
    "ens_oof_path  = os.path.join(OUT_DIR, f\"{tag_ens}_oof.npy\")\n",
    "ens_test_path = os.path.join(OUT_DIR, f\"{tag_ens}_test.npy\")\n",
    "ens_sub_path  = os.path.join(OUT_DIR, f\"{tag_ens}_submit.csv\")\n",
    "ens_sum_path  = os.path.join(OUT_DIR, f\"{tag_ens}_summary.txt\")\n",
    "\n",
    "np.save(ens_oof_path,  oof_ens)\n",
    "np.save(ens_test_path, test_ens)\n",
    "\n",
    "sub_ens = sub.copy()\n",
    "sub_ens[\"probability\"] = test_ens\n",
    "sub_ens.to_csv(ens_sub_path, index=False)\n",
    "\n",
    "with open(ens_sum_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"CatBoost Ensemble (partial incremental run)\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"DEVICE: {TASK_TYPE}\\n\")\n",
    "    f.write(f\"SEEDS_USED: {available_seeds}\\n\")\n",
    "    f.write(f\"N_FOLDS_TRAIN: {N_FOLDS_TRAIN}\\n\")\n",
    "    f.write(f\"N_FOLDS_TE: {N_FOLDS_TE}\\n\")\n",
    "    f.write(f\"OOF_AUC_ENSEMBLE: {oof_auc_ens:.6f}\\n\\n\")\n",
    "    f.write(\"[cb_params_base]\\n\")\n",
    "    f.write(str(cb_params_base) + \"\\n\")\n",
    "\n",
    "print(\"\\n[ENSEMBLE SAVED]\")\n",
    "print(\" -\", ens_sub_path)\n",
    "print(\" -\", ens_oof_path)\n",
    "print(\" -\", ens_test_path)\n",
    "print(\" -\", ens_sum_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e43e58",
   "metadata": {},
   "source": [
    "모든 seed 토대로 AUC 가장 높은 조합 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dc9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Find Best Seed Ensemble (from saved OOF/Test npy)\n",
    "# - auto-detect seed*_oof.npy / seed*_test.npy (includes seed42_only*)\n",
    "# - greedy forward selection to maximize OOF AUC\n",
    "# - optional: weight tuning on selected seeds (random simplex search)\n",
    "# - saves best ensemble submit/npy/summary\n",
    "# ============================================================\n",
    "\n",
    "import os, re, json, numpy as np, pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# -------------------------\n",
    "# Settings\n",
    "# -------------------------\n",
    "OUT_DIR = \"../outputs\"\n",
    "DATA_DIR = \"../data\"\n",
    "TARGET_COL = \"임신 성공 여부\"   \n",
    "ID_COL = \"ID\"\n",
    "\n",
    "MAX_SEEDS_SELECT = None  # None이면 자동(전부 탐색). 숫자 넣으면 그 개수까지만 greedy로 뽑음\n",
    "USE_WEIGHT_TUNING = True # False면 단순 평균(1/N)\n",
    "WEIGHT_TRIALS = 3000     # weight 튜닝 랜덤 탐색 횟수 (빠름)\n",
    "WEIGHT_SEED = 42         # weight 튜닝 RNG seed\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Helper: load y, submission\n",
    "# -------------------------\n",
    "train_path = os.path.join(DATA_DIR, \"train.csv\")\n",
    "sub_path   = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "y = train_df[TARGET_COL].astype(int).values\n",
    "\n",
    "sub = pd.read_csv(sub_path)\n",
    "\n",
    "# -------------------------\n",
    "# 1) Detect seeds (supports seed42_only_*)\n",
    "# -------------------------\n",
    "# examples:\n",
    "# seed202_F20_TE5_AUC0.740880_oof.npy\n",
    "# seed42_only_F20_TE5_AUC0.740756_oof.npy\n",
    "pat = re.compile(r\"^seed(\\d+)(?:_only)?_F\\d+_TE\\d+_AUC[\\d\\.]+_oof\\.npy$\")\n",
    "\n",
    "seed_to_paths = {}\n",
    "for fn in os.listdir(OUT_DIR):\n",
    "    m = pat.match(fn)\n",
    "    if not m:\n",
    "        continue\n",
    "    seed = int(m.group(1))\n",
    "    oof_fn = fn\n",
    "    test_fn = fn.replace(\"_oof.npy\", \"_test.npy\")\n",
    "    oof_path = os.path.join(OUT_DIR, oof_fn)\n",
    "    test_path = os.path.join(OUT_DIR, test_fn)\n",
    "    if os.path.exists(test_path):\n",
    "        seed_to_paths[seed] = (oof_path, test_path)\n",
    "\n",
    "seeds = sorted(seed_to_paths.keys())\n",
    "print(\"[FOUND SEEDS]\", seeds)\n",
    "\n",
    "if not seeds:\n",
    "    raise ValueError(\"OUT_DIR에서 seed*_oof.npy / seed*_test.npy를 못 찾았어. 경로/파일명 확인!\")\n",
    "\n",
    "# -------------------------\n",
    "# 2) Load all OOF/Test preds\n",
    "# -------------------------\n",
    "oof_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "for s in seeds:\n",
    "    oof_path, test_path = seed_to_paths[s]\n",
    "    oof = np.load(oof_path)\n",
    "    test = np.load(test_path)\n",
    "\n",
    "    if len(oof) != len(y):\n",
    "        raise ValueError(f\"seed {s} oof 길이({len(oof)}) != y 길이({len(y)})\")\n",
    "    oof_dict[s] = oof.astype(float)\n",
    "    test_dict[s] = test.astype(float)\n",
    "\n",
    "# seed별 단일 OOF AUC 출력\n",
    "single = [(s, roc_auc_score(y, oof_dict[s])) for s in seeds]\n",
    "single_sorted = sorted(single, key=lambda x: x[1], reverse=True)\n",
    "print(\"\\n[Single-seed OOF AUC]\")\n",
    "for s, auc in single_sorted:\n",
    "    print(f\" seed={s:<6} auc={auc:.6f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 3) Greedy Forward Selection (maximize OOF AUC)\n",
    "# -------------------------\n",
    "def mean_ensemble_oof(selected):\n",
    "    arr = np.mean(np.vstack([oof_dict[s] for s in selected]), axis=0)\n",
    "    return arr\n",
    "\n",
    "def mean_ensemble_test(selected):\n",
    "    arr = np.mean(np.vstack([test_dict[s] for s in selected]), axis=0)\n",
    "    return arr\n",
    "\n",
    "remaining = set(seeds)\n",
    "selected = []\n",
    "best_auc = -1.0\n",
    "history = []\n",
    "\n",
    "# 시작 seed: 단일 AUC 1등부터 시작(보통 안정적)\n",
    "start_seed = single_sorted[0][0]\n",
    "selected.append(start_seed)\n",
    "remaining.remove(start_seed)\n",
    "best_auc = roc_auc_score(y, mean_ensemble_oof(selected))\n",
    "history.append((selected.copy(), best_auc))\n",
    "print(f\"\\n[Greedy] start seed={start_seed}, auc={best_auc:.6f}\")\n",
    "\n",
    "# 몇 개까지 뽑을지\n",
    "limit = MAX_SEEDS_SELECT if MAX_SEEDS_SELECT is not None else len(seeds)\n",
    "\n",
    "while len(selected) < limit and len(remaining) > 0:\n",
    "    cand_best = None\n",
    "    cand_best_auc = best_auc\n",
    "\n",
    "    for s in list(remaining):\n",
    "        cand = selected + [s]\n",
    "        auc = roc_auc_score(y, mean_ensemble_oof(cand))\n",
    "        if auc > cand_best_auc + 1e-12:\n",
    "            cand_best_auc = auc\n",
    "            cand_best = s\n",
    "\n",
    "    if cand_best is None:\n",
    "        print(f\"[Greedy] stop: no improvement beyond auc={best_auc:.6f}\")\n",
    "        break\n",
    "\n",
    "    selected.append(cand_best)\n",
    "    remaining.remove(cand_best)\n",
    "    best_auc = cand_best_auc\n",
    "    history.append((selected.copy(), best_auc))\n",
    "    print(f\"[Greedy] add seed={cand_best} -> auc={best_auc:.6f} | selected={selected}\")\n",
    "\n",
    "best_set = selected\n",
    "best_oof_mean = mean_ensemble_oof(best_set)\n",
    "best_test_mean = mean_ensemble_test(best_set)\n",
    "best_mean_auc = roc_auc_score(y, best_oof_mean)\n",
    "\n",
    "print(\"\\n[Greedy Result]\")\n",
    "print(\" best_set =\", best_set)\n",
    "print(f\" best_mean_auc = {best_mean_auc:.6f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 4) (Optional) Weight tuning on selected seeds\n",
    "#    Random search on simplex (weights sum to 1, nonnegative)\n",
    "# -------------------------\n",
    "def weighted_ensemble(selected, weights, kind=\"oof\"):\n",
    "    mats = [oof_dict[s] if kind==\"oof\" else test_dict[s] for s in selected]\n",
    "    M = np.vstack(mats)   # (k, n)\n",
    "    w = np.array(weights).reshape(-1, 1)\n",
    "    return (w * M).sum(axis=0)\n",
    "\n",
    "best_w = None\n",
    "best_w_auc = best_mean_auc\n",
    "best_oof = best_oof_mean\n",
    "best_test = best_test_mean\n",
    "\n",
    "if USE_WEIGHT_TUNING and len(best_set) >= 2:\n",
    "    rng = np.random.default_rng(WEIGHT_SEED)\n",
    "\n",
    "    # baseline: equal weights\n",
    "    k = len(best_set)\n",
    "    w0 = np.ones(k) / k\n",
    "    oof0 = weighted_ensemble(best_set, w0, \"oof\")\n",
    "    auc0 = roc_auc_score(y, oof0)\n",
    "\n",
    "    print(f\"\\n[WeightTune] baseline equal weights auc={auc0:.6f}\")\n",
    "\n",
    "    # random simplex weights via Dirichlet\n",
    "    for t in range(WEIGHT_TRIALS):\n",
    "        w = rng.dirichlet(alpha=np.ones(k))\n",
    "        oof_pred = weighted_ensemble(best_set, w, \"oof\")\n",
    "        auc = roc_auc_score(y, oof_pred)\n",
    "        if auc > best_w_auc + 1e-12:\n",
    "            best_w_auc = auc\n",
    "            best_w = w\n",
    "            best_oof = oof_pred\n",
    "            best_test = weighted_ensemble(best_set, w, \"test\")\n",
    "\n",
    "    if best_w is not None:\n",
    "        print(f\"[WeightTune] improved! auc={best_w_auc:.6f}\")\n",
    "        print(\" best weights:\", {s: float(w) for s, w in zip(best_set, best_w)})\n",
    "    else:\n",
    "        print(\"[WeightTune] no improvement over equal-weight mean.\")\n",
    "\n",
    "# -------------------------\n",
    "# 5) Save best ensemble artifacts\n",
    "# -------------------------\n",
    "used_seeds = best_set\n",
    "final_auc = best_w_auc if best_w is not None else best_mean_auc\n",
    "final_oof = best_oof\n",
    "final_test = best_test\n",
    "final_weights = (best_w.tolist() if best_w is not None else (np.ones(len(used_seeds))/len(used_seeds)).tolist())\n",
    "\n",
    "tag = f\"BESTENS_S{'-'.join(map(str, used_seeds))}_OOF{final_auc:.6f}\"\n",
    "ens_oof_path  = os.path.join(OUT_DIR, f\"{tag}_oof.npy\")\n",
    "ens_test_path = os.path.join(OUT_DIR, f\"{tag}_test.npy\")\n",
    "ens_sub_path  = os.path.join(OUT_DIR, f\"{tag}_submit.csv\")\n",
    "ens_sum_path  = os.path.join(OUT_DIR, f\"{tag}_summary.txt\")\n",
    "\n",
    "np.save(ens_oof_path, final_oof)\n",
    "np.save(ens_test_path, final_test)\n",
    "\n",
    "sub_out = sub.copy()\n",
    "# sample_submission이 probability 컬럼인지 확인해서 맞춰주기\n",
    "if \"probability\" in sub_out.columns:\n",
    "    sub_out[\"probability\"] = final_test\n",
    "else:\n",
    "    # 혹시 컬럼명이 다르면 첫 번째 예측 컬럼에 넣음\n",
    "    pred_col = [c for c in sub_out.columns if c != ID_COL][0]\n",
    "    sub_out[pred_col] = final_test\n",
    "\n",
    "sub_out.to_csv(ens_sub_path, index=False)\n",
    "\n",
    "with open(ens_sum_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Best Seed Ensemble from saved npy\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"OUT_DIR: {OUT_DIR}\\n\")\n",
    "    f.write(f\"FOUND_SEEDS: {seeds}\\n\")\n",
    "    f.write(f\"SELECTED_SEEDS: {used_seeds}\\n\")\n",
    "    f.write(f\"OOF_AUC: {final_auc:.6f}\\n\")\n",
    "    f.write(f\"WEIGHTED: {best_w is not None}\\n\")\n",
    "    f.write(f\"WEIGHTS: {final_weights}\\n\\n\")\n",
    "    f.write(\"[Greedy History]\\n\")\n",
    "    for ss, auc in history:\n",
    "        f.write(f\"{ss} -> {auc:.6f}\\n\")\n",
    "\n",
    "print(\"\\n[SAVED BEST ENSEMBLE]\")\n",
    "print(\" -\", ens_sub_path)\n",
    "print(\" -\", ens_oof_path)\n",
    "print(\" -\", ens_test_path)\n",
    "print(\" -\", ens_sum_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a637f4f",
   "metadata": {},
   "source": [
    "BESTENS_S202-1024-4096-42_OOF0.741108_submit.csv 제출"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
